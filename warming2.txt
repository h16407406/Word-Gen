Climate change is a long-term change in the average weather patterns that have come to define Earth’s local, regional and global climates. These changes have a broad range of observed effects that are synonymous with the term.

Changes observed in Earth’s climate since the mid-20th century are driven by human activities, particularly fossil fuel burning, which increases heat-trapping greenhouse gas levels in Earth’s atmosphere, raising Earth’s average surface temperature. Natural processes, which have been overwhelmed by human activities, can also contribute to climate change, including internal variability (e.g., cyclical ocean patterns like El Niño, La Niña and the Pacific Decadal Oscillation) and external forcings (e.g., volcanic activity, changes in the Sun’s energy output, variations in Earth’s orbit).

Scientists use observations from the ground, air, and space, along with computer models, to monitor and study past, present, and future climate change. Climate data records provide evidence of climate change key indicators, such as global land and ocean temperature increases; rising sea levels; ice loss at Earth’s poles and in mountain glaciers; frequency and severity changes in extreme weather such as hurricanes, heatwaves, wildfires, droughts, floods, and precipitation; and cloud and vegetation cover changes.

“Climate change” and “global warming” are often used interchangeably but have distinct meanings. Similarly, the terms "weather" and "climate" are sometimes confused, though they refer to events with broadly different spatial- and timescales.

What Is Global Warming?
global_warming_2022
This graph illustrates the change in global surface temperature relative to 1951-1980 average temperatures, with the year 2020 statistically tying with 2016 for hottest on record (Source: NASA's Goddard Institute for Space Studies). Learn more about global surface temperature here.
NASA/JPL-Caltech
Global warming is the long-term heating of Earth’s surface observed since the pre-industrial period (between 1850 and 1900) due to human activities, primarily fossil fuel burning, which increases heat-trapping greenhouse gas levels in Earth’s atmosphere. This term is not interchangeable with the term "climate change."

Since the pre-industrial period, human activities are estimated to have increased Earth’s global average temperature by about 1 degree Celsius (1.8 degrees Fahrenheit), a number that is currently increasing by more than 0.2 degrees Celsius (0.36 degrees Fahrenheit) per decade. The current warming trend is unequivocally the result of human activity since the 1950s and is proceeding at an unprecedented rate over millennia.

Weather vs. Climate
“If you don’t like the weather in New England, just wait a few minutes.” <br>- Mark Twain

Weather refers to atmospheric conditions that occur locally over short periods of time—from minutes to hours or days. Familiar examples include rain, snow, clouds, winds, floods, or thunderstorms.

Climate, on the other hand, refers to the long-term (usually at least 30 years) regional or even global average of temperature, humidity, and rainfall patterns over seasons, years, or decades.
global warming is the current rise in earth's average temperature caused primarily by human produced greenhouse gas emissions from burning fossil fuels. average global temperature has increased by about one degree celsius since the industrial revolution and is projected to rise an additional two to four degrees celsius by two thousand one hundred. increased temperatures are causing sea levels to rise and weather patterns to change due to melting ice caps and thermal expansion of oceans. while some natural climate change has occurred throughout earth's history, the current changes are happening much faster than past changes due to human activity.

global warming is mostly because people burn things like gasoline for cars and natural gas to keep houses warm. the heat from the burning itself only makes the world a tiny bit warmer. it is the carbon dioxide from the burning which is the biggest part of the problem. among the greenhouse gases the increase of carbon dioxide in the atmosphere is the main cause of global warming. when people burn fossil fuels like coal oil and natural gas this adds carbon dioxide into the air. when people cut down many trees this means less carbon dioxide is taken out of the atmosphere by those plants.

as earth's surface temperature becomes hotter the sea level rises. this is partly because water expands when it gets warmer. it is also partly because warm temperatures make glaciers and ice caps melt. the sea level rise causes coastal areas to flood. weather patterns including where and how much rain or snow there is are changing. deserts will probably increase in size. colder areas will warm up faster than warm areas. strong storms may become more likely and farming may not make as much food.

global warming results when greenhouse gases trap heat in earth's atmosphere. these gases act like a blanket around earth keeping it warm. without them earth would be much colder. there are natural greenhouse gases like water vapour and clouds but human activity has added carbon dioxide methane and nitrous oxide. these additional gases trap more heat and cause the planet to warm.

global warming has many effects on people animals and the environment. higher temperatures can cause heat waves droughts and wildfires. melting ice reduces habitat for animals like polar bears. ocean warming and acidification harm plants and animals under water. rising seas flood coastal areas and can destroy homes farmland and habitats. more extreme weather events like storms floods and cyclones may happen more often.

people and nature can adapt to some changes like building sea walls planting different crops and protecting forests. but some large changes are too big or too fast to adapt to. to lessen global warming people can use cleaner energy like solar wind and hydropower. we can also waste less energy travel less by car make buildings more efficient plant trees and eat less meat. governments can set rules and laws to reduce greenhouse gases and help people change.

global warming often called climate change is one of the biggest problems the world faces today. even a small change in temperature can cause big effects over time. our actions in the coming years will help decide how hot the planet becomes and how well people and plants and animals survive.


Since the Industrial Revolution, the global annual temperature has increased in total by a little more than 1 degree Celsius, or about 2 degrees Fahrenheit. Between 1850—the year that accurate recordkeeping began—and 1980, it rose on average by 0.07 degrees Celsius (0.13 degrees Fahrenheit) every 10 years. Since 1981, however, the rate of increase has more than doubled: For the last 40 years, we’ve seen the global annual temperature rise by 0.2 degrees Celsius, or 0.36 degrees Fahrenheit, per decade.

The result? A planet that has never been hotter. The 10 most recent years are the warmest years on record. And the warmer it gets, the more probable it becomes that we trigger climate tipping points (such as rapid glacier melt or thawing permafrost) that can transform natural systems into entirely different states and lead to more warming.

In 2015, the Paris Agreement codified the recommendation of climate scientists to limit global warming to 1.5 degrees Celsius. Working toward that goal continues to give us our best chance to stave off the worst, most devastating effects of climate change: the extreme droughts, wildfires, floods, tropical storms, and other disasters that are so widespread and costly to both our infrastructure and our health.

What causes global warming?

Global warming results from the increasing concentration of carbon dioxide (CO2) and other greenhouse gases that trap heat in the earth’s atmosphere. This trapped energy comes from incoming solar radiation absorbed by the earth’s surface and re-radiated back into the atmosphere as infrared energy.

Though natural cycles and fluctuations have caused the planet's climate to change continually over the last 800,000 years, it is human activity that has driven our current era of global warming. In particular, our burning of fossil fuels—such as coal, oil, gasoline, and natural gas—has led to the greenhouse effect. In the United States, the largest source of greenhouse gases is transportation, followed closely by electricity production and industrial activity. (Learn about the natural and human causes of climate change.)

To support global efforts to limit warming to 1.5 degrees Celsius, the United States now faces the monumental (yet achievable) task of cutting greenhouse gas emissions to net zero no later than 2050. We must also fulfill our commitments to help developing nations meet their climate goals—a responsibility that we (and other rich, polluting nations) are currently falling short on. In better news, at the most recent United Nations climate convention, countries agreed to work toward scaling up climate finance to developing countries to at least $1.3 trillion per year by 2035.

How is global warming linked to extreme weather?

As the earth’s atmosphere heats up, it holds more water, changing weather patterns and fueling more severe rainfall events. At the same time, warmer air causes more moisture to evaporate from the planet’s surface in dry weather, resulting in more frequent and intense droughts and heat waves.

A 2023 paper by two NASA scientists published in the journal Nature Water confirmed the “wet-gets-wetter, dry-gets-drier hypothesis” through a review of extreme weather events across five continents from 2002 to 2021. Among the most dramatic was a pluvial (intense period of rainfall) that began in 2019 in central Africa and was still ongoing as the study concluded. The event caused Lake Victoria’s water levels to rise by more than 3 feet and resulted in severe flooding in surrounding areas. Meanwhile a 2015–'16 drought in Brazil led to empty reservoirs and water rationing across some cities. The scientists concluded that “the global total intensity of major extreme events appears to be increasing as the world warms.”

Ocean temperatures are getting warmer too—which means that tropical storms can pick up more energy. The 2020 Atlantic hurricane season included a record-breaking 30 tropical storms, 6 major hurricanes, and 13 hurricanes altogether. With increased intensity comes increased damage and death, particularly as coastal populations grow and coastal development accelerates. Billion-dollar weather and climate disasters have been increasing in recent years; the United States experienced an unprecedented 28 of these in 2023.

What are the other effects of global warming?

Each year scientists learn more about the consequences of global warming, and each year we also gain new evidence of its devastating impact on people and the planet. They touch on every facet of our lives—our economy and livelihoods, our health, our food supply, and our ways of life. Heat stress is killing workers. Allergies, asthma, and infectious disease outbreaks are becoming more common due to increased growth of pollen-producing ragweed, higher levels of air pollution, and the spread of conditions favorable to ticks and mosquitoes. Communities are migrating from scorched or flooded homelands. Melting ice is reshaping environments and impacting lives from the mountains to the coasts. (Learn more about the effects of climate change.)

Though everyone is affected by climate change, not everyone is affected equally. Indigenous Peoples, people of color, and the economically marginalized are typically hit the hardest, due in part to environmental racism. Inequities built into our housing, health care, and labor systems make these communities more vulnerable to the worst impacts of climate change—even though these same communities have done the least to contribute to it.

Where does the United States stand in terms of global-warming contributors?

In recent years, China has taken the lead in global-warming pollution, producing about 26 percent of all CO2 emissions. The United States comes in second. Despite making up just 4 percent of the world’s population, our nation produces a sobering 13 percent of all global CO2 emissions—nearly as much as the European Union and India (third and fourth place) combined. And America is still number one, by far, in cumulative emissions over the past 150 years. Given this outsize role in accelerating global warming, the United States must step up its financial commitments to bringing about a cleaner, safer, and more equitable future. Our responsibility matters to other countries, and it should matter to us, too.

Is the United States doing anything to prevent global warming?

We’ve started. But in order to avoid the worsening effects of climate change, we need to do a lot more—together with other countries—to reduce our dependence on fossil fuels and transition to clean energy sources.

Under the first administration of President Donald Trump, the United States withdrew from the Paris Agreement, rolled back or eliminated dozens of clean air protections, and opened up federally managed lands, including culturally sacred national monuments, to fossil fuel development.

The administration of President Joe Biden subsequently worked to pass record investments in electric vehicles and other clean energy sectors in the form of the Bipartisan Infrastructure Law and the Inflation Reduction Act. And through the Justice40 Initiative, they built in climate justice, requiring that at least 40 percent of the overall benefits from certain federal climate and infrastructure programs go toward disinvested and overburdened communities.

Those policies, coupled with the work of the U.S. Environmental Protection Agency (EPA) to rein in the largest sources of climate pollution across the energy and transportation sectors, brought us significantly closer to meeting our climate goals. Evidence has shown that the United States is on track to reduce its GHG emissions by 38 to 56 percent below 2005 levels in 2035, a significant increase from the pace of annual emissions abatement from 2005 to 2023. However, that progress is now uncertain with the second Trump administration promising more rollbacks of climate-focused regulations, including projects intending to address environmental injustice.

Despite the lack of cooperation from the Trump administration, local and state governments made great strides from 2017 to 2021 through efforts like the American Cities Climate Challenge and ongoing collaborations like the Regional Greenhouse Gas Initiative. Meanwhile, industry and business leaders continued to create and adopt new clean energy technologies and increase energy efficiency in buildings, appliances, and industrial processes. This public-private sector collaboration remains key to achieving our climate goals.

Today the American automotive industry is finding new ways to produce cars and trucks that are more fuel efficient and is committing itself to putting more and more zero-emission electric vehicles on the road. Developers, cities, and community advocates are coming together to make sure that new affordable housing is built with efficiency in mind, reducing energy consumption and lowering electric and heating bills for residents. And renewable energy continues to surge as the costs associated with its production and distribution keep falling. These trends have also fueled record job growth—at the beginning of 2024, 3.4 million workers were employed in clean energy in the United States.

Is global warming too big a problem for me to help tackle?

No! While we can’t win the fight without large-scale government action at the national level, we also can’t do it without the help of individuals who are willing to use their voices, hold government and industry leaders to account, and make changes in their daily habits.

Wondering how you can be a part of the fight against global warming? Reduce your own carbon footprint by taking a few easy steps: Make conserving energy a part of your daily routine and your decisions as a consumer. When you shop for new appliances like refrigerators, washers, and dryers, look for products with the government’s Energy Star label; they meet a higher standard for energy efficiency than the minimum federal requirements. When you buy a car, look for one with the highest gas mileage and lowest emissions, and consider how an EV can help you save in the long run. You can also reduce your emissions by taking public transportation or carpooling when possible.

And while new federal and state standards are a step in the right direction, much more needs to be done. Voice your support of climate-friendly and climate change preparedness policies, and tell your representatives that equitably transitioning from dirty fossil fuels to clean power should be a top priority—because it’s vital to building healthy, more secure communities.



Featured article
Page semi-protected
Listen to this article
From Wikipedia, the free encyclopedia
This article is about the present-day human-induced rise in global temperatures. For natural historical climate trends, see Climate variability and change.
"Global warming" redirects here. For other uses, see Climate change (disambiguation) and Global warming (disambiguation).
The global map shows sea temperature rises of 0.5 to 1 degree Celsius; land temperature rises of 1 to 2 degrees Celsius; and Arctic temperature rises of up to 4 degrees Celsius.
Changes in surface air temperature over the past 50 years.[1] The Arctic has warmed the most, and temperatures on land have generally increased more than sea surface temperatures.
Timeseries of global warming from 1880 to 2020 compared to simulated temperatures given only natural forcing. The first shows a positive trend since around 1950 and the second stays relatively flat.
Earth's average surface air temperature has increased almost 1.5 °C (about 2.5 °F) since the Industrial Revolution. Natural forces cause some variability, but the 20-year average shows the progressive influence of human activity.[2]
Present-day climate change includes both global warming—the ongoing increase in global average temperature—and its wider effects on Earth's climate system. Climate change in a broader sense also includes previous long-term changes to Earth's climate. The current rise in global temperatures is driven by human activities, especially fossil fuel burning since the Industrial Revolution.[3][4] Fossil fuel use, deforestation, and some agricultural and industrial practices release greenhouse gases.[5] These gases absorb some of the heat that the Earth radiates after it warms from sunlight, warming the lower atmosphere. Carbon dioxide, the primary gas driving global warming, has increased in concentration by about 50% since the pre-industrial era to levels not seen for millions of years.[6]

Climate change has an increasingly large impact on the environment. Deserts are expanding, while heat waves and wildfires are becoming more common.[7] Amplified warming in the Arctic has contributed to thawing permafrost, retreat of glaciers and sea ice decline.[8] Higher temperatures are also causing more intense storms, droughts, and other weather extremes.[9] Rapid environmental change in mountains, coral reefs, and the Arctic is forcing many species to relocate or become extinct.[10] Even if efforts to minimize future warming are successful, some effects will continue for centuries. These include ocean heating, ocean acidification and sea level rise.[11]

Climate change threatens people with increased flooding, extreme heat, increased food and water scarcity, more disease, and economic loss.[12] Human migration and conflict can also be a result.[13] The World Health Organization calls climate change one of the biggest threats to global health in the 21st century.[14] Societies and ecosystems will experience more severe risks without action to limit warming.[15] Adapting to climate change through efforts like flood control measures or drought-resistant crops partially reduces climate change risks, although some limits to adaptation have already been reached.[16] Poorer communities are responsible for a small share of global emissions, yet have the least ability to adapt and are most vulnerable to climate change.[17][18]

Bobcat Fire in Monrovia, CA, September 10, 2020
Bleached colony of Acropora coral
A dry lakebed in California, which is experiencing its worst megadrought in 1,200 years.[19]
Examples of some effects of climate change: Wildfire intensified by heat and drought, bleaching of corals occurring more often due to marine heatwaves, and worsening droughts compromising water supplies.
Many climate change impacts have been observed in the first decades of the 21st century, with 2024 the warmest on record at +1.60 °C (2.88 °F) since regular tracking began in 1850.[20][21] Additional warming will increase these impacts and can trigger tipping points, such as melting all of the Greenland ice sheet.[22] Under the 2015 Paris Agreement, nations collectively agreed to keep warming "well under 2 °C". However, with pledges made under the Agreement, global warming would still reach about 2.8 °C (5.0 °F) by the end of the century.[23] Limiting warming to 1.5 °C would require halving emissions by 2030 and achieving net-zero emissions by 2050.[24][25]

There is widespread support for climate action worldwide.[26][27] Fossil fuel use can be phased out by conserving energy and switching to energy sources that do not produce significant carbon pollution. These energy sources include wind, solar, hydro, and nuclear power.[28] Cleanly generated electricity can replace fossil fuels for powering transportation, heating buildings, and running industrial processes.[29] Carbon can also be removed from the atmosphere, for instance by increasing forest cover and farming with methods that capture carbon in soil.[30]

Terminology
Before the 1980s it was unclear whether the warming effect of increased greenhouse gases was stronger than the cooling effect of airborne particulates in air pollution. Scientists used the term inadvertent climate modification to refer to human impacts on the climate at this time.[31] In the 1980s, the terms global warming and climate change became more common, often being used interchangeably.[32][33][34] Scientifically, global warming refers only to increased surface warming, while climate change describes both global warming and its effects on Earth's climate system, such as precipitation changes.[31]

Climate change can also be used more broadly to include changes to the climate that have happened throughout Earth's history.[35] Global warming—used as early as 1975[36]—became the more popular term after NASA climate scientist James Hansen used it in his 1988 testimony in the U.S. Senate.[37] Since the 2000s, climate change has increased usage.[38] Various scientists, politicians and media may use the terms climate crisis or climate emergency to talk about climate change, and may use the term global heating instead of global warming.[39][40]

Global temperature rise
Further information: Global surface temperature
Temperatures prior to present-day global warming
Main articles: Climate variability and change; Temperature record of the last 2,000 years; and Paleoclimatology

Global surface temperature reconstruction over the last 2000 years using proxy data from tree rings, corals, and ice cores in blue.[41] Directly observed data is in red.[42]
Over the last few million years the climate cycled through ice ages. One of the hotter periods was the Last Interglacial, around 125,000 years ago, where temperatures were between 0.5 °C and 1.5 °C warmer than before the start of global warming.[43] This period saw sea levels 5 to 10 metres higher than today. The most recent glacial maximum 20,000 years ago was some 5–7 °C colder. This period has sea levels that were over 125 metres (410 ft) lower than today.[44]

Temperatures stabilized in the current interglacial period beginning 11,700 years ago.[45] This period also saw the start of agriculture.[46] Historical patterns of warming and cooling, like the Medieval Warm Period and the Little Ice Age, did not occur at the same time across different regions. Temperatures may have reached as high as those of the late 20th century in a limited set of regions.[47][48] Climate information for that period comes from climate proxies, such as trees and ice cores.[49][50]

Warming since the Industrial Revolution

In recent decades, new high temperature records have substantially outpaced new low temperature records on a growing portion of Earth's surface.[51]

There has been an increase in ocean heat content during recent decades as the oceans absorb over 90% of the heat from global warming.[52]
Around 1850 thermometer records began to provide global coverage.[53] Between the 18th century and 1970 there was little net warming, as the warming impact of greenhouse gas emissions was offset by cooling from sulfur dioxide emissions. Sulfur dioxide causes acid rain, but it also produces sulfate aerosols in the atmosphere, which reflect sunlight and cause global dimming. After 1970, the increasing accumulation of greenhouse gases and controls on sulfur pollution led to a marked increase in temperature.[54][55][56]

Duration: 30 seconds.0:30
NASA animation portraying global surface temperature changes from 1880 to 2023. The colour blue denotes cooler temperatures and red denotes warmer temperatures.
Ongoing changes in climate have had no precedent for several thousand years.[57] Multiple independent datasets all show worldwide increases in surface temperature,[58] at a rate of around 0.2 °C per decade.[59] The 2014–2023 decade warmed to an average 1.19 °C [1.06–1.30 °C] compared to the pre-industrial baseline (1850–1900).[60] Not every single year was warmer than the last: internal climate variability processes can make any year 0.2 °C warmer or colder than the average.[61] From 1998 to 2013, negative phases of two such processes, Pacific Decadal Oscillation (PDO)[62] and Atlantic Multidecadal Oscillation (AMO)[63] caused a short slower period of warming called the "global warming hiatus".[64] After the "hiatus", the opposite occurred, with 2024 well above the recent average at more than +1.5 °C.[65] This is why the temperature change is defined in terms of a 20-year average, which reduces the noise of hot and cold years and decadal climate patterns, and detects the long-term signal.[66]: 5 [67]

A wide range of other observations reinforce the evidence of warming.[68][69] The upper atmosphere is cooling, because greenhouse gases are trapping heat near the Earth's surface, and so less heat is radiating into space.[70] Warming reduces average snow cover and forces the retreat of glaciers. At the same time, warming also causes greater evaporation from the oceans, leading to more atmospheric humidity, more and heavier precipitation.[71][72] Plants are flowering earlier in spring, and thousands of animal species have been permanently moving to cooler areas.[73]

Differences by region
Different regions of the world warm at different rates. The pattern is independent of where greenhouse gases are emitted, because the gases persist long enough to diffuse across the planet. Since the pre-industrial period, the average surface temperature over land regions has increased almost twice as fast as the global average surface temperature.[74] This is because oceans lose more heat by evaporation and oceans can store a lot of heat.[75] The thermal energy in the global climate system has grown with only brief pauses since at least 1970, and over 90% of this extra energy has been stored in the ocean.[76][77] The rest has heated the atmosphere, melted ice, and warmed the continents.[78]

The Northern Hemisphere and the North Pole have warmed much faster than the South Pole and Southern Hemisphere. The Northern Hemisphere not only has much more land, but also more seasonal snow cover and sea ice. As these surfaces flip from reflecting a lot of light to being dark after the ice has melted, they start absorbing more heat.[79] Local black carbon deposits on snow and ice also contribute to Arctic warming.[80] Arctic surface temperatures are increasing between three and four times faster than in the rest of the world.[81][82][83] Melting of ice sheets near the poles weakens both the Atlantic and the Antarctic limb of thermohaline circulation, which further changes the distribution of heat and precipitation around the globe.[84][85][86][87]

Future global temperatures

CMIP6 multi-model projections of global surface temperature changes for the year 2090 relative to the 1850–1900 average. The current trajectory for warming by the end of the century is roughly halfway between these two extremes.[23][88][89]
The World Meteorological Organization estimates there is almost a 50% chance of the five-year average global temperature exceeding +1.5 °C between 2024 and 2028.[90] The IPCC expects the 20-year average to exceed +1.5 °C in the early 2030s.[91]

The IPCC Sixth Assessment Report (2021) included projections that by 2100 global warming is very likely to reach 1.0–1.8 °C under a scenario with very low emissions of greenhouse gases, 2.1–3.5 °C under an intermediate emissions scenario, or 3.3–5.7 °C under a very high emissions scenario.[92] The warming will continue past 2100 in the intermediate and high emission scenarios,[93][94] with future projections of global surface temperatures by year 2300 being similar to millions of years ago.[95]

The remaining carbon budget for staying beneath certain temperature increases is determined by modelling the carbon cycle and climate sensitivity to greenhouse gases.[96] According to UNEP, global warming can be kept below 1.5 °C with a 50% chance if emissions after 2023 do not exceed 200 gigatonnes of CO2. This corresponds to around 4 years of current emissions. To stay under 2.0 °C, the carbon budget is 900 gigatonnes of CO2, or 16 years of current emissions.[97]

Causes of recent global temperature rise
Main article: Causes of climate change

Physical drivers of global warming that has happened so far. Future global warming potential for long lived drivers like carbon dioxide emissions is not represented. Whiskers on each bar show the possible error range.
The climate system experiences various cycles on its own which can last for years, decades or even centuries. For example, El Niño events cause short-term spikes in surface temperature while La Niña events cause short term cooling.[98] Their relative frequency can affect global temperature trends on a decadal timescale.[99] Other changes are caused by an imbalance of energy from external forcings.[100] Examples of these include changes in the concentrations of greenhouse gases, solar luminosity, volcanic eruptions, and variations in the Earth's orbit around the Sun.[101]

To determine the human contribution to climate change, unique "fingerprints" for all potential causes are developed and compared with both observed patterns and known internal climate variability.[102] For example, solar forcing—whose fingerprint involves warming the entire atmosphere—is ruled out because only the lower atmosphere has warmed.[103] Atmospheric aerosols produce a smaller, cooling effect. Other drivers, such as changes in albedo, are less impactful.[104]

Greenhouse gases
Main articles: Greenhouse gas, Greenhouse gas emissions, Greenhouse effect, and Carbon dioxide in Earth's atmosphere

CO2 concentrations over the last 800,000 years as measured from ice cores (blue/green) and directly (black)
Greenhouse gases are transparent to sunlight, and thus allow it to pass through the atmosphere to heat the Earth's surface. The Earth radiates it as heat, and greenhouse gases absorb a portion of it. This absorption slows the rate at which heat escapes into space, trapping heat near the Earth's surface and warming it over time.[105]

While water vapour (≈50%) and clouds (≈25%) are the biggest contributors to the greenhouse effect, they primarily change as a function of temperature and are therefore mostly considered to be feedbacks that change climate sensitivity. On the other hand, concentrations of gases such as CO2 (≈20%), tropospheric ozone,[106] CFCs and nitrous oxide are added or removed independently from temperature, and are therefore considered to be external forcings that change global temperatures.[107]

Before the Industrial Revolution, naturally-occurring amounts of greenhouse gases caused the air near the surface to be about 33 °C warmer than it would have been in their absence.[108][109] Human activity since the Industrial Revolution, mainly extracting and burning fossil fuels (coal, oil, and natural gas),[110] has increased the amount of greenhouse gases in the atmosphere. In 2022, the concentrations of CO2 and methane had increased by about 50% and 164%, respectively, since 1750.[111] These CO2 levels are higher than they have been at any time during the last 14 million years.[112] Concentrations of methane are far higher than they were over the last 800,000 years.[113]


The Global Carbon Project shows how additions to CO2 since 1880 have been caused by different sources ramping up one after another.
Global human-caused greenhouse gas emissions in 2019 were equivalent to 59 billion tonnes of CO2. Of these emissions, seventyfive% was CO2, eighteen% was methane, four% was nitrous oxide, and two% was fluorinated gases.[114] CO2 emissions primarily come from burning fossil fuels to provide energy for transport, manufacturing, heating, and electricity.[5] Additional CO2 emissions come from deforestation and industrial processes, which include the CO2 released by the chemical reactions for making cement, steel, aluminum, and fertilizer.[115][116][117][118] Methane emissions come from livestock, manure, rice cultivation, landfills, wastewater, and coal mining, as well as oil and gas extraction.[119][120] Nitrous oxide emissions largely come from the microbial decomposition of fertilizer.[121][122]

While methane only lasts in the atmosphere for an average of twelve years,[123] CO2 lasts much longer. The Earth's surface absorbs CO2 as part of the carbon cycle. While plants on land and in the ocean absorb most excess emissions of CO2 every year, that CO2 is returned to the atmosphere when biological matter is digested, burns, or decays.[124] Land-surface carbon sink processes, such as carbon fixation in the soil and photosynthesis, remove about twentynine% of annual global CO2 emissions.[125] The ocean has absorbed 20 to 30% of emitted CO2 over the last two decades.[126] CO2 is only removed from the atmosphere for the long term when it is stored in the Earth's crust, which is a process that can take millions of years to complete.[124]

Land surface changes

The rate of global tree cover loss has approximately doubled since twothousandone, to an annual loss approaching an area the size of Italy.[127]
Around thirty% of Earth's land area is largely unusable for humans (glaciers, deserts, etc.), twentysix% is forests, 10% is shrubland and thirtyfour% is agricultural land.[128] Deforestation is the main land use change contributor to global warming,[129] as the destroyed trees release CO2, and are not replaced by new trees, removing that carbon sink.[130] Between twothousandone and twothousandeightteen, twentyseven% of deforestation was from permanent clearing to enable agricultural expansion for crops and livestock. Another twentyfour% has been lost to temporary clearing under the shifting cultivation agricultural systems. twentysix% was due to logging for wood and derived products, and wildfires have accounted for the remaining twentyseven%.[131] Some forests have not been fully cleared, but were already degraded by these impacts. Restoring these forests also recovers their potential as a carbon sink.[132]

Local vegetation cover impacts how much of the sunlight gets reflected back into space (albedo), and how much heat is lost by evaporation. For instance, the change from a dark forest to grassland makes the surface lighter, causing it to reflect more sunlight. Deforestation can also modify the release of chemical compounds that influence clouds, and by changing wind patterns.[133] In tropic and temperate areas the net effect is to produce significant warming, and forest restoration can make local temperatures cooler.[132] At latitudes closer to the poles, there is a cooling effect as forest is replaced by snow-covered (and more reflective) plains.[133] Globally, these increases in surface albedo have been the dominant direct influence on temperature from land use change. Thus, land use change to date is estimated to have a slight cooling effect.[134]

Global warming refers to the increase in the planet’s overall average temperature in recent decades. Natural processes have always affected Earth’s temperature and climate, but more recently, the planet’s temperature and climate have changed at a higher pace than nature alone can explain. These rapid changes are due to human activities and the widespread use of fossil fuels for energy.

Fossil fuels include coal, oil and natural gas. Burning fossil fuels causes what is known as the “greenhouse effect” in Earth’s atmosphere. The greenhouse effect happens when the sun’s rays penetrate the atmosphere, and the Earth’s surface reflects that heat. Some of the gasses in the atmosphere then trap heat over Earth. Gasses emitted by the burning of fossil fuels are very good at trapping heat and preventing it from leaving the atmosphere. These greenhouse gasses are carbon dioxide, methane, nitrous oxide, chlorofluorocarbons and water vapor. The excess heat in the atmosphere has caused the planet’s average global temperature to rise over time, otherwise known as global warming.

The Industrial Revolution, beginning in the mid-eighteenthth century, led to the start of an anthropogenic (human-caused) rise in greenhouse gas emissions from Europe and the United States. The invention of the coal-fired steam engine introduced coal as a major source of energy. Soon it was heating homes and fueling machines in factories.

Since that time, the burning of fossil fuels has steadily increased. Today, many countries around the world use fossil fuels to generate energy for electricity, heat and transportation. Emissions of greenhouse gasses have skyrocketed in the last 100 years, and especially since the nineteeneighties. This has accelerated the rise in Earth’s temperature.

Global warming has presented humans with another issue: climate change. People often use the terms “global warming” and “climate change” interchangeably, but they are different. Global warming refers to Earth’s rising average temperature, while climate change refers to changes in weather patterns and growing seasons around the world. Global warming causes climate change, which poses a serious threat to life on Earth.

Humans are feeling the impact of global warming around the world as climate change brings intense droughts, wildfires and extreme storms with heavier rainfall. Higher temperatures are altering ecosystems, forcing animals to migrate to cooler places to survive. Scientists predict that, if nothing is done to lower global temperatures, many species will go extinct.

The ocean is also warming, and glaciers, ice caps and ice sheets are melting. This is causing sea levels to rise, creating flooding problems for many people who live on islands and in coastal communities.

Corals have been a symbol of the consequences of a warmer ocean. Many coral reefs—home to thousands of species of fish and other organisms—are dying. National Geographic Explorer Shireen Rahimi is an underwater storyteller who focuses her lens on the impact of global warming on tropical coral reefs. Her images capture humans’ relationships to the changing seas in the South Pacific, the Coral Triangle, and the Caribbean. Rahimi is dedicated to telling personal stories that encourage environmental action.

Countries around the world are trying to lower greenhouse gas emissions to slow global warming. In twothousandfifteen, nearly twohundred countries signed the Paris Agreement at a United Nations Climate Change conference. The international treaty tasks each country with lowering greenhouse gas emissions. The goal is to slow the pace of global warming and prevent Earth’s temperature from rising two°C (three°F) above pre-industrial temperatures.

The principal causes are the widespread burning of fossil fuels including coal, oil and gas for electricity, heating, cooling and transportation, leading to the emission of carbon dioxide and other greenhouse gases. Unable to escape into space, these gases become trapped in the atmosphere, causing the planet to gradually warm over many decades. This then has an effect on climatic patterns, leading to long-term climate change that brings more storms, floods, droughts, forest fires and more extreme temperatures. Melting ice caps bring rising sea levels that threaten coastal cities, while greenhouse gas that are absorbed by oceans make them more acidic, threatening coral and marine life.
image.png
Source: NASA
The Paris Agreement seeks to limit global warming to below 2 degrees Celsius above pre-industrial levels by the end of this century, and to pursue efforts to limit it to 1.5 degrees. According to a report issued in October 2018 by the International Panel on Climate Change (IPCC), the Earth has already warmed by between 0.8 degrees and 1.2 degrees since 1750, with a consensus of an average of 1.0 degrees of warming. Limiting total warming to 1.5 degrees – i.e. allowing another 0.5 degrees of warming – requires the world to become effectively carbon-neutral by 2050.

Evidence of rising temperatures can be seen in that 10 of the warmest years in recorded history have occurred since 2005, according to the US-based National Oceanic and Atmospheric Administration. The hottest was in 2016, when the Earth’s atmosphere was on average 0.94 degrees warmer than the global mean since 1880. In 2019, several nations set new record national temperatures during summer heatwaves that exceeded 40 degrees in Europe. The records were broken in 29 countries for the period from 1 May to 30 August in 2019, according to the California-based climate institute Berkeley Earth. Its research shows that over the summer, there were 1,200 instances of places in the northern hemisphere that were the hottest they'd ever been in a given month.

Human-induced warming reached approximately 1°C (likely between 0.8°C and 1.2°C) above pre-industrial levels in 2017, increasing at 0.2°C (likely between 0.1°C and 0.3°C) per decade (high confidence). Global warming is defined in this report as an increase in combined surface air and sea surface temperatures averaged over the globe and over a 30-year period. Unless otherwise specified, warming is expressed relative to the period 1850–1900, used as an approximation of pre-industrial temperatures in AR5. For periods shorter than 30 years, warming refers to the estimated average temperature over the 30 years centred on that shorter period, accounting for the impact of any temperature fluctuations or trend within those 30 years. Accordingly, warming from pre- industrial levels to the decade 2006–2015 is assessed to be 0.87°C (likely between 0.75°C and 0.99°C). Since 2000, the estimated level of human-induced warming has been equal to the level of observed warming with a likely range of ±20% accounting for uncertainty due to contributions from solar and volcanic activity over the historical period (high confidence). {1.2.1}

Warming greater than the global average has already been experienced in many regions and seasons, with higher average warming over land than over the ocean (high confidence). Most land regions are experiencing greater warming than the global average, while most ocean regions are warming at a slower rate. Depending on the temperature dataset considered, 20–40% of the global human population live in regions that, by the decade 2006–2015, had already experienced warming of more than 1.5°C above pre-industrial in at least one season (medium confidence). {1.2.1, 1.2.2}

Past emissions alone are unlikely to raise global-mean temperature to 1.5°C above pre-industrial levels (medium confidence), but past emissions do commit to other changes, such as further sea level rise (high confidence). If all anthropogenic emissions (including aerosol-related) were reduced to zero immediately, any further warming beyond the 1°C already experienced would likely be less than 0.5°C over the next two to three decades (high confidence), and likely less than 0.5°C on a century time scale (medium confidence), due to the opposing effects of different climate processes and drivers. A warming greater than 1.5°C is therefore not geophysically unavoidable: whether it will occur depends on future rates of emission reductions. {1.2.3, 1.2.4}

1.5°C emission pathways are defined as those that, given current knowledge of the climate response, provide a one- in-two to two-in-three chance of warming either remaining below 1.5°C or returning to 1.5°C by around 2100 following an overshoot. Overshoot pathways are characterized by the peak magnitude of the overshoot, which may have implications for impacts. All 1.5°C pathways involve limiting cumulative emissions of long-lived greenhouse gases, including carbon dioxide and nitrous oxide, and substantial reductions in other climate forcers (high confidence). Limiting cumulative emissions requires either reducing net global emissions of long-lived greenhouse gases to zero before the cumulative limit is reached, or net negative global emissions (anthropogenic removals) after the limit is exceeded. {1.2.3, 1.2.4, Cross-Chapter Boxes 1 and 2}

This report assesses projected impacts at a global average warming of 1.5°C and higher levels of warming. Global warming of 1.5°C is associated with global average surface temperatures fluctuating naturally on either side of 1.5°C, together with warming substantially greater than 1.5°C in many regions and seasons (high confidence), all of which must be considered in the assessment of impacts. Impacts at 1.5°C of warming also depend on the emission pathway to 1.5°C. Very different impacts result from pathways that remain below 1.5°C versus pathways that return to 1.5°C after a substantial overshoot, and when temperatures stabilize at 1.5°C versus a transient warming past 1.5°C (medium confidence). {1.2.3, 1.3}

Ethical considerations, and the principle of equity in particular, are central to this report, recognizing that many of the impacts of warming up to and beyond 1.5°C, and some potential impacts of mitigation actions required to limit warming to 1.5°C, fall disproportionately on the poor and vulnerable (high confidence). Equity has procedural and distributive dimensions and requires fairness in burden sharing both between generations and between and within nations. In framing the objective of holding the increase in the global average temperature rise to well below 2°C above pre-industrial levels, and to pursue efforts to limit warming to 1.5°C, the Paris Agreement associates the principle of equity with the broader goals of poverty eradication and sustainable development, recognising that effective responses to climate change require a global collective effort that may be guided by the 2015 United Nations Sustainable Development Goals. {1.1.1}

Climate adaptation refers to the actions taken to manage impacts of climate change by reducing vulnerability and exposure to its harmful effects and exploiting any potential benefits. Adaptation takes place at international, national and local levels. Subnational jurisdictions and entities, including urban and rural municipalities, are key to developing and reinforcing measures for reducing weather- and climate-related risks. Adaptation implementation faces several barriers including lack of up-to-date and locally relevant information, lack of finance and technology, social values and attitudes, and institutional constraints (high confidence). Adaptation is more likely to contribute to sustainable development when policies align with mitigation and poverty eradication goals (medium confidence). {1.1, 1.4}

Ambitious mitigation actions are indispensable to limit warming to 1.5°C while achieving sustainable development and poverty eradication (high confidence). Ill-designed responses, however, could pose challenges especially – but not exclusively – for countries and regions contending with poverty and those requiring significant transformation of their energy systems. This report focuses on ‘climate-resilient development pathways’, which aim to meet the goals of sustainable development, including climate adaptation and mitigation, poverty eradication and reducing inequalities. But any feasible pathway that remains within 1.5°C involves synergies and trade-offs (high confidence). Significant uncertainty remains as to which pathways are more consistent with the principle of equity.
{1.1.1, 1.4}

Multiple forms of knowledge, including scientific evidence, narrative scenarios and prospective pathways, inform the understanding of 1.5°C. This report is informed by traditional evidence of the physical climate system and associated impacts and vulnerabilities of climate change, together with knowledge drawn from the perceptions of risk and the experiences of climate impacts and governance systems. Scenarios and pathways are used to explore conditions enabling goal-oriented futures while recognizing the significance of ethical considerations, the principle of equity, and the societal transformation needed. {1.2.3, 1.5.2}

There is no single answer to the question of whether it is feasible to limit warming to 1.5°C and adapt to the consequences. Feasibility is considered in this report as the capacity of a system as a whole to achieve a specific outcome. The global transformation that would be needed to limit warming to 1.5°C requires enabling conditions that reflect the links, synergies and trade-offs between mitigation, adaptation and sustainable development. These enabling conditions are assessed across many dimensions of feasibility – geophysical, environmental-ecological, technological, economic, socio-cultural and institutional – that may be considered through the unifying lens of the Anthropocene, acknowledging profound, differential but increasingly geologically significant human influences on the Earth system as a whole. This framing also emphasises the global interconnectivity of past, present and future human–environment relations, highlighting the need and opportunities for integrated responses to achieve the goals of the Paris Agreement. {1.1, Cross-Chapter Box 1}

The human fingerprint on global warming was likely evident in Earth’s atmosphere far earlier than previously thought—even before the invention of modern cars, a new study says.

Using a combination of scientific theory, modern observations and multiple, sophisticated computer models, researchers found a clear signal of human-caused climate change was likely discernible with high confidence as early as 1885, just before the advent of gas-powered cars but after the dawn of the industrial revolution.

The findings, detailed in a paper published Monday in the journal Proceedings of the National Academy of Sciences, raise the likelihood that humanity has been remaking the planet’s climate in a detectable way for longer than previously believed—and highlight the importance of tracking changes in the upper atmosphere.

Scientists had begun to record surface temperature observations by the mid-19th century. The start date for a detectable human signal in surface temperatures has generally been thought to be in the early-to-mid-20th century, though other parts of the climate system showed signs of change at different times.

For this study, the veteran climate researchers posed the question: With the observational tools of today, when is the earliest that the signs of human-caused climate change would have been detectable in the atmosphere?

The study looked specifically at signals in the stratosphere – the second level of the atmosphere. Most weather occurs in the lowest level, the troposphere. While greenhouse gas emissions warm the lower atmosphere, they exert the opposite effect on the stratosphere, particularly its upper regions.


Researchers used this knowledge to examine climate models looking back in time for signs of these effects.

The findings surprised lead author Ben Santer and co-author Susan Solomon, who did not expect to find such a clear human signal in the upper atmosphere so early in the climate record.

“It was surprising, really surprising to me the answer that we could have identified with high confidence a human-caused stratospheric cooling signal within 25 years of the start of monitoring, if we had back then in 1860 the measuring capability that we have today,” Santer, of the Woods Hole Oceanographic Institution, said.

The signal of climate change was detectable in the 19th-century atmosphere after just a 10 parts per million increase in carbon dioxide concentrations in the 40 years between 1860 and 1899. For comparison, planet-warming carbon dioxide levels skyrocketed by about 50 parts per million between 2000 and 2025, Santer said.


Overall, carbon dioxide levels in the atmosphere have increased by about 140 parts per million since the initially detectible point the scientists pinpointed.

“The results show it would have been detectable very quickly,” said Gabi Hegerl of the University of Edinburgh, who was not involved with the new paper. “This highlights the strong influence that greenhouse gas increases have on the upper atmosphere compared to the variability there.”

Andrea Steiner, a climate scientist at the Wegener Center for Climate and Global Change at the University of Graz in Austria, told CNN the study shows human-caused climate change can be detected earlier in the atmosphere than at the surface.

“This confirms that temperature change signals of the atmosphere are effective not only for detection, but also as early indicators of the success of climate mitigation efforts,” she said. Steiner was not involved in the new study.

Continued observations are key
Both Santer and Solomon emphasized the results show the importance of continuing to closely monitor the upper atmosphere.


That message comes at a time of steep scientific budget cuts, when crucial climate satellites and research programs are being targeted. This is particularly the case in the NOAA, NASA and Department of Energy budget proposals, Santer noted.

The NOAA budget proposal, for example, would eliminate the air and oceans agency’s research division, which includes carbon dioxide monitoring functions. In addition, the Trump administration’s NASA budget proposal would cut some climate-relevant satellite missions, while stripping future NOAA satellites of climate science sensors.

“I do think it’s important for non-scientists to know what’s at stake here. That when we lose the capability to measure and monitor how our world is changing, it makes us all less safe,” Santer said.

According to the annual report from NOAA National Centers for Environmental Information, 2024 was the warmest year since global records began in 1850. The global average surface temperature was 2.32 Fahrenheit (1.29 degrees Celsius) above the 20th-century average (57.0 degrees Fahrenheit, or 13.9 degrees Celsius) and 2.63 degrees Fahrenheit (1.46 degrees Celsius) above the pre-industrial average (56.7 degrees Fahrenheit, or 13.7 degrees Celsius), which NOAA defines as the period from 1850-1900.

Global map of temperature anomalies and animated bar chart of yearly anomalies from 1976-2024
Global temperatures in 2024 were above the 1991-2020 average (red) across most of the planet. Yearly temperatures compared to the 20th-century average (bar chart) show that it has been 48 years since Earth had a cooler-than-average year. NOAA Climate.gov image, based on data from NOAA National Centers for Environmental Information.
The 2024 global temperature anomaly (anomaly means “difference from average”) is 0.18 degrees F (0.10 degrees C) warmer than the previous record, set the year before, in 2023. The ten warmest years in the 175-year record have all occurred during the last decade (2015–2024). When the new century started in 2000, the first year to set a new high-temperature record was 2005. Now, 2005 is just the 13th-warmest year on record.

Other 2024 rankings included...

warmest year on record for both the Northern and Southern Hemispheres individually,
warmest year on record for land and ocean areas individually,
upper ocean heat content was highest on record.
For more regional details and 2024 climate statistics, see the 2024 Global Climate Report from NOAA's National Centers for Environmental Information.

Why global surface temperature matters

The global average surface temperature is an indicator of the state of Earth’s energy balance: how much sunlight it absorbs minus how much heat it radiates back to space. When these amounts are the same, Earth’s average surface temperature remains steady. When they are out of balance, Earth cools or warms. Earth’s average surface temperature has been rising because human-produced greenhouse gases are causing Earth to absorb more energy than it radiates back to space.

Given the tremendous size and heat capacity of the global oceans, it takes a massive amount of added heat energy to raise Earth’s average surface temperature even a small amount. The roughly 2-degree-Fahrenheit (1-degree-Celsius) increase in global average surface temperature that has occurred since the pre-industrial era (1850-1900 in NOAA's record) might seem small, but it represents a significant increase in heat energy circulating through all parts of the Earth system, including the oceans, frozen landscapes, and the atmosphere.

Beyond being an indicator of changes in Earth’s energy balance, surface temperature matters because it controls many environmental and ecological processes that are important to humans and other life, including the water cycle (evaporation, clouds, surface water supplies, and precipitation), the carbon cycle, and the kinds of plants, animals, and other living things that can survive in different places on Earth.

About surface temperature

The concept of an average temperature for the entire globe may seem odd. After all, at this very moment, the highest and lowest temperatures on Earth are likely more than 100 degrees Fahrenheit (55 degrees Celsius) apart. Temperatures vary from night to day and between seasonal extremes in the Northern and Southern Hemispheres. This means that some parts of Earth are quite cold while other parts are downright hot. To speak of the "average" temperature, then, may seem like nonsense. However, the concept of a global average temperature is convenient for detecting and tracking changes in Earth's energy budget, which can only be directly measured from space.

To calculate a global average temperature, scientists begin with temperature measurements taken at locations around the globe. Because their goal is to track changes in temperature, measurements are converted from absolute temperature readings to temperature anomalies—the difference between the observed temperature and the long-term average temperature for each location and date. Multiple independent research groups across the world perform their own analysis of the surface temperature data, and they all show a similar upward trend.

Across inaccessible areas that have few measurements, scientists use surrounding temperatures and known physical relationships—such as the way temperature decreases with altitude—to estimate the missing values. Each value is then used to calculate a global-scale temperature anomaly. This process provides a consistent, reliable method for monitoring changes in Earth's surface temperature over time. Read more about how the global surface temperature record is built in our Climate Data Primer.

Past and future change in global temperature

Temperature change has not been uniform across the planet, but  more areas are warming than cooling. And the rate of warming has accelerated in recent decades. According to NOAA's 2024 Annual Climate Report the combined land and ocean temperature has warmed at an average rate of 0.11 degrees Fahrenheit (0.06 degrees Celsius) per decade since 1850 and more than three times that rate (0.36 degrees Fahrenheit, or 0.20 degrees Celsius) per decade since 1975.

Two global maps comparing temperature trends over the full climate record versus the past 30 years

global warming, the phenomenon of increasing average air temperatures near the surface of Earth over the past one to two centuries. Climate scientists have since the mid-20th century gathered detailed observations of various weather phenomena (such as temperatures, precipitation, and storms) and of related influences on climate (such as ocean currents and the atmosphere’s chemical composition). These data indicate that Earth’s climate has changed over almost every conceivable timescale since the beginning of geologic time and that human activities since at least the beginning of the Industrial Revolution have a growing influence over the pace and extent of present-day climate change.


Giving voice to a growing conviction of most of the scientific community, the Intergovernmental Panel on Climate Change (IPCC) was formed in 1988 by the World Meteorological Organization (WMO) and the United Nations Environment Program (UNEP). The IPCC’s Sixth Assessment Report (AR6), published in 2021, noted that the best estimate of the increase in global average surface temperature between 1850 and 2019 was 1.07 °C (1.9 °F). An IPCC special report produced in 2018 noted that human beings and their activities have been responsible for a worldwide average temperature increase between 0.8 and 1.2 °C (1.4 and 2.2 °F) since preindustrial times, and most of the warming over the second half of the 20th century could be attributed to human activities.



AR6 produced a series of global climate predictions based on modeling five greenhouse gas emission scenarios that accounted for future emissions, mitigation (severity reduction) measures, and uncertainties in the model projections. Some of the main uncertainties include the precise role of feedback processes and the impacts of industrial pollutants known as aerosols, which may offset some warming. The lowest-emissions scenario, which assumed steep cuts in greenhouse gas emissions beginning in 2015, predicted that the global mean surface temperature would increase between 1.0 and 1.8 °C (1.8 and 3.2 °F) by 2100 relative to the 1850–1900 average. This range stood in stark contrast to the highest-emissions scenario, which predicted that the mean surface temperature would rise between 3.3 and 5.7 °C (5.9 and 10.2 °F) by 2100 based on the assumption that greenhouse gas emissions would continue to increase throughout the 21st century. The intermediate-emissions scenario, which assumed that emissions would stabilize by 2050 before declining gradually, projected an increase of between 2.1 and 3.5 °C (3.8 and 6.3 °F) by 2100.



Many climate scientists agree that significant societal, economic, and ecological damage would result if the global average temperature rose by more than 2 °C (3.6 °F) in such a short time. Such damage would include increased extinction of many plant and animal species, shifts in patterns of agriculture, and rising sea levels. By 2015 all but a few national governments had begun the process of instituting carbon reduction plans as part of the Paris Agreement, a treaty designed to help countries keep global warming to 1.5 °C (2.7 °F) above preindustrial levels in order to avoid the worst of the predicted effects. Whereas authors of the 2018 special report noted that should carbon emissions continue at their present rate, the increase in average near-surface air temperature would reach 1.5 °C sometime between 2030 and 2052, authors of the AR6 report suggested that this threshold would be reached by 2041 at the latest. In an ominous sign that the long-term temperature threshold of 1.5 °C could arrive far sooner than expected, global climate monitoring databases reported that the global temperature average for the year 2024 was 1.6 °C above preindustrial levels.



The AR6 report also noted that the global average sea level had risen by some 20 cm (7.9 inches) between 1901 and 2018 and that sea level rose faster in the second half of the 20th century than in the first half. It also predicted, again depending on a wide range of scenarios, that the global average sea level would rise by different amounts by 2100 relative to the 1995–2014 average. Under the report’s lowest-emission scenario, sea level would rise by 28–55 cm (11–21.7 inches), whereas, under the intermediate emissions scenario, sea level would rise by 44–76 cm (17.3–29.9 inches). The highest-emissions scenario suggested that sea level would rise by 63–101 cm (24.8–39.8 inches) by 2100.


Combination shot of Grinnell Glacier taken from the summit of Mount Gould, Glacier National Park, Montana in the years 1938, 1981, 1998 and 2006.
Britannica Quiz
Pop Quiz: 18 Things to Know About Global Warming
greenhouse effect on Earth

greenhouse effect on EarthThe greenhouse effect on Earth. Some incoming sunlight is reflected by Earth's atmosphere and surface, but most is absorbed by the surface, which is warmed. Infrared (IR) radiation is then emitted from the surface. Some IR radiation escapes to space, but some is absorbed by the atmosphere's greenhouse gases (especially water vapour, carbon dioxide, and methane) and reradiated in all directions, some to space and some back toward the surface, where it further warms the surface and the lower atmosphere.
(more)
The scenarios referred to above depend mainly on future concentrations of certain trace gases, called greenhouse gases, that have been injected into the lower atmosphere in increasing amounts through the burning of fossil fuels for industry, transportation, and residential uses. Modern global warming is the result of an increase in magnitude of the so-called greenhouse effect, a warming of Earth’s surface and lower atmosphere caused by the presence of water vapour, carbon dioxide, methane, nitrous oxides, and other greenhouse gases. In 2014 the IPCC first reported that concentrations of carbon dioxide, methane, and nitrous oxides in the atmosphere surpassed those found in ice cores dating back 800,000 years.

Of all these gases, carbon dioxide is the most important, both for its role in the greenhouse effect and for its role in the human economy. It has been estimated that, at the beginning of the industrial age in the mid-18th century, carbon dioxide concentrations in the atmosphere were roughly 280 parts per million (ppm). By the end of 2022 they had risen to 419 ppm, and, if fossil fuels continue to be burned at current rates, they are projected to reach 550 ppm by the mid-21st century—essentially, a doubling of carbon dioxide concentrations in 300 years.


What's the problem with an early spring?
What's the problem with an early spring?Is it just me, or did spring come early this year?
See all videos for this article
A vigorous debate is in progress over the extent and seriousness of rising surface temperatures, the effects of past and future warming on human life, and the need for action to reduce future warming and deal with its consequences. This article provides an overview of the scientific background related to the subject of global warming. It considers the causes of rising near-surface air temperatures, the influencing factors, the process of climate research and forecasting, and the possible ecological and social impacts of rising temperatures. For an overview of the public policy developments related to global warming occurring since the mid-20th century, see global warming policy. For a detailed description of Earth’s climate, its processes, and the responses of living things to its changing nature, see climate. For additional background on how Earth’s climate has changed throughout geologic time, see climatic variation and change. For a full description of Earth’s gaseous envelope, within which climate change and global warming occur, see atmosphere.
Climatic variation since the last glaciation

Global warming is related to the more general phenomenon of climate change, which refers to changes in the totality of attributes that define climate. In addition to changes in air temperature, climate change involves changes to precipitation patterns, winds, ocean currents, and other measures of Earth’s climate. Normally, climate change can be viewed as the combination of various natural forces occurring over diverse timescales. Since the advent of human civilization, climate change has involved an “anthropogenic,” or exclusively human-caused, element, and this anthropogenic element has become more important in the industrial period of the past two centuries. The term global warming is used specifically to refer to any warming of near-surface air during the past two centuries that can be traced to anthropogenic causes.

To define the concepts of global warming and climate change properly, it is first necessary to recognize that the climate of Earth has varied across many timescales, ranging from an individual human life span to billions of years. This variable climate history is typically classified in terms of “regimes” or “epochs.” For instance, the Pleistocene glacial epoch (about 2,600,000 to 11,700 years ago) was marked by substantial variations in the global extent of glaciers and ice sheets. These variations took place on timescales of tens to hundreds of millennia and were driven by changes in the distribution of solar radiation across Earth’s surface. The distribution of solar radiation is known as the insolation pattern, and it is strongly affected by the geometry of Earth’s orbit around the Sun and by the orientation, or tilt, of Earth’s axis relative to the direct rays of the Sun.

Worldwide, the most recent glacial period, or ice age, culminated about 21,000 years ago in what is often called the Last Glacial Maximum. During this time, continental ice sheets extended well into the middle latitude regions of Europe and North America, reaching as far south as present-day London and New York City. Global annual mean temperature appears to have been about 4–5 °C (7–9 °F) colder than in the mid-20th century. It is important to remember that these figures are a global average. In fact, during the height of this last ice age, Earth’s climate was characterized by greater cooling at higher latitudes (that is, toward the poles) and relatively little cooling over large parts of the tropical oceans (near the Equator). This glacial interval terminated abruptly about 11,700 years ago and was followed by the subsequent relatively ice-free period known as the Holocene Epoch. The modern period of Earth’s history is conventionally defined as residing within the Holocene. However, some scientists have argued that the Holocene Epoch terminated in the relatively recent past and that Earth currently resides in a climatic interval that could justly be called the Anthropocene Epoch—that is, a period during which humans have exerted a dominant influence over climate.

Though less dramatic than the climate changes that occurred during the Pleistocene Epoch, significant variations in global climate have nonetheless taken place over the course of the Holocene. During the early Holocene, roughly 9,000 years ago, atmospheric circulation and precipitation patterns appear to have been substantially different from those of today. For example, there is evidence for relatively wet conditions in what is now the Sahara Desert. The change from one climatic regime to another was caused by only modest changes in the pattern of insolation within the Holocene interval as well as the interaction of these patterns with large-scale climate phenomena such as monsoons and El Niño/Southern Oscillation (ENSO).

During the middle Holocene, some 5,000–7,000 years ago, conditions appear to have been relatively warm—indeed, perhaps warmer than today in some parts of the world and during certain seasons. For this reason, this interval is sometimes referred to as the Mid-Holocene Climatic Optimum. The relative warmth of average near-surface air temperatures at this time, however, is somewhat unclear. Changes in the pattern of insolation favoured warmer summers at higher latitudes in the Northern Hemisphere, but these changes also produced cooler winters in the Northern Hemisphere and relatively cool conditions year-round in the tropics. Any overall hemispheric or global mean temperature changes thus reflected a balance between competing seasonal and regional changes. In fact, recent theoretical climate model studies suggest that global mean temperatures during the middle Holocene were probably 0.2–0.3 °C (0.4–0.5 °F) colder than average late 20th-century conditions.

Over subsequent millennia, conditions appear to have cooled relative to middle Holocene levels. This period has sometimes been referred to as the “Neoglacial.” In the middle latitudes this cooling trend was associated with intermittent periods of advancing and retreating mountain glaciers reminiscent of (though far more modest than) the more substantial advance and retreat of the major continental ice sheets of the Pleistocene climate epoch.
Causes of global warming

The greenhouse effect

The average surface temperature of Earth is maintained by a balance of various forms of solar and terrestrial radiation. Solar radiation is often called “shortwave” radiation because the frequencies of the radiation are relatively high and the wavelengths relatively short—close to the visible portion of the electromagnetic spectrum. Terrestrial radiation, on the other hand, is often called “longwave” radiation because the frequencies are relatively low and the wavelengths relatively long—somewhere in the infrared part of the spectrum. Downward-moving solar energy is typically measured in watts per square metre. The energy of the total incoming solar radiation at the top of Earth’s atmosphere (the so-called “solar constant”) amounts roughly to 1,366 watts per square metre annually. Adjusting for the fact that only one-half of the planet’s surface receives solar radiation at any given time, the average surface insolation is 342 watts per square metre annually.

The amount of solar radiation absorbed by Earth’s surface is only a small fraction of the total solar radiation entering the atmosphere. For every 100 units of incoming solar radiation, roughly 30 units are reflected back to space by either clouds, the atmosphere, or reflective regions of Earth’s surface. This reflective capacity is referred to as Earth’s planetary albedo, and it need not remain fixed over time, since the spatial extent and distribution of reflective formations, such as clouds and ice cover, can change. The 70 units of solar radiation that are not reflected may be absorbed by the atmosphere, clouds, or the surface. In the absence of further complications, in order to maintain thermodynamic equilibrium, Earth’s surface and atmosphere must radiate these same 70 units back to space. Earth’s surface temperature (and that of the lower layer of the atmosphere essentially in contact with the surface) is tied to the magnitude of this emission of outgoing radiation according to the Stefan-Boltzmann law.

Earth’s energy budget is further complicated by the greenhouse effect. Trace gases with certain chemical properties—the so-called greenhouse gases, mainly carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O)—absorb some of the infrared radiation produced by Earth’s surface. Because of this absorption, some fraction of the original 70 units does not directly escape to space. Because greenhouse gases emit the same amount of radiation they absorb and because this radiation is emitted equally in all directions (that is, as much downward as upward), the net effect of absorption by greenhouse gases is to increase the total amount of radiation emitted downward toward Earth’s surface and lower atmosphere. To maintain equilibrium, Earth’s surface and lower atmosphere must emit more radiation than the original 70 units. Consequently, the surface temperature must be higher. This process is not quite the same as that which governs a true greenhouse, but the end effect is similar. The presence of greenhouse gases in the atmosphere leads to a warming of the surface and lower part of the atmosphere (and a cooling higher up in the atmosphere) relative to what would be expected in the absence of greenhouse gases.

It is essential to distinguish the “natural,” or background, greenhouse effect from the “enhanced” greenhouse effect associated with human activity. The natural greenhouse effect is associated with surface warming properties of natural constituents of Earth’s atmosphere, especially water vapour, carbon dioxide, and methane. The existence of this effect is accepted by all scientists. Indeed, in its absence, Earth’s average temperature would be approximately 33 °C (59 °F) colder than today, and Earth would be a frozen and likely uninhabitable planet. What has been subject to controversy is the so-called enhanced greenhouse effect, which is associated with increased concentrations of greenhouse gases caused by human activity. In particular, the burning of fossil fuels raises the concentrations of the major greenhouse gases in the atmosphere, and these higher concentrations have the potential to warm the atmosphere by several degrees.

Radiative forcing

global mean radiative forcings since 1750

global mean radiative forcings since 1750Since 1750 the concentration of carbon dioxide and other greenhouse gases has increased in Earth's atmosphere. As a result of these and other factors, Earth's atmosphere retains more heat than in the past.
(more)
In light of the discussion above of the greenhouse effect, it is apparent that the temperature of Earth’s surface and lower atmosphere may be modified in three ways: (1) through a net increase in the solar radiation entering at the top of Earth’s atmosphere, (2) through a change in the fraction of the radiation reaching the surface, and (3) through a change in the concentration of greenhouse gases in the atmosphere. In each case the changes can be thought of in terms of “radiative forcing.” As defined by the IPCC, radiative forcing is a measure of the influence a given climatic factor has on the amount of downward-directed radiant energy impinging upon Earth’s surface. Climatic factors are divided between those caused primarily by human activity (such as greenhouse gas emissions and aerosol emissions) and those caused by natural forces (such as solar irradiance); then, for each factor, so-called forcing values are calculated for the time period between 1750 and the present day. “Positive forcing” is exerted by climatic factors that contribute to the warming of Earth’s surface, whereas “negative forcing” is exerted by factors that cool Earth’s surface.


On average, about 342 watts of solar radiation strike each square metre of Earth’s surface, and this quantity can in turn be related to a rise or fall in Earth’s surface temperature. Temperatures at the surface may also rise or fall through a change in the distribution of terrestrial radiation (that is, radiation emitted by Earth) within the atmosphere. In some cases, radiative forcing has a natural origin, such as during explosive eruptions from volcanoes where vented gases and ash block some portion of solar radiation from the surface. In other cases, radiative forcing has an anthropogenic, or exclusively human, origin. For example, anthropogenic increases in carbon dioxide, methane, nitrous oxide, halogenated gases, and other factors are estimated to account for 2.72 watts per square metre of positive radiative forcing, relative to estimated 1750 benchmark values. When all values of positive and negative radiative forcing are taken together and all interactions between climatic factors are accounted for, the total net increase in surface radiation due to human activities since the beginning of the Industrial Revolution is 1.6 watts per square metre.
The influences of human activity on climate

carbon dioxide emissions
1 of 3
carbon dioxide emissionsMap of annual carbon dioxide emissions by country in 2014.
petroleum refinery
2 of 3
petroleum refineryPetroleum refinery at Ras Tanura, Saudi Arabia.
natural gas facility
3 of 3
natural gas facilityNatural gas facility near Kursk, Russia.


Human activity has influenced global surface temperatures by changing the radiative balance governing the Earth on various timescales and at varying spatial scales. The most profound and well-known anthropogenic influence is the elevation of concentrations of greenhouse gases in the atmosphere. Humans also influence climate by changing the concentrations of aerosols and ozone and by modifying the land cover of Earth’s surface.
Greenhouse gases

greenhouse gas emissions

greenhouse gas emissionsFactories that burn fossil fuels help to cause global warming.
As discussed above, greenhouse gases warm Earth’s surface by increasing the net downward longwave radiation reaching the surface. The relationship between atmospheric concentration of greenhouse gases and the associated positive radiative forcing of the surface is different for each gas. A complicated relationship exists between the chemical properties of each greenhouse gas and the relative amount of longwave radiation that each can absorb. What follows is a discussion of the radiative behaviour of each major greenhouse gas.
Water vapour

surface hydrologic cycle

surface hydrologic cycleThe present-day surface hydrologic cycle, in which water is transferred from the oceans through the atmosphere to the continents and back to the oceans over and beneath the land surface. The values in parentheses following the various forms of water (e.g., ice) refer to volumes in millions of cubic kilometres; those following the processes (e.g., precipitation) refer to their fluxes in millions of cubic kilometres of water per year.

Water vapour is the most potent of the greenhouse gases in Earth’s atmosphere, but its behaviour is fundamentally different from that of the other greenhouse gases. The primary role of water vapour is not as a direct agent of radiative forcing but rather as a climate feedback—that is, as a response within the climate system that influences the system’s continued activity (see below Water vapour feedback). This distinction arises from the fact that the amount of water vapour in the atmosphere cannot, in general, be directly modified by human behaviour but is instead set by air temperatures. The warmer the surface, the greater the evaporation rate of water from the surface. As a result, increased evaporation leads to a greater concentration of water vapour in the lower atmosphere capable of absorbing longwave radiation and emitting it downward.

Click here to search

Login
 Ask the Chatbot Games & Quizzes History & Society Science & Tech Biographies Animals & Nature Geography & Travel Arts & Culture ProCon Money Videos


You have reached Britannica's public website.
Click here for ad-free access to your Britannica School or Library account.

Contents
Ask the Chatbot a Question
Science
Earth Science, Geologic Time & Fossils
Earth Sciences
 Grinnell Glacier shrinkage

Grinnell Glacier shrinkage A series of photographs of the Grinnell Glacier taken from the summit of Mount Gould in Glacier National Park, Montana, in (from left) 1938, 1981, 1998, and 2006. In 1938 the Grinnell Glacier filled the entire area at the bottom of the image. By 2006 it had largely disappeared from this view.
(more)
global warming

Earth science
Ask the Chatbot a Question

More Actions
Written by
Michael E. Mann
Fact-checked by
The Editors of Encyclopaedia Britannica
Last Updated: Jun 15, 2025 • Article History
 Table of Contents
Key People:  Klaus Hasselmann Tim Flannery Roger Angel
Related Topics:  ocean warming global cooling air temperature anthropogenic climate change environmental change
(Show more)
On the Web:  National Center for Biotechnology Information - PubMed Central - Global warming and effects on the arctic fox (PDF) (June 04, 2025)
(Show more)
See all related content
Top Questions
How does global warming work?
Where does global warming occur in the atmosphere?
Why is global warming a social problem?

News • Emperor penguin populations shrink by almost a quarter, researchers say • June 10, 2025, 5:19 AM ET (ABC News (Australia))
global warming, the phenomenon of increasing average air temperatures near the surface of Earth over the past one to two centuries. Climate scientists have since the mid-20th century gathered detailed observations of various weather phenomena (such as temperatures, precipitation, and storms) and of related influences on climate (such as ocean currents and the atmosphere’s chemical composition). These data indicate that Earth’s climate has changed over almost every conceivable timescale since the beginning of geologic time and that human activities since at least the beginning of the Industrial Revolution have a growing influence over the pace and extent of present-day climate change.


Giving voice to a growing conviction of most of the scientific community, the Intergovernmental Panel on Climate Change (IPCC) was formed in 1988 by the World Meteorological Organization (WMO) and the United Nations Environment Program (UNEP). The IPCC’s Sixth Assessment Report (AR6), published in 2021, noted that the best estimate of the increase in global average surface temperature between 1850 and 2019 was 1.07 °C (1.9 °F). An IPCC special report produced in 2018 noted that human beings and their activities have been responsible for a worldwide average temperature increase between 0.8 and 1.2 °C (1.4 and 2.2 °F) since preindustrial times, and most of the warming over the second half of the 20th century could be attributed to human activities.



AR6 produced a series of global climate predictions based on modeling five greenhouse gas emission scenarios that accounted for future emissions, mitigation (severity reduction) measures, and uncertainties in the model projections. Some of the main uncertainties include the precise role of feedback processes and the impacts of industrial pollutants known as aerosols, which may offset some warming. The lowest-emissions scenario, which assumed steep cuts in greenhouse gas emissions beginning in 2015, predicted that the global mean surface temperature would increase between 1.0 and 1.8 °C (1.8 and 3.2 °F) by 2100 relative to the 1850–1900 average. This range stood in stark contrast to the highest-emissions scenario, which predicted that the mean surface temperature would rise between 3.3 and 5.7 °C (5.9 and 10.2 °F) by 2100 based on the assumption that greenhouse gas emissions would continue to increase throughout the 21st century. The intermediate-emissions scenario, which assumed that emissions would stabilize by 2050 before declining gradually, projected an increase of between 2.1 and 3.5 °C (3.8 and 6.3 °F) by 2100.



Many climate scientists agree that significant societal, economic, and ecological damage would result if the global average temperature rose by more than 2 °C (3.6 °F) in such a short time. Such damage would include increased extinction of many plant and animal species, shifts in patterns of agriculture, and rising sea levels. By 2015 all but a few national governments had begun the process of instituting carbon reduction plans as part of the Paris Agreement, a treaty designed to help countries keep global warming to 1.5 °C (2.7 °F) above preindustrial levels in order to avoid the worst of the predicted effects. Whereas authors of the 2018 special report noted that should carbon emissions continue at their present rate, the increase in average near-surface air temperature would reach 1.5 °C sometime between 2030 and 2052, authors of the AR6 report suggested that this threshold would be reached by 2041 at the latest. In an ominous sign that the long-term temperature threshold of 1.5 °C could arrive far sooner than expected, global climate monitoring databases reported that the global temperature average for the year 2024 was 1.6 °C above preindustrial levels.



The AR6 report also noted that the global average sea level had risen by some 20 cm (7.9 inches) between 1901 and 2018 and that sea level rose faster in the second half of the 20th century than in the first half. It also predicted, again depending on a wide range of scenarios, that the global average sea level would rise by different amounts by 2100 relative to the 1995–2014 average. Under the report’s lowest-emission scenario, sea level would rise by 28–55 cm (11–21.7 inches), whereas, under the intermediate emissions scenario, sea level would rise by 44–76 cm (17.3–29.9 inches). The highest-emissions scenario suggested that sea level would rise by 63–101 cm (24.8–39.8 inches) by 2100.


Combination shot of Grinnell Glacier taken from the summit of Mount Gould, Glacier National Park, Montana in the years 1938, 1981, 1998 and 2006.
Britannica Quiz
Pop Quiz: 18 Things to Know About Global Warming
greenhouse effect on Earth

greenhouse effect on EarthThe greenhouse effect on Earth. Some incoming sunlight is reflected by Earth's atmosphere and surface, but most is absorbed by the surface, which is warmed. Infrared (IR) radiation is then emitted from the surface. Some IR radiation escapes to space, but some is absorbed by the atmosphere's greenhouse gases (especially water vapour, carbon dioxide, and methane) and reradiated in all directions, some to space and some back toward the surface, where it further warms the surface and the lower atmosphere.
(more)
The scenarios referred to above depend mainly on future concentrations of certain trace gases, called greenhouse gases, that have been injected into the lower atmosphere in increasing amounts through the burning of fossil fuels for industry, transportation, and residential uses. Modern global warming is the result of an increase in magnitude of the so-called greenhouse effect, a warming of Earth’s surface and lower atmosphere caused by the presence of water vapour, carbon dioxide, methane, nitrous oxides, and other greenhouse gases. In 2014 the IPCC first reported that concentrations of carbon dioxide, methane, and nitrous oxides in the atmosphere surpassed those found in ice cores dating back 800,000 years.

Of all these gases, carbon dioxide is the most important, both for its role in the greenhouse effect and for its role in the human economy. It has been estimated that, at the beginning of the industrial age in the mid-18th century, carbon dioxide concentrations in the atmosphere were roughly 280 parts per million (ppm). By the end of 2022 they had risen to 419 ppm, and, if fossil fuels continue to be burned at current rates, they are projected to reach 550 ppm by the mid-21st century—essentially, a doubling of carbon dioxide concentrations in 300 years.


What's the problem with an early spring?
What's the problem with an early spring?Is it just me, or did spring come early this year?
See all videos for this article
A vigorous debate is in progress over the extent and seriousness of rising surface temperatures, the effects of past and future warming on human life, and the need for action to reduce future warming and deal with its consequences. This article provides an overview of the scientific background related to the subject of global warming. It considers the causes of rising near-surface air temperatures, the influencing factors, the process of climate research and forecasting, and the possible ecological and social impacts of rising temperatures. For an overview of the public policy developments related to global warming occurring since the mid-20th century, see global warming policy. For a detailed description of Earth’s climate, its processes, and the responses of living things to its changing nature, see climate. For additional background on how Earth’s climate has changed throughout geologic time, see climatic variation and change. For a full description of Earth’s gaseous envelope, within which climate change and global warming occur, see atmosphere.
Climatic variation since the last glaciation

Global warming is related to the more general phenomenon of climate change, which refers to changes in the totality of attributes that define climate. In addition to changes in air temperature, climate change involves changes to precipitation patterns, winds, ocean currents, and other measures of Earth’s climate. Normally, climate change can be viewed as the combination of various natural forces occurring over diverse timescales. Since the advent of human civilization, climate change has involved an “anthropogenic,” or exclusively human-caused, element, and this anthropogenic element has become more important in the industrial period of the past two centuries. The term global warming is used specifically to refer to any warming of near-surface air during the past two centuries that can be traced to anthropogenic causes.

To define the concepts of global warming and climate change properly, it is first necessary to recognize that the climate of Earth has varied across many timescales, ranging from an individual human life span to billions of years. This variable climate history is typically classified in terms of “regimes” or “epochs.” For instance, the Pleistocene glacial epoch (about 2,600,000 to 11,700 years ago) was marked by substantial variations in the global extent of glaciers and ice sheets. These variations took place on timescales of tens to hundreds of millennia and were driven by changes in the distribution of solar radiation across Earth’s surface. The distribution of solar radiation is known as the insolation pattern, and it is strongly affected by the geometry of Earth’s orbit around the Sun and by the orientation, or tilt, of Earth’s axis relative to the direct rays of the Sun.

Worldwide, the most recent glacial period, or ice age, culminated about 21,000 years ago in what is often called the Last Glacial Maximum. During this time, continental ice sheets extended well into the middle latitude regions of Europe and North America, reaching as far south as present-day London and New York City. Global annual mean temperature appears to have been about 4–5 °C (7–9 °F) colder than in the mid-20th century. It is important to remember that these figures are a global average. In fact, during the height of this last ice age, Earth’s climate was characterized by greater cooling at higher latitudes (that is, toward the poles) and relatively little cooling over large parts of the tropical oceans (near the Equator). This glacial interval terminated abruptly about 11,700 years ago and was followed by the subsequent relatively ice-free period known as the Holocene Epoch. The modern period of Earth’s history is conventionally defined as residing within the Holocene. However, some scientists have argued that the Holocene Epoch terminated in the relatively recent past and that Earth currently resides in a climatic interval that could justly be called the Anthropocene Epoch—that is, a period during which humans have exerted a dominant influence over climate.

Though less dramatic than the climate changes that occurred during the Pleistocene Epoch, significant variations in global climate have nonetheless taken place over the course of the Holocene. During the early Holocene, roughly 9,000 years ago, atmospheric circulation and precipitation patterns appear to have been substantially different from those of today. For example, there is evidence for relatively wet conditions in what is now the Sahara Desert. The change from one climatic regime to another was caused by only modest changes in the pattern of insolation within the Holocene interval as well as the interaction of these patterns with large-scale climate phenomena such as monsoons and El Niño/Southern Oscillation (ENSO).

During the middle Holocene, some 5,000–7,000 years ago, conditions appear to have been relatively warm—indeed, perhaps warmer than today in some parts of the world and during certain seasons. For this reason, this interval is sometimes referred to as the Mid-Holocene Climatic Optimum. The relative warmth of average near-surface air temperatures at this time, however, is somewhat unclear. Changes in the pattern of insolation favoured warmer summers at higher latitudes in the Northern Hemisphere, but these changes also produced cooler winters in the Northern Hemisphere and relatively cool conditions year-round in the tropics. Any overall hemispheric or global mean temperature changes thus reflected a balance between competing seasonal and regional changes. In fact, recent theoretical climate model studies suggest that global mean temperatures during the middle Holocene were probably 0.2–0.3 °C (0.4–0.5 °F) colder than average late 20th-century conditions.

Over subsequent millennia, conditions appear to have cooled relative to middle Holocene levels. This period has sometimes been referred to as the “Neoglacial.” In the middle latitudes this cooling trend was associated with intermittent periods of advancing and retreating mountain glaciers reminiscent of (though far more modest than) the more substantial advance and retreat of the major continental ice sheets of the Pleistocene climate epoch.
Causes of global warming

The greenhouse effect

The average surface temperature of Earth is maintained by a balance of various forms of solar and terrestrial radiation. Solar radiation is often called “shortwave” radiation because the frequencies of the radiation are relatively high and the wavelengths relatively short—close to the visible portion of the electromagnetic spectrum. Terrestrial radiation, on the other hand, is often called “longwave” radiation because the frequencies are relatively low and the wavelengths relatively long—somewhere in the infrared part of the spectrum. Downward-moving solar energy is typically measured in watts per square metre. The energy of the total incoming solar radiation at the top of Earth’s atmosphere (the so-called “solar constant”) amounts roughly to 1,366 watts per square metre annually. Adjusting for the fact that only one-half of the planet’s surface receives solar radiation at any given time, the average surface insolation is 342 watts per square metre annually.

The amount of solar radiation absorbed by Earth’s surface is only a small fraction of the total solar radiation entering the atmosphere. For every 100 units of incoming solar radiation, roughly 30 units are reflected back to space by either clouds, the atmosphere, or reflective regions of Earth’s surface. This reflective capacity is referred to as Earth’s planetary albedo, and it need not remain fixed over time, since the spatial extent and distribution of reflective formations, such as clouds and ice cover, can change. The 70 units of solar radiation that are not reflected may be absorbed by the atmosphere, clouds, or the surface. In the absence of further complications, in order to maintain thermodynamic equilibrium, Earth’s surface and atmosphere must radiate these same 70 units back to space. Earth’s surface temperature (and that of the lower layer of the atmosphere essentially in contact with the surface) is tied to the magnitude of this emission of outgoing radiation according to the Stefan-Boltzmann law.

Earth’s energy budget is further complicated by the greenhouse effect. Trace gases with certain chemical properties—the so-called greenhouse gases, mainly carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O)—absorb some of the infrared radiation produced by Earth’s surface. Because of this absorption, some fraction of the original 70 units does not directly escape to space. Because greenhouse gases emit the same amount of radiation they absorb and because this radiation is emitted equally in all directions (that is, as much downward as upward), the net effect of absorption by greenhouse gases is to increase the total amount of radiation emitted downward toward Earth’s surface and lower atmosphere. To maintain equilibrium, Earth’s surface and lower atmosphere must emit more radiation than the original 70 units. Consequently, the surface temperature must be higher. This process is not quite the same as that which governs a true greenhouse, but the end effect is similar. The presence of greenhouse gases in the atmosphere leads to a warming of the surface and lower part of the atmosphere (and a cooling higher up in the atmosphere) relative to what would be expected in the absence of greenhouse gases.

It is essential to distinguish the “natural,” or background, greenhouse effect from the “enhanced” greenhouse effect associated with human activity. The natural greenhouse effect is associated with surface warming properties of natural constituents of Earth’s atmosphere, especially water vapour, carbon dioxide, and methane. The existence of this effect is accepted by all scientists. Indeed, in its absence, Earth’s average temperature would be approximately 33 °C (59 °F) colder than today, and Earth would be a frozen and likely uninhabitable planet. What has been subject to controversy is the so-called enhanced greenhouse effect, which is associated with increased concentrations of greenhouse gases caused by human activity. In particular, the burning of fossil fuels raises the concentrations of the major greenhouse gases in the atmosphere, and these higher concentrations have the potential to warm the atmosphere by several degrees.

Radiative forcing

global mean radiative forcings since 1750

global mean radiative forcings since 1750Since 1750 the concentration of carbon dioxide and other greenhouse gases has increased in Earth's atmosphere. As a result of these and other factors, Earth's atmosphere retains more heat than in the past.
(more)
In light of the discussion above of the greenhouse effect, it is apparent that the temperature of Earth’s surface and lower atmosphere may be modified in three ways: (1) through a net increase in the solar radiation entering at the top of Earth’s atmosphere, (2) through a change in the fraction of the radiation reaching the surface, and (3) through a change in the concentration of greenhouse gases in the atmosphere. In each case the changes can be thought of in terms of “radiative forcing.” As defined by the IPCC, radiative forcing is a measure of the influence a given climatic factor has on the amount of downward-directed radiant energy impinging upon Earth’s surface. Climatic factors are divided between those caused primarily by human activity (such as greenhouse gas emissions and aerosol emissions) and those caused by natural forces (such as solar irradiance); then, for each factor, so-called forcing values are calculated for the time period between 1750 and the present day. “Positive forcing” is exerted by climatic factors that contribute to the warming of Earth’s surface, whereas “negative forcing” is exerted by factors that cool Earth’s surface.


On average, about 342 watts of solar radiation strike each square metre of Earth’s surface, and this quantity can in turn be related to a rise or fall in Earth’s surface temperature. Temperatures at the surface may also rise or fall through a change in the distribution of terrestrial radiation (that is, radiation emitted by Earth) within the atmosphere. In some cases, radiative forcing has a natural origin, such as during explosive eruptions from volcanoes where vented gases and ash block some portion of solar radiation from the surface. In other cases, radiative forcing has an anthropogenic, or exclusively human, origin. For example, anthropogenic increases in carbon dioxide, methane, nitrous oxide, halogenated gases, and other factors are estimated to account for 2.72 watts per square metre of positive radiative forcing, relative to estimated 1750 benchmark values. When all values of positive and negative radiative forcing are taken together and all interactions between climatic factors are accounted for, the total net increase in surface radiation due to human activities since the beginning of the Industrial Revolution is 1.6 watts per square metre.
The influences of human activity on climate

carbon dioxide emissions
1 of 3
carbon dioxide emissionsMap of annual carbon dioxide emissions by country in 2014.
petroleum refinery
2 of 3
petroleum refineryPetroleum refinery at Ras Tanura, Saudi Arabia.
natural gas facility
3 of 3
natural gas facilityNatural gas facility near Kursk, Russia.


Human activity has influenced global surface temperatures by changing the radiative balance governing the Earth on various timescales and at varying spatial scales. The most profound and well-known anthropogenic influence is the elevation of concentrations of greenhouse gases in the atmosphere. Humans also influence climate by changing the concentrations of aerosols and ozone and by modifying the land cover of Earth’s surface.
Greenhouse gases

greenhouse gas emissions

greenhouse gas emissionsFactories that burn fossil fuels help to cause global warming.
As discussed above, greenhouse gases warm Earth’s surface by increasing the net downward longwave radiation reaching the surface. The relationship between atmospheric concentration of greenhouse gases and the associated positive radiative forcing of the surface is different for each gas. A complicated relationship exists between the chemical properties of each greenhouse gas and the relative amount of longwave radiation that each can absorb. What follows is a discussion of the radiative behaviour of each major greenhouse gas.
Water vapour

surface hydrologic cycle

surface hydrologic cycleThe present-day surface hydrologic cycle, in which water is transferred from the oceans through the atmosphere to the continents and back to the oceans over and beneath the land surface. The values in parentheses following the various forms of water (e.g., ice) refer to volumes in millions of cubic kilometres; those following the processes (e.g., precipitation) refer to their fluxes in millions of cubic kilometres of water per year.
(more)
Water vapour is the most potent of the greenhouse gases in Earth’s atmosphere, but its behaviour is fundamentally different from that of the other greenhouse gases. The primary role of water vapour is not as a direct agent of radiative forcing but rather as a climate feedback—that is, as a response within the climate system that influences the system’s continued activity (see below Water vapour feedback). This distinction arises from the fact that the amount of water vapour in the atmosphere cannot, in general, be directly modified by human behaviour but is instead set by air temperatures. The warmer the surface, the greater the evaporation rate of water from the surface. As a result, increased evaporation leads to a greater concentration of water vapour in the lower atmosphere capable of absorbing longwave radiation and emitting it downward.
High-oblique view of the extra-tropical unnamed cyclone that merged with Hurricane Earl is featured in this image taken by an Expedition 24 crew member on the International Space Station (Sept. 2010).
More From Britannica
Is the Number of Hurricanes Increasing?

Carbon dioxide

carbon cycle

carbon cycleCarbon is transported in various forms through the atmosphere, the hydrosphere, and geologic formations. One of the primary pathways for the exchange of carbon dioxide (CO2) takes place between the atmosphere and the oceans; there a fraction of the CO2 combines with water, forming carbonic acid (H2CO3) that subsequently loses hydrogen ions (H+) to form bicarbonate (HCO3−) and carbonate (CO32−) ions. Mollusk shells or mineral precipitates that form by the reaction of calcium or other metal ions with carbonate may become buried in geologic strata and eventually release CO2 through volcanic outgassing. Carbon dioxide also exchanges through photosynthesis in plants and through respiration in animals. Dead and decaying organic matter may ferment and release CO2 or methane (CH4) or may be incorporated into sedimentary rock, where it is converted to fossil fuels. Burning of hydrocarbon fuels returns CO2 and water (H2O) to the atmosphere. The biological and anthropogenic pathways are much faster than the geochemical pathways and, consequently, have a greater impact on the composition and temperature of the atmosphere.
(more)

Awareness and a partial understanding of most of the
interactive processes in the Earth system that govern climate
and climate change predate the IPCC, often by many decades. A
deeper understanding and quantifi cation of these processes and
their incorporation in climate models have progressed rapidly
since the IPCC First Assessment Report in 1990.
As climate science and the Earth’s climate have continued
to evolve over recent decades, increasing evidence of
anthropogenic infl uences on climate change has been found.
Correspondingly, the IPCC has made increasingly more
defi nitive statements about human impacts on climate.
Debate has stimulated a wide variety of climate change
research. The results of this research have refi ned but not
signifi cantly redirected the main scientifi c conclusions from the
sequence of IPCC assessments.
1.1 Overview of the Chapter
To better understand the science assessed in this Fourth
Assessment Report (AR4), it is helpful to review the long
historical perspective that has led to the current state of
climate change knowledge. This chapter starts by describing
the fundamental nature of earth science. It then describes the
history of climate change science using a wide-ranging subset
of examples, and ends with a history of the IPCC.
The concept of this chapter is new. There is no counterpart in
previous IPCC assessment reports for an introductory chapter
providing historical context for the remainder of the report.
Here, a restricted set of topics has been selected to illustrate
key accomplishments and challenges in climate change science.
The topics have been chosen for their signifi cance to the IPCC
task of assessing information relevant for understanding the
risks of human-induced climate change, and also to illustrate
the complex and uneven pace of scientifi c progress.
In this chapter, the time frame under consideration stops with
the publication of the Third Assessment Report (TAR; IPCC,
2001a). Developments subsequent to the TAR are described in
the other chapters of this report, and we refer to these chapters
throughout this fi rst chapter.
1.2 The Nature of Earth Science
Science may be stimulated by argument and debate, but it
generally advances through formulating hypotheses clearly and
testing them objectively. This testing is the key to science. In
fact, one philosopher of science insisted that to be genuinely
scientifi c, a statement must be susceptible to testing that could
potentially show it to be false (Popper, 1934). In practice,
contemporary scientists usually submit their research fi ndings
to the scrutiny of their peers, which includes disclosing the
methods that they use, so their results can be checked through
replication by other scientists. The insights and research results
of individual scientists, even scientists of unquestioned genius,
are thus confi rmed or rejected in the peer-reviewed literature
by the combined efforts of many other scientists. It is not the
belief or opinion of the scientists that is important, but rather
the results of this testing. Indeed, when Albert Einstein was
informed of the publication of a book entitled 100 Authors
Against Einstein, he is said to have remarked, ‘If I were wrong,
then one would have been enough!’ (Hawking, 1988); however,
that one opposing scientist would have needed proof in the form
of testable results.
Thus science is inherently self-correcting; incorrect or
incomplete scientifi c concepts ultimately do not survive repeated
testing against observations of nature. Scientifi c theories are
ways of explaining phenomena and providing insights that
can be evaluated by comparison with physical reality. Each
successful prediction adds to the weight of evidence supporting
the theory, and any unsuccessful prediction demonstrates that
the underlying theory is imperfect and requires improvement or
abandonment. Sometimes, only certain kinds of questions tend
to be asked about a scientifi c phenomenon until contradictions
build to a point where a sudden change of paradigm takes
place (Kuhn, 1996). At that point, an entire fi eld can be rapidly
reconstructed under the new paradigm.
Despite occasional major paradigm shifts, the majority of
scientifi c insights, even unexpected insights, tend to emerge
incrementally as a result of repeated attempts to test hypotheses
as thoroughly as possible. Therefore, because almost every new
advance is based on the research and understanding that has
gone before, science is cumulative, with useful features retained
and non-useful features abandoned. Active research scientists,
throughout their careers, typically spend large fractions of their
working time studying in depth what other scientists have done.
Superfi cial or amateurish acquaintance with the current state of
a scientifi c research topic is an obstacle to a scientist’s progress.
Working scientists know that a day in the library can save a year
in the laboratory. Even Sir Isaac Newton (1675) wrote that if he
had ‘seen further it is by standing on the shoulders of giants’.
Intellectual honesty and professional ethics call for scientists to
acknowledge the work of predecessors and colleagues.
The attributes of science briefl y described here can be used
in assessing competing assertions about climate change. Can
the statement under consideration, in principle, be proven false?
Has it been rigorously tested? Did it appear in the peer-reviewed
literature? Did it build on the existing research record where
appropriate? If the answer to any of these questions is no, then
less credence should be given to the assertion until it is tested
and independently verifi ed. The IPCC assesses the scientifi c
literature to create a report based on the best available science
(Section 1.6). It must be acknowledged, however, that the IPCC
also contributes to science by identifying the key uncertainties
and by stimulating and coordinating targeted research to answer
important climate change questions.
95
Historical Overview of Climate Change Science Chapter 1
Frequently Asked Question 1.1
What Factors Determine Earth’s Climate?
The climate system is a complex, interactive system consisting
of the atmosphere, land surface, snow and ice, oceans and other
bodies of water, and living things. The atmospheric component of
the climate system most obviously characterises climate; climate
is often defi ned as ‘average weather’. Climate is usually described
in terms of the mean and variability of temperature, precipitation
and wind over a period of time, ranging from months to millions
of years (the classical period is 30 years). The climate system
evolves in time under the infl uence of its own internal dynamics
and due to changes in external factors that affect climate (called
‘forcings’). External forcings include natural phenomena such as
volcanic eruptions and solar variations, as well as human-induced
changes in atmospheric composition. Solar radiation powers the
climate system. There are three fundamental ways to change the
radiation balance of the Earth: 1) by changing the incoming solar
radiation (e.g., by changes in Earth’s orbit or in the Sun itself); 2)
by changing the fraction of solar radiation that is refl ected (called
‘albedo’; e.g., by changes in cloud cover, atmospheric particles or
vegetation); and 3) by altering the longwave radiation from Earth
back towards space (e.g., by changing greenhouse gas concentra-
tions). Climate, in turn, responds directly to such changes, as well
as indirectly, through a variety of feedback mechanisms.
The amount of energy reaching the top of Earth’s atmosphere
each second on a surface area of one square metre facing the
Sun during daytime is about 1,370 Watts, and the amount of en-
ergy per square metre per second averaged over the entire planet
is one-quarter of this (see Figure 1). About 30% of the sunlight
that reaches the top of the atmosphere is refl ected back to space.
Roughly two-thirds of this refl ectivity is due to clouds and small
particles in the atmosphere known as ‘aerosols’. Light-coloured
areas of Earth’s surface – mainly snow, ice and deserts – refl ect the
remaining one-third of the sunlight. The most dramatic change in
aerosol-produced refl ectivity comes when major volcanic erup-
tions eject material very high into the atmosphere. Rain typically
(continued)
FAQ 1.1, Figure 1. Estimate of the Earth’s annual and global mean energy balance. Over the long term, the amount of incoming solar radiation absorbed by the Earth and
atmosphere is balanced by the Earth and atmosphere releasing the same amount of outgoing longwave radiation. About half of the incoming solar radiation is absorbed by the
Earth’s surface. This energy is transferred to the atmosphere by warming the air in contact with the surface (thermals), by evapotranspiration and by longwave radiation that is
absorbed by clouds and greenhouse gases. The atmosphere in turn radiates longwave energy back to Earth as well as out to space. Source: Kiehl and Trenberth (1997).
96
Chapter 1 clears aerosols out of the atmosphere in a week or two, but when
material from a violent volcanic eruption is projected far above
the highest cloud, these aerosols typically infl uence the climate
for about a year or two before falling into the troposphere and
being carried to the surface by precipitation. Major volcanic erup-
tions can thus cause a drop in mean global surface temperature of
about half a degree celsius that can last for months or even years.
Some man-made aerosols also signifi cantly refl ect sunlight.
The energy that is not refl ected back to space is absorbed by
the Earth’s surface and atmosphere. This amount is approximately
240 Watts per square metre (W m–2). To balance the incoming en-
ergy, the Earth itself must radiate, on average, the same amount
of energy back to space. The Earth does this by emitting outgoing
longwave radiation. Everything on Earth emits longwave radia-
tion continuously. That is the heat energy one feels radiating out
from a fi re; the warmer an object, the more heat energy it radi-
ates. To emit 240 W m–2, a surface would have to have a tem-
perature of around –19°C. This is much colder than the conditions
that actually exist at the Earth’s surface (the global mean surface
temperature is about 14°C). Instead, the necessary –19°C is found
at an altitude about 5 km above the surface.
The reason the Earth’s surface is this warm is the presence of
greenhouse gases, which act as a partial blanket for the longwave
radiation coming from the surface. This blanketing is known as
the natural greenhouse effect. The most important greenhouse
gases are water vapour and carbon dioxide. The two most abun-
dant constituents of the atmosphere – nitrogen and oxygen – have
no such effect. Clouds, on the other hand, do exert a blanketing
effect similar to that of the greenhouse gases; however, this effect
is offset by their refl ectivity, such that on average, clouds tend to
have a cooling effect on climate (although locally one can feel the
warming effect: cloudy nights tend to remain warmer than clear
nights because the clouds radiate longwave energy back down
to the surface). Human activities intensify the blanketing effect
through the release of greenhouse gases. For instance, the amount
of carbon dioxide in the atmosphere has increased by about 35%
in the industrial era, and this increase is known to be due to hu-
man activities, primarily the combustion of fossil fuels and re-
moval of forests. Thus, humankind has dramatically altered the
chemical composition of the global atmosphere with substantial
implications for climate.
Because the Earth is a sphere, more solar energy arrives for a
given surface area in the tropics than at higher latitudes, where
Historical Overview of Climate Change Science
sunlight strikes the atmosphere at a lower angle. Energy is trans-
ported from the equatorial areas to higher latitudes via atmo-
spheric and oceanic circulations, including storm systems. Energy
is also required to evaporate water from the sea or land surface,
and this energy, called latent heat, is released when water vapour
condenses in clouds (see Figure 1). Atmospheric circulation is pri-
marily driven by the release of this latent heat. Atmospheric cir-
culation in turn drives much of the ocean circulation through the
action of winds on the surface waters of the ocean, and through
changes in the ocean’s surface temperature and salinity through
precipitation and evaporation.
Due to the rotation of the Earth, the atmospheric circulation
patterns tend to be more east-west than north-south. Embedded
in the mid-latitude westerly winds are large-scale weather sys-
tems that act to transport heat toward the poles. These weather
systems are the familiar migrating low- and high-pressure sys-
tems and their associated cold and warm fronts. Because of land-
ocean temperature contrasts and obstacles such as mountain
ranges and ice sheets, the circulation system’s planetary-scale
atmospheric waves tend to be geographically anchored by conti-
nents and mountains although their amplitude can change with
time. Because of the wave patterns, a particularly cold winter
over North America may be associated with a particularly warm
winter elsewhere in the hemisphere. Changes in various aspects
of the climate system, such as the size of ice sheets, the type and
distribution of vegetation or the temperature of the atmosphere
or ocean will infl uence the large-scale circulation features of the
atmosphere and oceans.
There are many feedback mechanisms in the climate system
that can either amplify (‘positive feedback’) or diminish (‘negative
feedback’) the effects of a change in climate forcing. For example,
as rising concentrations of greenhouse gases warm Earth’s cli-
mate, snow and ice begin to melt. This melting reveals darker
land and water surfaces that were beneath the snow and ice,
and these darker surfaces absorb more of the Sun’s heat, causing
more warming, which causes more melting, and so on, in a self-
reinforcing cycle. This feedback loop, known as the ‘ice-albedo
feedback’, amplifi es the initial warming caused by rising levels
of greenhouse gases. Detecting, understanding and accurately
quantifying climate feedbacks have been the focus of a great deal
of research by scientists unravelling the complexities of Earth’s
climate.
97
Historical Overview of Climate Change Science A characteristic of Earth sciences is that Earth scientists are
unable to perform controlled experiments on the planet as a
whole and then observe the results. In this sense, Earth science
is similar to the disciplines of astronomy and cosmology that
cannot conduct experiments on galaxies or the cosmos. This
is an important consideration, because it is precisely such
whole-Earth, system-scale experiments, incorporating the full
complexity of interacting processes and feedbacks, that might
ideally be required to fully verify or falsify climate change
hypotheses (Schellnhuber et al., 2004). Nevertheless, countless
empirical tests of numerous different hypotheses have built
up a massive body of Earth science knowledge. This repeated
testing has refi ned the understanding of numerous aspects of the
climate system, from deep oceanic circulation to stratospheric
chemistry. Sometimes a combination of observations and models
can be used to test planetary-scale hypotheses. For example,
the global cooling and drying of the atmosphere observed after
the eruption of Mt. Pinatubo (Section 8.6) provided key tests
of particular aspects of global climate models (Hansen et al.,
1992).
Another example is provided by past IPCC projections
of future climate change compared to current observations.
Figure 1.1 reveals that the model projections of global average
temperature from the First Assessment Report (FAR; IPCC,
1990) were higher than those from the Second Assessment
Report (SAR; IPCC, 1996). Subsequent observations (Section
3.2) showed that the evolution of the actual climate system
fell midway between the FAR and the SAR ‘best estimate’
projections and were within or near the upper range of
projections from the TAR (IPCC, 2001a).
Not all theories or early results are verifi ed by later analysis.
In the mid-1970s, several articles about possible global cooling
appeared in the popular press, primarily motivated by analyses
indicating that Northern Hemisphere (NH) temperatures had
decreased during the previous three decades (e.g., Gwynne,
1975). In the peer-reviewed literature, a paper by Bryson
and Dittberner (1976) reported that increases in carbon
dioxide (CO2) should be associated with a decrease in global
temperatures. When challenged by Woronko (1977), Bryson and
Dittberner (1977) explained that the cooling projected by their
model was due to aerosols (small particles in the atmosphere)
produced by the same combustion that caused the increase in
CO2. However, because aerosols remain in the atmosphere only
a short time compared to CO2, the results were not applicable
for long-term climate change projections. This example of a
prediction of global cooling is a classic illustration of the self-
correcting nature of Earth science. The scientists involved were
reputable researchers who followed the accepted paradigm of
publishing in scientifi c journals, submitting their methods and
results to the scrutiny of their peers (although the peer-review
did not catch this problem), and responding to legitimate
criticism.
A recurring theme throughout this chapter is that climate
science in recent decades has been characterised by the
98
Chapter 1
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
1990
1991
1992
1993
1994
1995
1996
1997
1998
1999
2000
2001
2002
2003
2004
2005
2006
2007
2008
2009
2010
Figure 1.1. Yearly global average surface temperature (Brohan et al., 2006), rela-
tive to the mean 1961 to 1990 values, and as projected in the FAR (IPCC, 1990), SAR
(IPCC, 1996) and TAR (IPCC, 2001a). The ‘best estimate’ model projections from the
FAR and SAR are in solid lines with their range of estimated projections shown by the
shaded areas. The TAR did not have ‘best estimate’ model projections but rather a
range of projections. Annual mean observations (Section 3.2) are depicted by black
circles and the thick black line shows decadal variations obtained by smoothing the
time series using a 13-point fi lter.
increasing rate of advancement of research in the fi eld and
by the notable evolution of scientifi c methodology and tools,
including the models and observations that support and enable
the research. During the last four decades, the rate at which
scientists have added to the body of knowledge of atmospheric
and oceanic processes has accelerated dramatically. As scientists
incrementally increase the totality of knowledge, they publish
their results in peer-reviewed journals. Between 1965 and 1995,
the number of articles published per year in atmospheric science
journals tripled (Geerts, 1999). Focusing more narrowly,
Stanhill (2001) found that the climate change science literature
grew approximately exponentially with a doubling time of 11
years for the period 1951 to 1997. Furthermore, 95% of all the
climate change science literature since 1834 was published
after 1951. Because science is cumulative, this represents
considerable growth in the knowledge of climate processes and
in the complexity of climate research. An important example
of this is the additional physics incorporated in climate models
over the last several decades, as illustrated in Figure 1.2. As a
result of the cumulative nature of science, climate science today
is an interdisciplinary synthesis of countless tested and proven
physical processes and principles painstakingly compiled
and verifi ed over several centuries of detailed laboratory
measurements, observational experiments and theoretical
analyses; and is now far more wide-ranging and physically
comprehensive than was the case only a few decades ago.
Chapter 1 Historical Overview of Climate Change Science
Figure 1.2. The complexity of climate models has increased over the last few decades. The additional physics incorporated in the models are shown pictorially by the
different features of the modelled world.
99
Historical Overview of Climate Change Science Chapter 1
1.3 Examples of Progress in
Detecting and Attributing Recent
Climate Change
1.3.1 The Human Fingerprint on Greenhouse
Gases
The high-accuracy measurements of atmospheric CO2
concentration, initiated by Charles David Keeling in 1958,
constitute the master time series documenting the changing
composition of the atmosphere (Keeling, 1961, 1998). These
data have iconic status in climate change science as evidence of
the effect of human activities on the chemical composition of
the global atmosphere (see FAQ 7.1). Keeling’s measurements
on Mauna Loa in Hawaii provide a true measure of the global
carbon cycle, an effectively continuous record of the burning of
fossil fuel. They also maintain an accuracy and precision that
allow scientists to separate fossil fuel emissions from those due
to the natural annual cycle of the biosphere, demonstrating a
long-term change in the seasonal exchange of CO2 between
the atmosphere, biosphere and ocean. Later observations of
parallel trends in the atmospheric abundances of the 13CO2
isotope (Francey and Farquhar, 1982) and molecular oxygen
(O2) (Keeling and Shertz, 1992; Bender et al., 1996) uniquely
identifi ed this rise in CO2 with fossil fuel burning (Sections 2.3,
7.1 and 7.3).
To place the increase in CO2 abundance since the late
1950s in perspective, and to compare the magnitude of the
anthropogenic increase with natural cycles in the past, a longer-
term record of CO2 and other natural greenhouse gases is
needed. These data came from analysis of the composition of air
enclosed in bubbles in ice cores from Greenland and Antarctica.
The initial measurements demonstrated that CO2 abundances
were signifi cantly lower during the last ice age than over the
last 10 kyr of the Holocene (Delmas et al., 1980; Berner et al.,
1980; Neftel et al., 1982). From 10 kyr before present up to
the year 1750, CO2 abundances stayed within the range 280
± 20 ppm (Indermühle et al., 1999). During the industrial era,
CO2 abundance rose roughly exponentially to 367 ppm in 1999
(Neftel et al., 1985; Etheridge et al., 1996; IPCC, 2001a) and to
379 ppm in 2005 (Section 2.3.1; see also Section 6.4).
Direct atmospheric measurements since 1970 (Steele et al.,
1996) have also detected the increasing atmospheric abundances
of two other major greenhouse gases, methane (CH4) and nitrous
oxide (N2O). Methane abundances were initially increasing at a
rate of about 1% yr–1 (Graedel and McRae, 1980; Fraser et al.,
1981; Blake et al., 1982) but then slowed to an average increase
of 0.4% yr–1 over the 1990s (Dlugokencky et al., 1998) with the
possible stabilisation of CH4 abundance (Section 2.3.2). The
increase in N2O abundance is smaller, about 0.25% yr–1, and
more diffi cult to detect (Weiss, 1981; Khalil and Rasmussen,
1988). To go back in time, measurements were made from fi rn
air trapped in snowpack dating back over 200 years, and these
data show an accelerating rise in both CH4 and N2O into the
20th century (Machida et al., 1995; Battle et al., 1996). When
100
ice core measurements extended the CH4 abundance back
1 kyr, they showed a stable, relatively constant abundance of 700
ppb until the 19th century when a steady increase brought CH4
abundances to 1,745 ppb in 1998 (IPCC, 2001a) and 1,774 ppb
in 2005 (Section 2.3.2). This peak abundance is much higher than
the range of 400 to 700 ppb seen over the last half-million years
of glacial-interglacial cycles, and the increase can be readily
explained by anthropogenic emissions. For N2O the results are
similar: the relative increase over the industrial era is smaller
(15%), yet the 1998 abundance of 314 ppb (IPCC, 2001a), rising
to 319 ppb in 2005 (Section 2.3.3), is also well above the 180-
to-260 ppb range of glacial-interglacial cycles (Flückiger et al.,
1999; see Sections 2.3, 6.2, 6.3, 6.4, 7.1 and 7.4)
Several synthetic halocarbons (chlorofl uorocarbons (CFCs),
hydrofl uorocarbons, perfl uorocarbons, halons and sulphur
hexafl uoride) are greenhouse gases with large global warming
potentials (GWPs; Section 2.10). The chemical industry has
been producing these gases and they have been leaking into the
atmosphere since about 1930. Lovelock (1971) fi rst measured
CFC-11 (CFCl3) in the atmosphere, noting that it could serve as
an artifi cial tracer, with its north-south gradient refl ecting the
latitudinal distribution of anthropogenic emissions. Atmospheric
abundances of all the synthetic halocarbons were increasing
until the 1990s, when the abundance of halocarbons phased
out under the Montreal Protocol began to fall (Montzka et al.,
1999; Prinn et al., 2000). In the case of synthetic halocarbons
(except perfl uoromethane), ice core research has shown that
these compounds did not exist in ancient air (Langenfelds et
al., 1996) and thus confi rms their industrial human origin (see
Sections 2.3 and 7.1).
At the time of the TAR scientists could say that the abundances
of all the well-mixed greenhouse gases during the 1990s were
greater than at any time during the last half-million years (Petit
et al, 1999), and this record now extends back nearly one million
years (Section 6.3). Given this daunting picture of increasing
greenhouse gas abundances in the atmosphere, it is noteworthy
that, for simpler challenges but still on a hemispheric or even
global scale, humans have shown the ability to undo what they
have done. Sulphate pollution in Greenland was reversed in
the 1980s with the control of acid rain in North America and
Europe (IPCC, 2001b), and CFC abundances are declining
globally because of their phase-out undertaken to protect the
ozone layer.
1.3.2 Global Surface Temperature
Shortly after the invention of the thermometer in the early
1600s, efforts began to quantify and record the weather. The
fi rst meteorological network was formed in northern Italy in
1653 (Kington, 1988) and reports of temperature observations
were published in the earliest scientifi c journals (e.g., Wallis and
Beale, 1669). By the latter part of the 19th century, systematic
observations of the weather were being made in almost all
inhabited areas of the world. Formal international coordination
of meteorological observations from ships commenced in 1853
(Quetelet, 1854).
Chapter 1 Historical Overview of Climate Change Science
Inspired by the paper Suggestions
on a Uniform System of Meteorological
Observations (Buys-Ballot, 1872), the
International Meteorological Organization
(IMO) was formed in 1873. Its successor,
the World Meteorological Organization
(WMO), still works to promote and
exchange standardised meteorological
observations. Yet even with uniform
observations, there are still four major
obstacles to turning instrumental
observations into accurate global time
series: (1) access to the data in usable
form; (2) quality control to remove or edit
erroneous data points; (3) homogeneity
assessments and adjustments where
necessary to ensure the fi delity of the data;
and (4) area-averaging in the presence of
substantial gaps.
Köppen (1873, 1880, 1881) was the
fi rst scientist to overcome most of these
obstacles in his quest to study the effect of
changes in sunspots (Section 2.7). Much
of his data came from Dove (1852), but
wherever possible he used data directly from
the original source, because Dove often
lacked information about the observing
methods. Köppen considered examination
of the annual mean temperature to be an
adequate technique for quality control of far distant stations.
Using data from more than 100 stations, Köppen averaged
annual observations into several major latitude belts and then
area-averaged these into a near-global time series shown in
Figure 1.3.
Callendar (1938) produced the next global temperature
time series expressly to investigate the infl uence of CO2 on
temperature (Section 2.3). Callendar examined about 200
station records. Only a small portion of them were deemed
defective, based on quality concerns determined by comparing
differences with neighbouring stations or on homogeneity
concerns based on station changes documented in the recorded
metadata. After further removing two arctic stations because
he had no compensating stations from the antarctic region, he
created a global average using data from 147 stations.
Most of Callendar’s data came from World Weather Records
(WWR; Clayton, 1927). Initiated by a resolution at the 1923
IMO Conference, WWR was a monumental international
undertaking producing a 1,196-page volume of monthly
temperature, precipitation and pressure data from hundreds
of stations around the world, some with data starting in the
early 1800s. In the early 1960s, J. Wolbach had these data
digitised (National Climatic Data Center, 2002). The WWR
project continues today under the auspices of the WMO with
the digital publication of decadal updates to the climate records
for thousands of stations worldwide (National Climatic Data
Center, 2005).
Figure 1.3. Published records of surface temperature change over large regions. Köppen (1881) tropics
and temperate latitudes using land air temperature. Callendar (1938) global using land stations. Willett
(1950) global using land stations. Callendar (1961) 60°N to 60°S using land stations. Mitchell (1963) global
using land stations. Budyko (1969) Northern Hemisphere using land stations and ship reports. Jones et al.
(1986a,b) global using land stations. Hansen and Lebedeff (1987) global using land stations. Brohan et al.
(2006) global using land air temperature and sea surface temperature data is the longest of the currently
updated global temperature time series (Section 3.2). All time series were smoothed using a 13-point fi lter.
The Brohan et al. (2006) time series are anomalies from the 1961 to 1990 mean (°C). Each of the other time
series was originally presented as anomalies from the mean temperature of a specifi c and differing base
period. To make them comparable, the other time series have been adjusted to have the mean of their last
30 years identical to that same period in the Brohan et al. (2006) anomaly time series.
Willett (1950) also used WWR as the main source of data for
129 stations that he used to create a global temperature time series
going back to 1845. While the resolution that initiated WWR
called for the publication of long and homogeneous records,
Willett took this mandate one step further by carefully selecting
a subset of stations with as continuous and homogeneous a
record as possible from the most recent update of WWR, which
included data through 1940. To avoid over-weighting certain
areas such as Europe, only one record, the best available, was
included from each 10° latitude and longitude square. Station
monthly data were averaged into fi ve-year periods and then
converted to anomalies with respect to the fi ve-year period
1935 to 1939. Each station’s anomaly was given equal weight
to create the global time series.
Callendar in turn created a new near-global temperature
time series in 1961 and cited Willett (1950) as a guide for
some of his improvements. Callendar (1961) evaluated 600
stations with about three-quarters of them passing his quality
checks. Unbeknownst to Callendar, a former student of Willett,
Mitchell (1963), in work fi rst presented in 1961, had created
his own updated global temperature time series using slightly
fewer than 200 stations and averaging the data into latitude
bands. Landsberg and Mitchell (1961) compared Callendar’s
results with Mitchell’s and stated that there was generally good
agreement except in the data-sparse regions of the Southern
Hemisphere.
101
Historical Overview of Climate Change Science Meanwhile, research in Russia was proceeding on a very
different method to produce large-scale time series. Budyko
(1969) used smoothed, hand-drawn maps of monthly temperature
anomalies as a starting point. While restricted to analysis of the
NH, this map-based approach not only allowed the inclusion of
an increasing number of stations over time (e.g., 246 in 1881,
753 in 1913, 976 in 1940 and about 2,000 in 1960) but also the
utilisation of data over the oceans (Robock, 1982).
Increasing the number of stations utilised has been a
continuing theme over the last several decades with considerable
effort being spent digitising historical station data as well as
addressing the continuing problem of acquiring up-to-date data,
as there can be a long lag between making an observation and
the data getting into global data sets. During the 1970s and
1980s, several teams produced global temperature time series.
Advances especially worth noting during this period include the
extended spatial interpolation and station averaging technique
of Hansen and Lebedeff (1987) and the Jones et al. (1986a,b)
painstaking assessment of homogeneity and adjustments to
account for discontinuities in the record of each of the thousands
of stations in a global data set. Since then, global and national
data sets have been rigorously adjusted for homogeneity using
a variety of statistical and metadata-based approaches (Peterson
et al., 1998).
One recurring homogeneity concern is potential urban heat
island contamination in global temperature time series. This
concern has been addressed in two ways. The fi rst is by adjusting
the temperature of urban stations to account for assessed urban
heat island effects (e.g., Karl et al., 1988; Hansen et al., 2001).
The second is by performing analyses that, like Callendar
(1938), indicate that the bias induced by urban heat islands
in the global temperature time series is either minor or non-
existent (Jones et al., 1990; Peterson et al., 1999).
As the importance of ocean data became increasingly
recognised, a major effort was initiated to seek out, digitise
and quality-control historical archives of ocean data. This work
has since grown into the International Comprehensive Ocean-
Atmosphere Data Set (ICOADS; Worley et al., 2005), which
has coordinated the acquisition, digitisation and synthesis of
data ranging from transmissions by Japanese merchant ships
to the logbooks of South African whaling boats. The amount
of sea surface temperature (SST) and related data acquired
continues to grow.
As fundamental as the basic data work of ICOADS was,
there have been two other major advances in SST data. The fi rst
was adjusting the early observations to make them comparable
to current observations (Section 3.2). Prior to 1940, the majority
of SST observations were made from ships by hauling a bucket
on deck fi lled with surface water and placing a thermometer in
it. This ancient method eventually gave way to thermometers
placed in engine cooling water inlets, which are typically
located several metres below the ocean surface. Folland and
Parker (1995) developed an adjustment model that accounted
for heat loss from the buckets and that varied with bucket size
and type, exposure to solar radiation, ambient wind speed and
ship speed. They verifi ed their results using time series of
102
Chapter 1
night marine air temperature. This adjusted the early bucket
observations upwards by a few tenths of a degree celsius.
Most of the ship observations are taken in narrow shipping
lanes, so the second advance has been increasing global
coverage in a variety of ways. Direct improvement of coverage
has been achieved by the internationally coordinated placement
of drifting and moored buoys. The buoys began to be numerous
enough to make signifi cant contributions to SST analyses in
the mid-1980s (McPhaden et al., 1998) and have subsequently
increased to more than 1,000 buoys transmitting data at any one
time. Since 1982, satellite data, anchored to in situ observations,
have contributed to near-global coverage (Reynolds and Smith,
1994). In addition, several different approaches have been used
to interpolate and combine land and ocean observations into the
current global temperature time series (Section 3.2). To place
the current instrumental observations into a longer historical
context requires the use of proxy data (Section 6.2).
Figure 1.3 depicts several historical ‘global’ temperature
time series, together with the longest of the current global
temperature time series, that of Brohan et al. (2006; Section
3.2). While the data and the analysis techniques have changed
over time, all the time series show a high degree of consistency
since 1900. The differences caused by using alternate data
sources and interpolation techniques increase when the data
are sparser. This phenomenon is especially illustrated by the
pre-1880 values of Willett’s (1950) time series. Willett noted
that his data coverage remained fairly constant after 1885 but
dropped off dramatically before that time to only 11 stations
before 1850. The high degree of agreement between the time
series resulting from these many different analyses increases
the confi dence that the changes they are indicating are real.
Despite the fact that many recent observations are automatic,
the vast majority of data that go into global surface temperature
calculations – over 400 million individual readings of
thermometers at land stations and over 140 million individual
in situ SST observations – have depended on the dedication of
tens of thousands of individuals for well over a century. Climate
science owes a great debt to the work of these individual weather
observers as well as to international organisations such as the
IMO, WMO and the Global Climate Observing System, which
encourage the taking and sharing of high-quality meteorological
observations. While modern researchers and their institutions
put a great deal of time and effort into acquiring and adjusting
the data to account for all known problems and biases,
century-scale global temperature time series would not have
been possible without the conscientious work of individuals
and organisations worldwide dedicated to quantifying and
documenting their local environment (Section 3.2).
1.3.3 Detection and Attribution
Using knowledge of past climates to qualify the nature of
ongoing changes has become a concern of growing importance
during the last decades, as refl ected in the successive IPCC
reports. While linked together at a technical level, detection
and attribution have separate objectives. Detection of climate
Chapter 1 change is the process of demonstrating that climate has changed
in some defi ned statistical sense, without providing a reason
for that change. Attribution of causes of climate change is
the process of establishing the most likely causes for the
detected change with some defi ned level of confi dence. Using
traditional approaches, unequivocal attribution would require
controlled experimentation with our climate system. However,
with no spare Earth with which to experiment, attribution
of anthropogenic climate change must be pursued by: (a)
detecting that the climate has changed (as defi ned above);
(b) demonstrating that the detected change is consistent with
computer model simulations of the climate change ‘signal’ that
is calculated to occur in response to anthropogenic forcing; and
(c) demonstrating that the detected change is not consistent with
alternative, physically plausible explanations of recent climate
change that exclude important anthropogenic forcings.
Both detection and attribution rely on observational data
and model output. In spite of the efforts described in Section
1.3.2, estimates of century-scale natural climate fl uctuations
remain diffi cult to obtain directly from observations due to the
relatively short length of most observational records and a lack
of understanding of the full range and effects of the various
and ongoing external infl uences. Model simulations with no
changes in external forcing (e.g., no increases in atmospheric
CO2 concentration) provide valuable information on the natural
internal variability of the climate system on time scales of years
to centuries. Attribution, on the other hand, requires output from
model runs that incorporate historical estimates of changes in
key anthropogenic and natural forcings, such as well-mixed
greenhouse gases, volcanic aerosols and solar irradiance. These
simulations can be performed with changes in a single forcing
only (which helps to isolate the climate effect of that forcing),
or with simultaneous changes in a whole suite of forcings.
In the early years of detection and attribution research, the
focus was on a single time series – the estimated global-mean
changes in the Earth’s surface temperature. While it was not
possible to detect anthropogenic warming in 1980, Madden
and Ramanathan (1980) and Hansen et al. (1981) predicted it
would be evident at least within the next two decades. A decade
later, Wigley and Raper (1990) used a simple energy-balance
climate model to show that the observed change in global-mean
surface temperature from 1867 to 1982 could not be explained
by natural internal variability. This fi nding was later confi rmed
using variability estimates from more complex coupled ocean-
atmosphere general circulation models (e.g., Stouffer et al.,
1994).
As the science of climate change progressed, detection
and attribution research ventured into more sophisticated
statistical analyses that examined complex patterns of climate
change. Climate change patterns or ‘fi ngerprints’ were no
longer limited to a single variable (temperature) or to the
Earth’s surface. More recent detection and attribution work
has made use of precipitation and global pressure patterns,
and analysis of vertical profi les of temperature change in the
ocean and atmosphere. Studies with multiple variables make it
easier to address attribution issues. While two different climate
Historical Overview of Climate Change Science
forcings may yield similar changes in global mean temperature,
it is highly unlikely that they will produce exactly the same
‘fi ngerprint’ (i.e., climate changes that are identical as a function
of latitude, longitude, height, season and history over the
20th century).
Such model-predicted fi ngerprints of anthropogenic climate
change are clearly statistically identifi able in observed data.
The common conclusion of a wide range of fi ngerprint studies
conducted over the past 15 years is that observed climate changes
cannot be explained by natural factors alone (Santer et al.,
1995, 1996a,b,c; Hegerl et al., 1996, 1997, 2000; Hasselmann,
1997; Barnett et al., 1999; Tett et al., 1999; Stott et al., 2000). A
substantial anthropogenic infl uence is required in order to best
explain the observed changes. The evidence from this body of
work strengthens the scientifi c case for a discernible human
infl uence on global climate.
1.4 Examples of Progress in
Understanding Climate Processes
1.4.1 The Earth’s Greenhouse Effect
The realisation that Earth’s climate might be sensitive to the
atmospheric concentrations of gases that create a greenhouse
effect is more than a century old. Fleming (1998) and Weart
(2003) provided an overview of the emerging science. In terms
of the energy balance of the climate system, Edme Mariotte
noted in 1681 that although the Sun’s light and heat easily pass
through glass and other transparent materials, heat from other
sources (chaleur de feu) does not. The ability to generate an
artifi cial warming of the Earth’s surface was demonstrated in
simple greenhouse experiments such as Horace Benedict de
Saussure’s experiments in the 1760s using a ‘heliothermometer’
(panes of glass covering a thermometer in a darkened box) to
provide an early analogy to the greenhouse effect. It was a
conceptual leap to recognise that the air itself could also trap
thermal radiation. In 1824, Joseph Fourier, citing Saussure,
argued ‘the temperature [of the Earth] can be augmented by
the interposition of the atmosphere, because heat in the state
of light fi nds less resistance in penetrating the air, than in
repassing into the air when converted into non-luminous heat’.
In 1836, Pouillit followed up on Fourier’s ideas and argued
‘the atmospheric stratum…exercises a greater absorption
upon the terrestrial than on the solar rays’. There was still no
understanding of exactly what substance in the atmosphere was
responsible for this absorption.
In 1859, John Tyndall (1861) identifi ed through laboratory
experiments the absorption of thermal radiation by complex
molecules (as opposed to the primary bimolecular atmospheric
constituents O2 and molecular nitrogen). He noted that changes
in the amount of any of the radiatively active constituents of the
atmosphere such as water (H2O) or CO2 could have produced
‘all the mutations of climate which the researches of geologists
103
Historical Overview of Climate Change Science Chapter 1
Frequently Asked Question 1.2
What is the Relationship between Climate Change
and Weather?
Climate is generally defi ned as average weather, and as such,
climate change and weather are intertwined. Observations can
show that there have been changes in weather, and it is the statis-
tics of changes in weather over time that identify climate change.
While weather and climate are closely related, there are important
differences. A common confusion between weather and climate
arises when scientists are asked how they can predict climate 50
years from now when they cannot predict the weather a few weeks
from now. The chaotic nature of weather makes it unpredictable
beyond a few days. Projecting changes in climate (i.e., long-term
average weather) due to changes in atmospheric composition or
other factors is a very different and much more manageable issue.
As an analogy, while it is impossible to predict the age at which
any particular man will die, we can say with high confi dence that
the average age of death for men in industrialised countries is
about 75. Another common confusion of these issues is thinking
that a cold winter or a cooling spot on the globe is evidence against
global warming. There are always extremes of hot and cold, al-
though their frequency and intensity change as climate changes.
But when weather is averaged over space and time, the fact that
the globe is warming emerges clearly from the data.
Meteorologists put a great deal of effort into observing, un-
derstanding and predicting the day-to-day evolution of weath-
er systems. Using physics-based concepts that govern how the
atmosphere moves, warms, cools, rains, snows, and evaporates
water, meteorologists are typically able to predict the weather
successfully several days into the future. A major limiting factor
to the predictability of weather beyond several days is a funda-
mental dynamical property of the atmosphere. In the 1960s, me-
teorologist Edward Lorenz discovered that very slight differences
in initial conditions can produce very different forecast results.
(continued)
FAQ 1.2, Figure 1. Schematic view of the components of the climate system, their processes and interactions.
104
Chapter 1 This is the so-called butterfl y effect: a butterfl y fl apping its wings
(or some other small phenomenon) in one place can, in principle,
alter the subsequent weather pattern in a distant place. At the
core of this effect is chaos theory, which deals with how small
changes in certain variables can cause apparent randomness in
complex systems.
Nevertheless, chaos theory does not imply a total lack of or-
der. For example, slightly different conditions early in its history
might alter the day a storm system would arrive or the exact path
it would take, but the average temperature and precipitation (that
is, climate) would still be about the same for that region and that
period of time. Because a signifi cant problem facing weather fore-
casting is knowing all the conditions at the start of the forecast
period, it can be useful to think of climate as dealing with the
background conditions for weather. More precisely, climate can
be viewed as concerning the status of the entire Earth system, in-
cluding the atmosphere, land, oceans, snow, ice and living things
(see Figure 1) that serve as the global background conditions that
determine weather patterns. An example of this would be an El
Niño affecting the weather in coastal Peru. The El Niño sets limits
on the probable evolution of weather patterns that random effects
can produce. A La Niña would set different limits.
Another example is found in the familiar contrast between
summer and winter. The march of the seasons is due to changes in
the geographical patterns of energy absorbed and radiated away
by the Earth system. Likewise, projections of future climate are
reveal’. In 1895, Svante Arrhenius (1896) followed with a
climate prediction based on greenhouse gases, suggesting that
a 40% increase or decrease in the atmospheric abundance of the
trace gas CO2 might trigger the glacial advances and retreats.
One hundred years later, it would be found that CO2 did indeed
vary by this amount between glacial and interglacial periods.
However, it now appears that the initial climatic change preceded
the change in CO2 but was enhanced by it (Section 6.4).
G. S. Callendar (1938) solved a set of equations linking
greenhouse gases and climate change. He found that a doubling
of atmospheric CO2 concentration resulted in an increase
in the mean global temperature of 2°C, with considerably
more warming at the poles, and linked increasing fossil fuel
combustion with a rise in CO2 and its greenhouse effects: ‘As
man is now changing the composition of the atmosphere at a
rate which must be very exceptional on the geological time
scale, it is natural to seek for the probable effects of such a
change. From the best laboratory observations it appears that
the principal result of increasing atmospheric carbon dioxide…
would be a gradual increase in the mean temperature of the
colder regions of the Earth.’ In 1947, Ahlmann reported a 1.3°C
warming in the North Atlantic sector of the Arctic since the 19th
century and mistakenly believed this climate variation could be
explained entirely by greenhouse gas warming. Similar model
Historical Overview of Climate Change Science
shaped by fundamental changes in heat energy in the Earth sys-
tem, in particular the increasing intensity of the greenhouse effect
that traps heat near Earth’s surface, determined by the amount of
carbon dioxide and other greenhouse gases in the atmosphere.
Projecting changes in climate due to changes in greenhouse gas-
es 50 years from now is a very different and much more easily
solved problem than forecasting weather patterns just weeks from
now. To put it another way, long-term variations brought about
by changes in the composition of the atmosphere are much more
predictable than individual weather events. As an example, while
we cannot predict the outcome of a single coin toss or roll of the
dice, we can predict the statistical behaviour of a large number
of such trials.
While many factors continue to infl uence climate, scientists
have determined that human activities have become a dominant
force, and are responsible for most of the warming observed over
the past 50 years. Human-caused climate change has resulted pri-
marily from changes in the amounts of greenhouse gases in the
atmosphere, but also from changes in small particles (aerosols), as
well as from changes in land use, for example. As climate changes,
the probabilities of certain types of weather events are affected.
For example, as Earth’s average temperature has increased, some
weather phenomena have become more frequent and intense (e.g.,
heat waves and heavy downpours), while others have become less
frequent and intense (e.g., extreme cold events).
predictions were echoed by Plass in 1956 (see Fleming, 1998):
‘If at the end of this century, measurements show that the carbon
dioxide content of the atmosphere has risen appreciably and at
the same time the temperature has continued to rise throughout
the world, it will be fi rmly established that carbon dioxide is an
important factor in causing climatic change’ (see Chapter 9).
In trying to understand the carbon cycle, and specifi cally
how fossil fuel emissions would change atmospheric CO2, the
interdisciplinary fi eld of carbon cycle science began. One of the
fi rst problems addressed was the atmosphere-ocean exchange
of CO2. Revelle and Suess (1957) explained why part of the
emitted CO2 was observed to accumulate in the atmosphere
rather than being completely absorbed by the oceans. While
CO2 can be mixed rapidly into the upper layers of the ocean,
the time to mix with the deep ocean is many centuries. By
the time of the TAR, the interaction of climate change with
the oceanic circulation and biogeochemistry was projected to
reduce the fraction of anthropogenic CO2 emissions taken up
by the oceans in the future, leaving a greater fraction in the
atmosphere (Sections 7.1, 7.3 and 10.4).
In the 1950s, the greenhouse gases of concern remained
CO2 and H2O, the same two identifi ed by Tyndall a century
earlier. It was not until the 1970s that other greenhouse
gases – CH4, N2O and CFCs – were widely recognised as
105
Historical Overview of Climate Change Science important anthropogenic greenhouse gases (Ramanathan, 1975;
Wang et al., 1976; Section 2.3). By the 1970s, the importance
of aerosol-cloud effects in refl ecting sunlight was known
(Twomey, 1977), and atmospheric aerosols (suspended small
particles) were being proposed as climate-forcing constituents.
Charlson and others (summarised in Charlson et al., 1990) built
a consensus that sulphate aerosols were, by themselves, cooling
the Earth’s surface by directly refl ecting sunlight. Moreover, the
increases in sulphate aerosols were anthropogenic and linked
with the main source of CO2, burning of fossil fuels (Section
2.4). Thus, the current picture of the atmospheric constituents
driving climate change contains a much more diverse mix of
greenhouse agents.
1.4.2 Past Climate Observations, Astronomical
Theory and Abrupt Climate Changes
Throughout the 19th and 20th centuries, a wide range of
geomorphology and palaeontology studies has provided new
insight into the Earth’s past climates, covering periods of
hundreds of millions of years. The Palaeozoic Era, beginning
600 Ma, displayed evidence of both warmer and colder climatic
conditions than the present; the Tertiary Period (65 to 2.6 Ma)
was generally warmer; and the Quaternary Period (2.6 Ma to
the present – the ice ages) showed oscillations between glacial
and interglacial conditions. Louis Agassiz (1837) developed the
hypothesis that Europe had experienced past glacial ages, and
there has since been a growing awareness that long-term climate
observations can advance the understanding of the physical
mechanisms affecting climate change. The scientifi c study of
one such mechanism – modifi cations in the geographical and
temporal patterns of solar energy reaching the Earth’s surface
due to changes in the Earth’s orbital parameters – has a long
history. The pioneering contributions of Milankovitch (1941) to
this astronomical theory of climate change are widely known,
and the historical review of Imbrie and Imbrie (1979) calls
attention to much earlier contributions, such as those of James
Croll, originating in 1864.
The pace of palaeoclimatic research has accelerated
over recent decades. Quantitative and well-dated records of
climate fl uctuations over the last 100 kyr have brought a more
comprehensive view of how climate changes occur, as well
as the means to test elements of the astronomical theory. By
the 1950s, studies of deep-sea cores suggested that the ocean
temperatures may have been different during glacial times
(Emiliani, 1955). Ewing and Donn (1956) proposed that
changes in ocean circulation actually could initiate an ice age.
In the 1960s, the works of Emiliani (1969) and Shackleton
(1967) showed the potential of isotopic measurements in deep-
sea sediments to help explain Quaternary changes. In the 1970s,
it became possible to analyse a deep-sea core time series of
more than 700 kyr, thereby using the last reversal of the Earth’s
magnetic fi eld to establish a dated chronology. This deep-sea
observational record clearly showed the same periodicities
found in the astronomical forcing, immediately providing
strong support to Milankovitch’s theory (Hays et al., 1976).
106
Chapter 1
Ice cores provide key information about past climates,
including surface temperatures and atmospheric chemical
composition. The bubbles sealed in the ice are the only available
samples of these past atmospheres. The fi rst deep ice cores from
Vostok in Antarctica (Barnola et al., 1987; Jouzel et al., 1987,
1993) provided additional evidence of the role of astronomical
forcing. They also revealed a highly correlated evolution of
temperature changes and atmospheric composition, which
was subsequently confi rmed over the past 400 kyr (Petit et al.,
1999) and now extends to almost 1 Myr. This discovery drove
research to understand the causal links between greenhouse
gases and climate change. The same data that confi rmed the
astronomical theory also revealed its limits: a linear response
of the climate system to astronomical forcing could not explain
entirely the observed fl uctuations of rapid ice-age terminations
preceded by longer cycles of glaciations.
The importance of other sources of climate variability was
heightened by the discovery of abrupt climate changes. In this
context, ‘abrupt’ designates regional events of large amplitude,
typically a few degrees celsius, which occurred within several
decades – much shorter than the thousand-year time scales
that characterise changes in astronomical forcing. Abrupt
temperature changes were fi rst revealed by the analysis of deep
ice cores from Greenland (Dansgaard et al., 1984). Oeschger
et al. (1984) recognised that the abrupt changes during the
termination of the last ice age correlated with cooling in
Gerzensee (Switzerland) and suggested that regime shifts in
the Atlantic Ocean circulation were causing these widespread
changes. The synthesis of palaeoclimatic observations by
Broecker and Denton (1989) invigorated the community over
the next decade. By the end of the 1990s, it became clear that
the abrupt climate changes during the last ice age, particularly in
the North Atlantic regions as found in the Greenland ice cores,
were numerous (Dansgaard et al., 1993), indeed abrupt (Alley
et al., 1993) and of large amplitude (Severinghaus and Brook,
1999). They are now referred to as Dansgaard-Oeschger events.
A similar variability is seen in the North Atlantic Ocean, with
north-south oscillations of the polar front (Bond et al., 1992) and
associated changes in ocean temperature and salinity (Cortijo et
al., 1999). With no obvious external forcing, these changes are
thought to be manifestations of the internal variability of the
climate system.
The importance of internal variability and processes was
reinforced in the early 1990s with analysis of records with
high temporal resolution. New ice cores (Greenland Ice Core
Project, Johnsen et al., 1992; Greenland Ice Sheet Project 2,
Grootes et al., 1993), new ocean cores from regions with high
sedimentation rates, as well as lacustrine sediments and cave
stalagmites produced additional evidence for unforced climate
changes, and revealed a large number of abrupt changes in many
regions throughout the last glacial cycle. Long sediment cores
from the deep ocean were used to reconstruct the thermohaline
circulation connecting deep and surface waters (Bond et al.,
1992; Broecker, 1997) and to demonstrate the participation
of the ocean in these abrupt climate changes during glacial
periods.
Chapter 1 By the end of the 1990s, palaeoclimate proxies for a range
of climate observations had expanded greatly. The analysis
of deep corals provided indicators for nutrient content and
mass exchange from the surface to deep water (Adkins et al.,
1998), showing abrupt variations characterised by synchronous
changes in surface and deep-water properties (Shackleton et
al., 2000). Precise measurements of the CH4 abundances (a
global quantity) in polar ice cores showed that they changed in
concert with the Dansgaard-Oeschger events and thus allowed
for synchronisation of the dating across ice cores (Blunier
et al., 1998). The characteristics of the antarctic temperature
variations and their relation to the Dansgaard-Oeschger events in
Greenland were consistent with the simple concept of a bipolar
seesaw caused by changes in the thermohaline circulation of
the Atlantic Ocean (Stocker, 1998). This work underlined the
role of the ocean in transmitting the signals of abrupt climate
change.
Abrupt changes are often regional, for example, severe
droughts lasting for many years have changed civilizations, and
have occurred during the last 10 kyr of stable warm climate
(deMenocal, 2001). This result has altered the notion of a stable
climate during warm epochs, as previously suggested by the
polar ice cores. The emerging picture of an unstable ocean-
atmosphere system has opened the debate of whether human
interference through greenhouse gases and aerosols could
trigger such events (Broecker, 1997).
Palaeoclimate reconstructions cited in the FAR were based
on various data, including pollen records, insect and animal
remains, oxygen isotopes and other geological data from lake
varves, loess, ocean sediments, ice cores and glacier termini.
These records provided estimates of climate variability on
time scales up to millions of years. A climate proxy is a local
quantitative record (e.g., thickness and chemical properties of
tree rings, pollen of different species) that is interpreted as a
climate variable (e.g., temperature or rainfall) using a transfer
function that is based on physical principles and recently
observed correlations between the two records. The combination
of instrumental and proxy data began in the 1960s with the
investigation of the infl uence of climate on the proxy data,
including tree rings (Fritts, 1962), corals (Weber and Woodhead,
1972; Dunbar and Wellington, 1981) and ice cores (Dansgaard
et al., 1984; Jouzel et al., 1987). Phenological and historical
data (e.g., blossoming dates, harvest dates, grain prices,
ships’ logs, newspapers, weather diaries, ancient manuscripts)
are also a valuable source of climatic reconstruction for the
period before instrumental records became available. Such
documentary data also need calibration against instrumental
data to extend and reconstruct the instrumental record (Lamb,
1969; Zhu, 1973; van den Dool, 1978; Brazdil, 1992; Pfi ster,
1992). With the development of multi-proxy reconstructions,
the climate data were extended not only from local to global,
but also from instrumental data to patterns of climate variability
(Wanner et al., 1995; Mann et al., 1998; Luterbacher et al.,
1999). Most of these reconstructions were at single sites and
only loose efforts had been made to consolidate records. Mann
et al. (1998) made a notable advance in the use of proxy data by
Historical Overview of Climate Change Science
ensuring that the dating of different records lined up. Thus, the
true spatial patterns of temperature variability and change could
be derived, and estimates of NH average surface temperatures
were obtained.
The Working Group I (WGI) WGI FAR noted that past
climates could provide analogues. Fifteen years of research
since that assessment has identifi ed a range of variations and
instabilities in the climate system that occurred during the last
2 Myr of glacial-interglacial cycles and in the super-warm period
of 50 Ma. These past climates do not appear to be analogues of
the immediate future, yet they do reveal a wide range of climate
processes that need to be understood when projecting 21st-
century climate change (see Chapter 6).
1.4.3 Solar Variability and the Total Solar
Irradiance
Measurement of the absolute value of total solar irradiance
(TSI) is diffi cult from the Earth’s surface because of the need
to correct for the infl uence of the atmosphere. Langley (1884)
attempted to minimise the atmospheric effects by taking
measurements from high on Mt. Whitney in California, and
to estimate the correction for atmospheric effects by taking
measurements at several times of day, for example, with the
solar radiation having passed through different atmospheric
pathlengths. Between 1902 and 1957, Charles Abbot and a
number of other scientists around the globe made thousands of
measurements of TSI from mountain sites. Values ranged from
1,322 to 1,465 W m–2, which encompasses the current estimate
of 1,365 W m–2. Foukal et al. (1977) deduced from Abbot’s
daily observations that higher values of TSI were associated
with more solar faculae (e.g., Abbot, 1910).
In 1978, the Nimbus-7 satellite was launched with a cavity
radiometer and provided evidence of variations in TSI (Hickey
et al., 1980). Additional observations were made with an active
cavity radiometer on the Solar Maximum Mission, launched
in 1980 (Willson et al., 1980). Both of these missions showed
that the passage of sunspots and faculae across the Sun’s disk
infl uenced TSI. At the maximum of the 11-year solar activity
cycle, the TSI is larger by about 0.1% than at the minimum.
The observation that TSI is highest when sunspots are at their
maximum is the opposite of Langley’s (1876) hypothesis.
As early as 1910, Abbot believed that he had detected a
downward trend in TSI that coincided with a general cooling
of climate. The solar cycle variation in irradiance corresponds
to an 11-year cycle in radiative forcing which varies by about
0.2 W m–2. There is increasingly reliable evidence of its
infl uence on atmospheric temperatures and circulations,
particularly in the higher atmosphere (Reid, 1991; Brasseur,
1993; Balachandran and Rind, 1995; Haigh, 1996; Labitzke and
van Loon, 1997; van Loon and Labitzke, 2000). Calculations
with three-dimensional models (Wetherald and Manabe, 1975;
Cubasch et al., 1997; Lean and Rind, 1998; Tett et al., 1999;
Cubasch and Voss, 2000) suggest that the changes in solar
radiation could cause surface temperature changes of the order
of a few tenths of a degree celsius.
107
Historical Overview of Climate Change Science For the time before satellite measurements became available,
the solar radiation variations can be inferred from cosmogenic
isotopes (10Be, 14C) and from the sunspot number. Naked-eye
observations of sunspots date back to ancient times, but it was
only after the invention of the telescope in 1607 that it became
possible to routinely monitor the number, size and position of
these ‘stains’ on the surface of the Sun. Throughout the 17th
and 18th centuries, numerous observers noted the variable
concentrations and ephemeral nature of sunspots, but very few
sightings were reported between 1672 and 1699 (for an overview
see Hoyt et al., 1994). This period of low solar activity, now
known as the Maunder Minimum, occurred during the climate
period now commonly referred to as the Little Ice Age (Eddy,
1976). There is no exact agreement as to which dates mark the
beginning and end of the Little Ice Age, but from about 1350 to
about 1850 is one reasonable estimate.
During the latter part of the 18th century, Wilhelm Herschel
(1801) noted the presence not only of sunspots but of bright
patches, now referred to as faculae, and of granulations on
the solar surface. He believed that when these indicators of
activity were more numerous, solar emissions of light and heat
were greater and could affect the weather on Earth. Heinrich
Schwabe (1844) published his discovery of a ‘10-year cycle’
in sunspot numbers. Samuel Langley (1876) compared the
brightness of sunspots with that of the surrounding photosphere.
He concluded that they would block the emission of radiation
and estimated that at sunspot cycle maximum the Sun would be
about 0.1% less bright than at the minimum of the cycle, and
that the Earth would be 0.1°C to 0.3°C cooler.
These satellite data have been used in combination with the
historically recorded sunspot number, records of cosmogenic
isotopes, and the characteristics of other Sun-like stars to
estimate the solar radiation over the last 1,000 years (Eddy,
1976; Hoyt and Schatten, 1993, 1997; Lean et al., 1995; Lean,
1997). These data sets indicated quasi-periodic changes in solar
radiation of 0.24 to 0.30% on the centennial time scale. These
values have recently been re-assessed (see, e.g., Chapter 2).
The TAR states that the changes in solar irradiance are not
the major cause of the temperature changes in the second half
of the 20th century unless those changes can induce unknown
large feedbacks in the climate system. The effects of galactic
cosmic rays on the atmosphere (via cloud nucleation) and those
due to shifts in the solar spectrum towards the ultraviolet (UV)
range, at times of high solar activity, are largely unknown. The
latter may produce changes in tropospheric circulation via
changes in static stability resulting from the interaction of the
increased UV radiation with stratospheric ozone. More research
to investigate the effects of solar behaviour on climate is needed
before the magnitude of solar effects on climate can be stated
with certainty.
1.4.4 Biogeochemistry and Radiative Forcing
The modern scientifi c understanding of the complex and
interconnected roles of greenhouse gases and aerosols in
climate change has undergone rapid evolution over the last
108
Chapter 1
two decades. While the concepts were recognised and outlined
in the 1970s (see Sections 1.3.1 and 1.4.1), the publication of
generally accepted quantitative results coincides with, and was
driven in part by, the questions asked by the IPCC beginning in
1988. Thus, it is instructive to view the evolution of this topic as
it has been treated in the successive IPCC reports.
The WGI FAR codifi ed the key physical and biogeochemical
processes in the Earth system that relate a changing climate to
atmospheric composition, chemistry, the carbon cycle and natural
ecosystems. The science of the time, as summarised in the FAR,
made a clear case for anthropogenic interference with the climate
system. In terms of greenhouse agents, the main conclusions
from the WGI FAR Policymakers Summary are still valid today:
(1) ‘emissions resulting from human activities are substantially
increasing the atmospheric concentrations of the greenhouse
gases: CO2, CH4, CFCs, N2O’; (2) ‘some gases are potentially
more effective (at greenhouse warming)’; (3) feedbacks between
the carbon cycle, ecosystems and atmospheric greenhouse
gases in a warmer world will affect CO2 abundances; and (4)
GWPs provide a metric for comparing the climatic impact of
different greenhouse gases, one that integrates both the radiative
infl uence and biogeochemical cycles. The climatic importance
of tropospheric ozone, sulphate aerosols and atmospheric
chemical feedbacks were proposed by scientists at the time and
noted in the assessment. For example, early global chemical
modelling results argued that global tropospheric ozone, a
greenhouse gas, was controlled by emissions of the highly
reactive gases nitrogen oxides (NOx), carbon monoxide (CO)
and non-methane hydrocarbons (NMHC, also known as volatile
organic compounds, VOC). In terms of sulphate aerosols, both
the direct radiative effects and the indirect effects on clouds were
acknowledged, but the importance of carbonaceous aerosols
from fossil fuel and biomass combustion was not recognised
(Chapters 2, 7 and 10).
The concept of radiative forcing (RF) as the radiative
imbalance (W m–2) in the climate system at the top of the
atmosphere caused by the addition of a greenhouse gas (or
other change) was established at the time and summarised in
Chapter 2 of the WGI FAR. Agents of RF included the direct
greenhouse gases, solar radiation, aerosols and the Earth’s
surface albedo. What was new and only briefl y mentioned
was that ‘many gases produce indirect effects on the global
radiative forcing’. The innovative global modelling work of
Derwent (1990) showed that emissions of the reactive but non-
greenhouse gases – NOx, CO and NMHCs – altered atmospheric
chemistry and thus changed the abundance of other greenhouse
gases. Indirect GWPs for NOx, CO and VOCs were proposed.
The projected chemical feedbacks were limited to short-lived
increases in tropospheric ozone. By 1990, it was clear that the
RF from tropospheric ozone had increased over the 20th century
and stratospheric ozone had decreased since 1980 (e.g., Lacis
et al., 1990), but the associated RFs were not evaluated in the
assessments. Neither was the effect of anthropogenic sulphate
aerosols, except to note in the FAR that ‘it is conceivable that
this radiative forcing has been of a comparable magnitude,
but of opposite sign, to the greenhouse forcing earlier in the
Chapter 1 century’. Refl ecting in general the community’s concerns about
this relatively new measure of climate forcing, RF bar charts
appear only in the underlying FAR chapters, but not in the FAR
Summary. Only the long-lived greenhouse gases are shown,
although sulphate aerosols direct effect in the future is noted
with a question mark (i.e., dependent on future emissions)
(Chapters 2, 7 and 10).
The cases for more complex chemical and aerosol effects
were becoming clear, but the scientifi c community was unable at
the time to reach general agreement on the existence, scale and
magnitude of these indirect effects. Nevertheless, these early
discoveries drove the research agendas in the early 1990s. The
widespread development and application of global chemistry-
transport models had just begun with international workshops
(Pyle et al., 1996; Jacob et al., 1997; Rasch, 2000). In the
Supplementary Report (IPCC, 1992) to the FAR, the indirect
chemical effects of CO, NOx and VOC were reaffi rmed, and
the feedback effect of CH4 on the tropospheric hydroxyl radical
(OH) was noted, but the indirect RF values from the FAR were
retracted and denoted in a table with ‘+’, ‘0’ or ‘–’. Aerosol-
climate interactions still focused on sulphates, and the assessment
of their direct RF for the NH (i.e., a cooling) was now somewhat
quantitative as compared to the FAR. Stratospheric ozone
depletion was noted as causing a signifi cant and negative RF, but
not quantifi ed. Ecosystems research at this time was identifying
the responses to climate change and CO2 increases, as well as
altered CH4 and N2O fl uxes from natural systems; however, in
terms of a community assessment it remained qualitative.
By 1994, with work on SAR progressing, the Special
Report on Radiative Forcing (IPCC, 1995) reported signifi cant
breakthroughs in a set of chapters limited to assessment of the
carbon cycle, atmospheric chemistry, aerosols and RF. The
carbon budget for the 1980s was analysed not only from bottom-
up emissions estimates, but also from a top-down approach
including carbon isotopes. A fi rst carbon cycle assessment
was performed through an international model and analysis
workshop examining terrestrial and oceanic uptake to better
quantify the relationship between CO2 emissions and the
resulting increase in atmospheric abundance. Similarly,
expanded analyses of the global budgets of trace gases
and aerosols from both natural and anthropogenic sources
highlighted the rapid expansion of biogeochemical research.
The fi rst RF bar chart appears, comparing all the major
components of RF change from the pre-industrial period to the
present. Anthropogenic soot aerosol, with a positive RF, was
not in the 1995 Special Report but was added to the SAR. In
terms of atmospheric chemistry, the fi rst open-invitation
modelling study for the IPCC recruited 21 atmospheric chemistry
models to participate in a controlled study of photochemistry
and chemical feedbacks. These studies (e.g., Olson et al., 1997)
demonstrated a robust consensus about some indirect effects,
such as the CH4 impact on atmospheric chemistry, but great
uncertainty about others, such as the prediction of tropospheric
ozone changes. The model studies plus the theory of chemical
feedbacks in the CH4-CO-OH system (Prather, 1994) fi rmly
established that the atmospheric lifetime of a perturbation
Historical Overview of Climate Change Science
(and hence climate impact and GWP) of CH4 emissions was
about 50% greater than reported in the FAR. There was still
no consensus on quantifying the past or future changes in
tropospheric ozone or OH (the primary sink for CH4) (Chapters
2, 7 and 10).
In the early 1990s, research on aerosols as climate forcing
agents expanded. Based on new research, the range of climate-
relevant aerosols was extended for the fi rst time beyond
sulphates to include nitrates, organics, soot, mineral dust and sea
salt. Quantitative estimates of sulphate aerosol indirect effects on
cloud properties and hence RF were suffi ciently well established
to be included in assessments, and carbonaceous aerosols from
biomass burning were recognised as being comparable in
importance to sulphate (Penner et al., 1992). Ranges are given
in the special report (IPCC, 1995) for direct sulphate RF (–0.25
to –0.9 W m–2) and biomass-burning aerosols (–0.05 to –0.6
W m–2). The aerosol indirect RF was estimated to be about
equal to the direct RF, but with larger uncertainty. The injection
of stratospheric aerosols from the eruption of Mt. Pinatubo was
noted as the fi rst modern test of a known radiative forcing, and
indeed one climate model accurately predicted the temperature
response (Hansen et al., 1992). In the one-year interval between
the special report and the SAR, the scientifi c understanding of
aerosols grew. The direct anthropogenic aerosol forcing (from
sulphate, fossil-fuel soot and biomass-burning aerosols) was
reduced to –0.5 W m–2. The RF bar chart was now broken into
aerosol components (sulphate, fossil-fuel soot and biomass
burning aerosols) with a separate range for indirect effects
(Chapters 2 and 7; Sections 8.2 and 9.2).
Throughout the 1990s, there were concerted research programs
in the USA and EU to evaluate the global environmental impacts
of aviation. Several national assessments culminated in the IPCC
Special Report on Aviation and the Global Atmosphere (IPCC,
1999), which assessed the impacts on climate and global air
quality. An open invitation for atmospheric model participation
resulted in community participation and a consensus on many
of the environmental impacts of aviation (e.g., the increase in
tropospheric ozone and decrease in CH4 due to NOx emissions
were quantifi ed). The direct RF of sulphate and of soot aerosols
was likewise quantifi ed along with that of contrails, but the
impact on cirrus clouds that are sometimes generated downwind
of contrails was not. The assessment re-affi rmed that RF was
a fi rst-order metric for the global mean surface temperature
response, but noted that it was inadequate for regional climate
change, especially in view of the largely regional forcing from
aerosols and tropospheric ozone (Sections 2.6, 2.8 and 10.2).
By the end of the 1990s, research on atmospheric composition
and climate forcing had made many important advances. The
TAR was able to provide a more quantitative evaluation in some
areas. For example, a large, open-invitation modelling workshop
was held for both aerosols (11 global models) and tropospheric
ozone-OH chemistry (14 global models). This workshop brought
together as collaborating authors most of the international
scientifi c community involved in developing and testing global
models of atmospheric composition. In terms of atmospheric
chemistry, a strong consensus was reached for the fi rst time
109
Historical Overview of Climate Change Science that science could predict the changes in tropospheric ozone in
response to scenarios for CH4 and the indirect greenhouse gases
(CO, NOx, VOC) and that a quantitative GWP for CO could be
reported. Further, combining these models with observational
analysis, an estimate of the change in tropospheric ozone since
the pre-industrial era – with uncertainties – was reported. The
aerosol workshop made similar advances in evaluating the
impact of different aerosol types. There were many different
representations of uncertainty (e.g., a range in models versus
an expert judgment) in the TAR, and the consensus RF bar
chart did not generate a total RF or uncertainties for use in the
subsequent IPCC Synthesis Report (IPCC, 2001b) (Chapters 2
and 7; Section 9.2).
1.4.5 Cryospheric Topics
The cryosphere, which includes the ice sheets of Greenland
and Antarctica, continental (including tropical) glaciers, snow,
sea ice, river and lake ice, permafrost and seasonally frozen
ground, is an important component of the climate system. The
cryosphere derives its importance to the climate system from
a variety of effects, including its high refl ectivity (albedo) for
solar radiation, its low thermal conductivity, its large thermal
inertia, its potential for affecting ocean circulation (through
exchange of freshwater and heat) and atmospheric circulation
(through topographic changes), its large potential for affecting
sea level (through growth and melt of land ice), and its potential
for affecting greenhouse gases (through changes in permafrost)
(Chapter 4).
Studies of the cryospheric albedo feedback have a long
history. The albedo is the fraction of solar energy refl ected back
to space. Over snow and ice, the albedo (about 0.7 to 0.9) is
large compared to that over the oceans (<0.1). In a warming
climate, it is anticipated that the cryosphere would shrink,
the Earth’s overall albedo would decrease and more solar
energy would be absorbed to warm the Earth still further. This
powerful feedback loop was recognised in the 19th century
by Croll (1890) and was fi rst introduced in climate models by
Budyko (1969) and Sellers (1969). But although the principle
of the albedo feedback is simple, a quantitative understanding
of the effect is still far from complete. For instance, it is not
clear whether this mechanism is the main reason for the high-
latitude amplifi cation of the warming signal.
The potential cryospheric impact on ocean circulation and
sea level are of particular importance. There may be ‘large-scale
discontinuities’ (IPCC, 2001a) resulting from both the shutdown
of the large-scale meridional circulation of the world oceans
(see Section 1.4.6) and the disintegration of large continental
ice sheets. Mercer (1968, 1978) proposed that atmospheric
warming could cause the ice shelves of western Antarctica to
disintegrate and that as a consequence the entire West Antarctic
Ice Sheet (10% of the antarctic ice volume) would lose its land
connection and come afl oat, causing a sea level rise of about
fi ve metres.
The importance of permafrost-climate feedbacks came to be
realised widely only in the 1990s, starting with the works of
110
Chapter 1
Kvenvolden (1988, 1993), MacDonald (1990) and Harriss et al.
(1993). As permafrost thaws due to a warmer climate, CO2 and
CH4 trapped in permafrost are released to the atmosphere. Since
CO2 and CH4 are greenhouse gases, atmospheric temperature is
likely to increase in turn, resulting in a feedback loop with more
permafrost thawing. The permafrost and seasonally thawed soil
layers at high latitudes contain a signifi cant amount (about
one-quarter) of the global total amount of soil carbon. Because
global warming signals are amplifi ed in high-latitude regions,
the potential for permafrost thawing and consequent greenhouse
gas releases is thus large.
In situ monitoring of the cryosphere has a long tradition. For
instance, it is important for fi sheries and agriculture. Seagoing
communities have documented sea ice extent for centuries.
Records of thaw and freeze dates for lake and river ice start
with Lake Suwa in Japan in 1444, and extensive records of
snowfall in China were made during the Qing Dynasty (1644–
1912). Records of glacial length go back to the mid-1500s.
Internationally coordinated, long-term glacier observations
started in 1894 with the establishment of the International
Glacier Commission in Zurich, Switzerland. The longest
time series of a glacial mass balance was started in 1946 at
the Storglaciären in northern Sweden, followed by Storbreen
in Norway (begun in 1949). Today a global network of mass
balance monitoring for some 60 glaciers is coordinated
through the World Glacier Monitoring Service. Systematic
measurements of permafrost (thermal state and active layer)
began in earnest around 1950 and were coordinated under the
Global Terrestrial Network for Permafrost.
The main climate variables of the cryosphere (extent,
albedo, topography and mass) are in principle observable from
space, given proper calibration and validation through in situ
observing efforts. Indeed, satellite data are required in order
to have full global coverage. The polar-orbiting Nimbus 5
satellite, launched in 1972, yielded the earliest all-weather, all-
season imagery of global sea ice, using microwave instruments
(Parkinson et al., 1987), and enabled a major advance in the
scientifi c understanding of the dynamics of the cryosphere.
Launched in 1978, the Television Infrared Observation Satellite
(TIROS-N) yielded the fi rst monitoring from space of snow on
land surfaces (Dozier et al., 1981). The number of cryospheric
elements now routinely monitored from space is growing, and
current satellites are now addressing one of the more challenging
elements, variability of ice volume.
Climate modelling results have pointed to high-latitude
regions as areas of particular importance and ecological
vulnerability to global climate change. It might seem logical to
expect that the cryosphere overall would shrink in a warming
climate or expand in a cooling climate. However, potential
changes in precipitation, for instance due to an altered hydrological
cycle, may counter this effect both regionally and globally.
By the time of the TAR, several climate models incorporated
physically based treatments of ice dynamics, although the land
ice processes were only rudimentary. Improving representation
of the cryosphere in climate models is still an area of intense
research and continuing progress (Chapter 8).
Chapter 1 1.4.6 Ocean and Coupled Ocean-Atmosphere
Dynamics
Developments in the understanding of the oceanic and
atmospheric circulations, as well as their interactions, constitute
a striking example of the continuous interplay among theory,
observations and, more recently, model simulations. The
atmosphere and ocean surface circulations were observed
and analysed globally as early as the 16th and 17th centuries,
in close association with the development of worldwide trade
based on sailing. These efforts led to a number of important
conceptual and theoretical works. For example, Edmund Halley
fi rst published a description of the tropical atmospheric cells in
1686, and George Hadley proposed a theory linking the existence
of the trade winds with those cells in 1735. These early studies
helped to forge concepts that are still useful in analysing and
understanding both the atmospheric general circulation itself
and model simulations (Lorenz, 1967; Holton, 1992).
A comprehensive description of these circulations was
delayed by the lack of necessary observations in the higher
atmosphere or deeper ocean. The balloon record of Gay-Lussac,
who reached an altitude of 7,016 m in 1804, remained unbroken
for more than 50 years. The stratosphere was independently
discovered near the turn of the 20th century by Aßmann (1902)
and Teisserenc de Bort (1902), and the fi rst manned balloon
fl ight into the stratosphere was made in 1901 (Berson and
Süring, 1901). Even though it was recognised over 200 years ago
(Rumford, 1800; see also Warren, 1981) that the oceans’ cold
subsurface waters must originate at high latitudes, it was not
appreciated until the 20th century that the strength of the deep
circulation might vary over time, or that the ocean’s Meridional
Overturning Circulation (MOC; often loosely referred to as
the ‘thermohaline circulation’, see the Glossary for more
information) may be very important for Earth’s climate.
By the 1950s, studies of deep-sea cores suggested that the deep
ocean temperatures had varied in the distant past. Technology
also evolved to enable measurements that could confi rm that
the deep ocean is not only not static, but in fact quite dynamic
(Swallow and Stommel’s 1960 subsurface fl oat experiment
Aries, referred to by Crease, 1962). By the late 1970s, current
meters could monitor deep currents for substantial amounts of
time, and the fi rst ocean observing satellite (SeaSat) revealed
that signifi cant information about subsurface ocean variability
is imprinted on the sea surface. At the same time, the fi rst
estimates of the strength of the meridional transport of heat
and mass were made (Oort and Vonder Haar, 1976; Wunsch,
1978), using a combination of models and data. Since then the
technological developments have accelerated, but monitoring
the MOC directly remains a substantial challenge (see Chapter
5), and routine observations of the subsurface ocean remain
scarce compared to that of the atmosphere.
In parallel with the technological developments yielding
new insights through observations, theoretical and numerical
explorations of multiple (stable or unstable) equilibria began.
Chamberlain (1906) suggested that deep ocean currents could
reverse in direction, and might affect climate. The idea did not
Historical Overview of Climate Change Science
gain momentum until fi fty years later, when Stommel (1961)
presented a mechanism, based on the opposing effects that
temperature and salinity have on density, by which ocean
circulation can fl uctuate between states. Numerical climate
models incorporating models of the ocean circulation were
developed during this period, including the pioneering work of
Bryan (1969) and Manabe and Bryan (1969). The idea that the
ocean circulation could change radically, and might perhaps even
feel the attraction of different equilibrium states, gained further
support through the simulations of coupled climate models
(Bryan and Spelman, 1985; Bryan, 1986; Manabe and Stouffer,
1988). Model simulations using a hierarchy of models showed
that the ocean circulation system appeared to be particularly
vulnerable to changes in the freshwater balance, either by direct
addition of freshwater or by changes in the hydrological cycle.
A strong case emerged for the hypothesis that rapid changes
in the Atlantic meridional circulation were responsible for the
abrupt Dansgaard-Oeschger climate change events.
Although scientists now better appreciate the strength
and variability of the global-scale ocean circulation, its roles
in climate are still hotly debated. Is it a passive recipient of
atmospheric forcing and so merely a diagnostic consequence
of climate change, or is it an active contributor? Observational
evidence for the latter proposition was presented by Sutton and
Allen (1997), who noticed SST anomalies propagating along
the Gulf Stream/North Atlantic Current system for years, and
therefore implicated internal oceanic time scales. Is a radical
change in the MOC likely in the near future? Brewer et al. (1983)
and Lazier (1995) showed that the water masses of the North
Atlantic were indeed changing (some becoming signifi cantly
fresher) in the modern observational record, a phenomenon
that at least raises the possibility that ocean conditions may be
approaching the point where the circulation might shift into
Stommel’s other stable regime. Recent developments in the
ocean’s various roles in climate can be found in Chapters 5, 6,
9 and 10.
Studying the interactions between atmosphere and
ocean circulations was also facilitated through continuous
interactions between observations, theories and simulations,
as is dramatically illustrated by the century-long history of the
advances in understanding the El Niño-Southern Oscillation
(ENSO) phenomenon. This coupled air-sea phenomenon
originates in the Pacifi c but affects climate globally, and has
raised concern since at least the 19th century. Sir Gilbert Walker
(1928) describes how H. H. Hildebrandsson (1897) noted large-
scale relationships between interannual trends in pressure data
from a worldwide network of 68 weather stations, and how
Lockyer and Lockyer (1902) confi rmed Hildebrandsson’s
discovery of an apparent ‘seesaw’ in pressure between South
America and the Indonesian region. Walker named this seesaw
pattern the ‘Southern Oscillation’ and related it to occurrences
of drought and heavy rains in India, Australia, Indonesia and
Africa. He also proposed that there must be a certain level of
predictive skill in that system.
El Niño is the name given to the rather unusual oceanic
conditions involving anomalously warm waters occurring in
111
Historical Overview of Climate Change Science the eastern tropical Pacifi c off the coast of Peru every few years.
The 1957–1958 International Geophysical Year coincided with
a large El Niño, allowing a remarkable set of observations of
the phenomenon. A decade later, a mechanism was presented
that connected Walker’s observations to El Niño (Bjerknes,
1969). This mechanism involved the interaction, through the
SST fi eld, between the east-west atmospheric circulation of
which Walker’s Southern Oscillation was an indicator (Bjerknes
appropriately referred to this as the ‘Walker Circulation’) and
variability in the pool of equatorial warm water of the Pacifi c
Ocean. Observations made in the 1970s (e.g., Wyrtki, 1975)
showed that prior to ENSO warm phases, the sea level in the
western Pacifi c often rises signifi cantly. By the mid-1980s,
after an unusually disruptive El Niño struck in 1982 and 1983,
an observing system (the Tropical Ocean Global Atmosphere
(TOGA) array; see McPhaden et al., 1998) had been put in
place to monitor ENSO. The resulting data confi rmed the idea
that the phenomenon was inherently one involving coupled
atmosphere-ocean interactions and yielded much-needed
detailed observational insights. By 1986, the fi rst experimental
ENSO forecasts were made (Cane et al., 1986; Zebiak and
Cane, 1987).
The mechanisms and predictive skill of ENSO are still
under discussion. In particular, it is not clear how ENSO
changes with, and perhaps interacts with, a changing climate.
The TAR states ‘...increasing evidence suggests the ENSO
plays a fundamental role in global climate and its interannual
variability, and increased credibility in both regional and global
climate projections will be gained once realistic ENSOs and
their changes are simulated’.
Just as the phenomenon of El Niño has been familiar to the
people of tropical South America for centuries, a spatial pattern
affecting climate variability in the North Atlantic has similarly
been known by the people of Northern Europe for a long time.
The Danish missionary Hans Egede made the following well-
known diary entry in the mid-18th century: ‘In Greenland,
all winters are severe, yet they are not alike. The Danes have
noticed that when the winter in Denmark was severe, as we
perceive it, the winter in Greenland in its manner was mild, and
conversely’ (van Loon and Rogers, 1978).
Teisserenc de Bort, Hann, Exner, Defant and Walker all
contributed to the discovery of the underlying dynamic structure.
Walker, in his studies in the Indian Ocean, actually studied global
maps of sea level pressure correlations, and named not only the
Southern Oscillation, but also a Northern Oscillation, which he
subsequently divided into a North Pacifi c and a North Atlantic
Oscillation (Walker, 1924). However, it was Exner (1913, 1924)
who made the fi rst correlation maps showing the spatial structure
in the NH, where the North Atlantic Oscillation (NAO) pattern
stands out clearly as a north-south oscillation in atmospheric
mass with centres of action near Iceland and Portugal.
The NAO signifi cantly affects weather and climate,
ecosystems and human activities of the North Atlantic sector.
But what is the underlying mechanism? The recognition that
the NAO is associated with variability and latitudinal shifts in
the westerly fl ow of the jet stream originates with the works of
112
Chapter 1
Willett, Namias, Lorenz, Rossby and others in the 1930s, 1940s
and 1950s (reviewed by Stephenson et al., 2003). Because
atmospheric planetary waves are hemispheric in nature, changes
in one region are often connected with changes in other regions,
a phenomenon dubbed ‘teleconnection’ (Wallace and Gutzler,
1981).
The NAO may be partly described as a high-frequency
stochastic process internal to the atmosphere. This understanding
is evidenced by numerous atmosphere-only model simulations.
It is also considered an expression of one of Earth’s ‘annular
modes’ (See Chapter 3). It is, however, the low-frequency
variability of this phenomenon (Hurrell, 1995) that fuels
continued investigations by climate scientists. The long time
scales are the indication of potential predictive skill in the NAO.
The mechanisms responsible for the correspondingly long
‘memory’ are still debated, although they are likely to have a
local or remote oceanic origin. Bjerknes (1964) recognised the
connection between the NAO index (which he referred to as the
‘zonal index’) and sea surface conditions. He speculated that
ocean heat advection could play a role on longer time scales.
The circulation of the Atlantic Ocean is radically different
from that of the Indian and Pacifi c Oceans, in that the MOC is
strongest in the Atlantic with warm water fl owing northwards,
even south of the equator, and cold water returning at depth. It
would therefore not be surprising if the oceanic contributions to
the NAO and to the Southern Oscillation were different.
Earth’s climate is characterised by many modes of variability,
involving both the atmosphere and ocean, and also the
cryosphere and biosphere. Understanding the physical processes
involved in producing low-frequency variability is crucial
for improving scientists’ ability to accurately predict climate
change and for allowing the separation of anthropogenic and
natural variability, thereby improving the ability to detect and
attribute anthropogenic climate change. One central question
for climate scientists, addressed in particular in Chapter 9, is to
determine how human activities infl uence the dynamic nature
of Earth’s climate, and to identify what would have happened
without any human infl uence at all.
1.5 Examples of Progress in
Modelling the Climate
1.5.1 Model Evolution and Model Hierarchies
Climate scenarios rely upon the use of numerical models.
The continuous evolution of these models over recent decades
has been enabled by a considerable increase in computational
capacity, with supercomputer speeds increasing by roughly
a factor of a million in the three decades from the 1970s to
the present. This computational progress has permitted a
corresponding increase in model complexity (by including
more and more components and processes, as depicted in Figure
1.2), in the length of the simulations, and in spatial resolution,
Chapter 1 Historical Overview of Climate Change Science
as shown in Figure 1.4. The models used to evaluate future
climate changes have therefore evolved over time. Most of the
pioneering work on CO2-induced climate change was based on
atmospheric general circulation models coupled to simple ‘slab’
ocean models (i.e., models omitting ocean dynamics), from the
early work of Manabe and Wetherald (1975) to the review of
Schlesinger and Mitchell (1987). At the same time the physical
content of the models has become more comprehensive (see
in Section 1.5.2 the example of clouds). Similarly, most of the
results presented in the FAR were from atmospheric models,
rather than from models of the coupled climate system, and were
used to analyse changes in the equilibrium climate resulting
from a doubling of the atmospheric CO2 concentration. Current
climate projections can investigate time-dependent scenarios of
climate evolution and can make use of much more complex
coupled ocean-atmosphere models, sometimes even including
interactive chemical or biochemical components.
A parallel evolution toward increased complexity and
resolution has occurred in the domain of numerical weather
prediction, and has resulted in a large and verifi able improvement
in operational weather forecast quality. This example alone
shows that present models are more realistic than were those of
a decade ago. There is also, however, a continuing awareness
that models do not provide a perfect simulation of reality,
because resolving all important spatial or time scales remains
far beyond current capabilities, and also because the behaviour
of such a complex nonlinear system may in general be chaotic.
It has been known since the work of Lorenz (1963) that even
simple models may display intricate behaviour because of their
nonlinearities. The inherent nonlinear behaviour of the climate
system appears in climate simulations at all time scales (Ghil,
1989). In fact, the study of nonlinear dynamical systems has
become important for a wide range of scientifi c disciplines, and
the corresponding mathematical developments are essential to
interdisciplinary studies. Simple models of ocean-atmosphere
interactions, climate-biosphere interactions or climate-economy
interactions may exhibit a similar behaviour, characterised by
partial unpredictability, bifurcations and transition to chaos.
In addition, many of the key processes that control climate
sensitivity or abrupt climate changes (e.g., clouds, vegetation,
oceanic convection) depend on very small spatial scales. They
cannot be represented in full detail in the context of global
models, and scientifi c understanding of them is still notably
incomplete. Consequently, there is a continuing need to assist
in the use and interpretation of complex models through models
that are either conceptually simpler, or limited to a number of
processes or to a specifi c region, therefore enabling a deeper
understanding of the processes at work or a more relevant
comparison with observations. With the development of
computer capacities, simpler models have not disappeared; on
the contrary, a stronger emphasis has been given to the concept
of a ‘hierarchy of models’ as the only way to provide a linkage
between theoretical understanding and the complexity of
realistic models (Held, 2005).
The list of these ‘simpler’ models is very long. Simplicity
may lie in the reduced number of equations (e.g., a single
Figure 1.4. Geographic resolution characteristic of the generations of climate
models used in the IPCC Assessment Reports: FAR (IPCC, 1990), SAR (IPCC, 1996),
TAR (IPCC, 2001a), and AR4 (2007). The fi gures above show how successive genera-
tions of these global models increasingly resolved northern Europe. These illustra-
tions are representative of the most detailed horizontal resolution used for short-term
climate simulations. The century-long simulations cited in IPCC Assessment Reports
after the FAR were typically run with the previous generation’s resolution. Vertical
resolution in both atmosphere and ocean models is not shown, but it has increased
comparably with the horizontal resolution, beginning typically with a single-layer slab
ocean and ten atmospheric layers in the FAR and progressing to about thirty levels in
both atmosphere and ocean.
113
Historical Overview of Climate Change Science equation for the global surface temperature); in the reduced
dimensionality of the problem (one-dimension vertical, one-
dimension latitudinal, two-dimension); or in the restriction
to a few processes (e.g., a mid-latitude quasi-geostrophic
atmosphere with or without the inclusion of moist processes).
The notion of model hierarchy is also linked to the idea of scale:
global circulation models are complemented by regional models
that exhibit a higher resolution over a given area, or process
oriented models, such as cloud resolving models or large eddy
simulations. Earth Models of Intermediate Complexity are used
to investigate long time scales, such as those corresponding to
glacial to interglacial oscillations (Berger et al., 1998). This
distinction between models according to scale is evolving
quickly, driven by the increase in computer capacities. For
example, global models explicitly resolving the dynamics of
convective clouds may soon become computationally feasible.
Many important scientifi c debates in recent years have had
their origin in the use of conceptually simple models. The
study of idealised atmospheric representations of the tropical
climate, for example by Pierrehumbert (1995) who introduced
a separate representation of the areas with ascending and
subsiding circulation in the tropics, has signifi cantly improved
the understanding of the feedbacks that control climate. Simple
linearized models of the atmospheric circulation have been
used to investigate potential new feedback effects. Ocean
box models have played an important role in improving the
understanding of the possible slowing down of the Atlantic
thermohaline circulation (Birchfi eld et al., 1990), as emphasized
in the TAR. Simple models have also played a central role in the
interpretation of IPCC scenarios: the investigation of climate
scenarios presented in the SAR or the TAR has been extended
to larger ensembles of cases using idealised models.
1.5.2 Model Clouds and Climate Sensitivity
The modelling of cloud processes and feedbacks provides
a striking example of the irregular pace of progress in climate
science. Representation of clouds may constitute the area
in which atmospheric models have been modifi ed most
continuously to take into account increasingly complex physical
processes. At the time of the TAR clouds remained a major
source of uncertainty in the simulation of climate changes (as
they still are at present: e.g., Sections 2.4, 2.6, 3.4.3, 7.5, 8.2,
8.4.11, 8.6.2.2, 8.6.3.2, 9.2.1.2, 9.4.1.8, 10.2.1.2, 10.3.2.2,
10.5.4.3, 11.8.1.3, 11.8.2.2).
In the early 1980s, most models were still using prescribed
cloud amounts, as functions of location and altitude, and
prescribed cloud radiative properties, to compute atmospheric
radiation. The cloud amounts were very often derived from the
zonally averaged climatology of London (1957). Succeeding
generations of models have used relative humidity or other
simple predictors to diagnose cloudiness (Slingo, 1987), thus
providing a foundation of increased realism for the models,
but at the same time possibly causing inconsistencies in
the representation of the multiple roles of clouds as bodies
interacting with radiation, generating precipitation and
114
Chapter 1
infl uencing small-scale convective or turbulent circulations.
Following the pioneering studies of Sundqvist (1978), an explicit
representation of clouds was progressively introduced into
climate models, beginning in the late 1980s. Models fi rst used
simplifi ed representations of cloud microphysics, following,
for example, Kessler (1969), but more recent generations of
models generally incorporate a much more comprehensive and
detailed representation of clouds, based on consistent physical
principles. Comparisons of model results with observational
data presented in the TAR have shown that, based on zonal
averages, the representation of clouds in most climate models
was also more realistic in 2000 than had been the case only a
few years before.
In spite of this undeniable progress, the amplitude and
even the sign of cloud feedbacks was noted in the TAR as
highly uncertain, and this uncertainty was cited as one of the
key factors explaining the spread in model simulations of
future climate for a given emission scenario. This cannot be
regarded as a surprise: that the sensitivity of the Earth’s climate
to changing atmospheric greenhouse gas concentrations must
depend strongly on cloud feedbacks can be illustrated on the
simplest theoretical grounds, using data that have been available
for a long time. Satellite measurements have indeed provided
meaningful estimates of Earth’s radiation budget since the early
1970s (Vonder Haar and Suomi, 1971). Clouds, which cover
about 60% of the Earth’s surface, are responsible for up to two-
thirds of the planetary albedo, which is about 30%. An albedo
decrease of only 1%, bringing the Earth’s albedo from 30%
to 29%, would cause an increase in the black-body radiative
equilibrium temperature of about 1°C, a highly signifi cant value,
roughly equivalent to the direct radiative effect of a doubling
of the atmospheric CO2 concentration. Simultaneously, clouds
make an important contribution to the planetary greenhouse
effect. In addition, changes in cloud cover constitute only one
of the many parameters that affect cloud radiative interactions:
cloud optical thickness, cloud height and cloud microphysical
properties can also be modifi ed by atmospheric temperature
changes, which adds to the complexity of feedbacks, as
evidenced, for example, through satellite observations analysed
by Tselioudis and Rossow (1994).
The importance of simulated cloud feedbacks was revealed
by the analysis of model results (Manabe and Wetherald,
1975; Hansen et al, 1984), and the fi rst extensive model
intercomparisons (Cess et al., 1989) also showed a substantial
model dependency. The strong effect of cloud processes on
climate model sensitivities to greenhouse gases was emphasized
further through a now-classic set of General Circulation Model
(GCM) experiments, carried out by Senior and Mitchell (1993).
They produced global average surface temperature changes
(due to doubled atmospheric CO2 concentration) ranging from
1.9°C to 5.4°C, simply by altering the way that cloud radiative
properties were treated in the model. It is somewhat unsettling
that the results of a complex climate model can be so drastically
altered by substituting one reasonable cloud parametrization
for another, thereby approximately replicating the overall inter-
model range of sensitivities. Other GCM groups have also
Chapter 1 Historical Overview of Climate Change Science
Frequently Asked Question 1.3
What is the Greenhouse Effect?
The Sun powers Earth’s climate, radiating energy at very short
wavelengths, predominately in the visible or near-visible (e.g., ul-
traviolet) part of the spectrum. Roughly one-third of the solar
energy that reaches the top of Earth’s atmosphere is refl ected di-
rectly back to space. The remaining two-thirds is absorbed by the
surface and, to a lesser extent, by the atmosphere. To balance the
absorbed incoming energy, the Earth must, on average, radiate the
same amount of energy back to space. Because the Earth is much
colder than the Sun, it radiates at much longer wavelengths, pri-
marily in the infrared part of the spectrum (see Figure 1). Much
of this thermal radiation emitted by the land and ocean is ab-
sorbed by the atmosphere, including clouds, and reradiated back
to Earth. This is called the greenhouse effect. The glass walls in
a greenhouse reduce airfl ow and increase the temperature of the
air inside. Analogously, but through a different physical process,
the Earth’s greenhouse effect warms the surface of the planet.
Without the natural greenhouse effect, the average temperature at
Earth’s surface would be below the freezing point of water. Thus,
Earth’s natural greenhouse effect makes life as we know it pos-
sible. However, human activities, primarily the burning of fossil
fuels and clearing of forests, have greatly intensifi ed the natural
greenhouse effect, causing global warming.
The two most abundant gases in the atmosphere, nitrogen
(comprising 78% of the dry atmosphere) and oxygen (comprising
21%), exert almost no greenhouse effect. Instead, the greenhouse
effect comes from molecules that are more complex and much less
common. Water vapour is the most important greenhouse gas, and
carbon dioxide (CO2) is the second-most important one. Methane,
nitrous oxide, ozone and several other gases present in the atmo-
sphere in small amounts also contribute to the greenhouse effect.
In the humid equatorial regions, where there is so much water
vapour in the air that the greenhouse effect is very large, add-
ing a small additional amount of CO2 or water vapour has only a
small direct impact on downward infrared radiation. However, in
the cold, dry polar regions, the effect of a small increase in CO2 or
(continued)
FAQ 1.3, Figure 1. An idealised model of the natural greenhouse effect. See text for explanation.
115
Historical Overview of Climate Change Science water vapour is much greater. The same is true for the cold, dry
upper atmosphere where a small increase in water vapour has a
greater infl uence on the greenhouse effect than the same change
in water vapour would have near the surface.
Several components of the climate system, notably the oceans
and living things, affect atmospheric concentrations of green-
house gases. A prime example of this is plants taking CO2 out of
the atmosphere and converting it (and water) into carbohydrates
via photosynthesis. In the industrial era, human activities have
added greenhouse gases to the atmosphere, primarily through the
burning of fossil fuels and clearing of forests.
Adding more of a greenhouse gas, such as CO2, to the at-
mosphere intensifi es the greenhouse effect, thus warming Earth’s
climate. The amount of warming depends on various feedback
mechanisms. For example, as the atmosphere warms due to rising
levels of greenhouse gases, its concentration of water vapour
consistently obtained widely varying results by trying other
techniques of incorporating cloud microphysical processes and
their radiative interactions (e.g., Roeckner et al., 1987; Le Treut
and Li, 1991), which differed from the approach of Senior and
Mitchell (1993) through the treatment of partial cloudiness or
mixed-phase properties. The model intercomparisons presented
in the TAR showed no clear resolution of this unsatisfactory
situation.
The scientifi c community realised long ago that using
adequate data to constrain models was the only way to solve this
problem. Using climate changes in the distant past to constrain
the amplitude of cloud feedback has defi nite limitations
(Ramstein et al., 1998). The study of cloud changes at decadal,
interannual or seasonal time scales therefore remains a necessary
path to constrain models. A long history of cloud observations
now runs parallel to that of model development. Operational
ground-based measurements, carried out for the purpose of
weather prediction, constitute a valuable source of information
that has been gathered and analysed by Warren et al. (1986,
1988). The International Satellite Cloud Climatology Project
(ISCCP; Rossow and Schiffer, 1991) has developed an analysis
of cloud cover and cloud properties using the measurements
of operational meteorological satellites over a period of more
than two decades. These data have been complemented by
other satellite remote sensing data sets, such as those associated
with the Nimbus-7 Temperature Humidity Infrared Radiometer
(THIR) instrument (Stowe et al., 1988), with high-resolution
spectrometers such as the High Resolution Infrared Radiation
Sounder (HIRS) (Susskind et al., 1987), and with microwave
absorption, as used by the Special Sensor Microwave/Imager
(SSM/I). Chapter 8 provides an update of this ongoing
observational effort.
A parallel effort has been carried out to develop a wider
range of ground-based measurements, not only to provide an
116
Chapter 1
increases, further intensifying the greenhouse effect. This in turn
causes more warming, which causes an additional increase in
water vapour, in a self-reinforcing cycle. This water vapour feed-
back may be strong enough to approximately double the increase
in the greenhouse effect due to the added CO2 alone.
Additional important feedback mechanisms involve clouds.
Clouds are effective at absorbing infrared radiation and therefore
exert a large greenhouse effect, thus warming the Earth. Clouds
are also effective at refl ecting away incoming solar radiation, thus
cooling the Earth. A change in almost any aspect of clouds, such
as their type, location, water content, cloud altitude, particle size
and shape, or lifetimes, affects the degree to which clouds warm
or cool the Earth. Some changes amplify warming while others
diminish it. Much research is in progress to better understand how
clouds change in response to climate warming, and how these
changes affect climate through various feedback mechanisms.
adequate reference for satellite observations, but also to make
possible a detailed and empirically based analysis of the entire
range of space and time scales involved in cloud processes.
The longest-lasting and most comprehensive effort has been
the Atmospheric Radiation Measurement (ARM) Program
in the USA, which has established elaborately instrumented
observational sites to monitor the full complexity of cloud
systems on a long-term basis (Ackerman and Stokes, 2003).
Shorter fi eld campaigns dedicated to the observation of specifi c
phenomena have also been established, such as the TOGA
Coupled Ocean-Atmosphere Response Experiment (COARE)
for convective systems (Webster and Lukas, 1992), or the
Atlantic Stratocumulus Transition Experiment (ASTEX) for
stratocumulus (Albrecht et al., 1995).
Observational data have clearly helped the development of
models. The ISCCP data have greatly aided the development
of cloud representations in climate models since the mid-1980s
(e.g., Le Treut and Li, 1988; Del Genio et al., 1996). However,
existing data have not yet brought about any reduction in the
existing range of simulated cloud feedbacks. More recently,
new theoretical tools have been developed to aid in validating
parametrizations in a mode that emphasizes the role of cloud
processes participating in climatic feedbacks. One such approach
has been to focus on comprehensively observed episodes of
cloudiness for which the large-scale forcing is observationally
known, using single-column models (Randall et al., 1996;
Somerville, 2000) and higher-resolution cloud-resolving
models to evaluate GCM parametrizations. Another approach
is to make use of the more global and continuous satellite data,
on a statistical basis, through an investigation of the correlation
between climate forcing and cloud parameters (Bony et al.,
1997), in such a way as to provide a test of feedbacks between
different climate variables. Chapter 8 assesses recent progress
in this area.
Chapter 1 1.5.3 Coupled Models: Evolution, Use,
Assessment
The fi rst National Academy of Sciences of the USA report
on global warming (Charney et al., 1979), on the basis of two
models simulating the impact of doubled atmospheric CO2
concentrations, spoke of a range of global mean equilibrium
surface temperature increase of between 1.5°C and 4.5°C, a
range that has remained part of conventional wisdom at least as
recently as the TAR. These climate projections, as well as those
treated later in the comparison of three models by Schlesinger
and Mitchell (1987) and most of those presented in the FAR,
were the results of atmospheric models coupled with simple
‘slab’ ocean models (i.e., models omitting all changes in ocean
dynamics).
The fi rst attempts at coupling atmospheric and oceanic
models were carried out during the late 1960s and early 1970s
(Manabe and Bryan, 1969; Bryan et al., 1975; Manabe et al.,
1975). Replacing ‘slab’ ocean models by fully coupled ocean-
atmosphere models may arguably have constituted one of the
most signifi cant leaps forward in climate modelling during the
last 20 years (Trenberth, 1993), although both the atmospheric
and oceanic components themselves have undergone highly
signifi cant improvements. This advance has led to signifi cant
modifi cations in the patterns of simulated climate change,
particularly in oceanic regions. It has also opened up the
possibility of exploring transient climate scenarios, and it
constitutes a step toward the development of comprehensive
‘Earth-system models’ that include explicit representations of
chemical and biogeochemical cycles.
Throughout their short history, coupled models have faced
diffi culties that have considerably impeded their development,
including: (i) the initial state of the ocean is not precisely known;
(ii) a surface fl ux imbalance (in either energy, momentum or
fresh water) much smaller than the observational accuracy is
enough to cause a drifting of coupled GCM simulations into
unrealistic states; and (iii) there is no direct stabilising feedback
that can compensate for any errors in the simulated salinity. The
strong emphasis placed on the realism of the simulated base
state provided a rationale for introducing ‘fl ux adjustments’ or
‘fl ux corrections’ (Manabe and Stouffer, 1988; Sausen et al.,
1988) in early simulations. These were essentially empirical
corrections that could not be justifi ed on physical principles,
and that consisted of arbitrary additions of surface fl uxes of
heat and salinity in order to prevent the drift of the simulated
climate away from a realistic state. The National Center for
Atmospheric Research model may have been the fi rst to realise
non-fl ux-corrected coupled simulations systematically, and it
was able to achieve simulations of climate change into the 21st
century, in spite of a persistent drift that still affected many of
its early simulations. Both the FAR and the SAR pointed out the
apparent need for fl ux adjustments as a problematic feature of
climate modelling (Cubasch et al., 1990; Gates et al., 1996).
By the time of the TAR, however, the situation had evolved,
and about half the coupled GCMs assessed in the TAR did not
Historical Overview of Climate Change Science
employ fl ux adjustments. That report noted that ‘some non-fl ux-
adjusted models are now able to maintain stable climatologies
of comparable quality to fl ux-adjusted models’ (McAvaney et
al., 2001). Since that time, evolution away from fl ux correction
(or fl ux adjustment) has continued at some modelling centres,
although a number of state-of-the-art models continue to rely on
it. The design of the coupled model simulations is also strongly
linked with the methods chosen for model initialisation. In fl ux-
adjusted models, the initial ocean state is necessarily the result
of preliminary and typically thousand-year-long simulations
to bring the ocean model into equilibrium. Non-fl ux-adjusted
models often employ a simpler procedure based on ocean
observations, such as those compiled by Levitus et al. (1994),
although some spin-up phase is even then necessary. One
argument brought forward is that non-adjusted models made
use of ad hoc tuning of radiative parameters (i.e., an implicit
fl ux adjustment).
This considerable advance in model design has not
diminished the existence of a range of model results. This is not
a surprise, however, because it is known that climate predictions
are intrinsically affected by uncertainty (Lorenz, 1963). Two
distinct kinds of prediction problems were defi ned by Lorenz
(1975). The fi rst kind was defi ned as the prediction of the actual
properties of the climate system in response to a given initial
state. Predictions of the fi rst kind are initial-value problems
and, because of the nonlinearity and instability of the governing
equations, such systems are not predictable indefi nitely into the
future. Predictions of the second kind deal with the determination
of the response of the climate system to changes in the external
forcings. These predictions are not concerned directly with the
chronological evolution of the climate state, but rather with
the long-term average of the statistical properties of climate.
Originally, it was thought that predictions of the second kind do
not at all depend on initial conditions. Instead, they are intended
to determine how the statistical properties of the climate system
(e.g., the average annual global mean temperature, or the
expected number of winter storms or hurricanes, or the average
monsoon rainfall) change as some external forcing parameter,
for example CO2 content, is altered. Estimates of future climate
scenarios as a function of the concentration of atmospheric
greenhouse gases are typical examples of predictions of the
second kind. However, ensemble simulations show that the
projections tend to form clusters around a number of attractors
as a function of their initial state (see Chapter 10).
Uncertainties in climate predictions (of the second kind)
arise mainly from model uncertainties and errors. To assess
and disentangle these effects, the scientifi c community has
organised a series of systematic comparisons of the different
existing models, and it has worked to achieve an increase in
the number and range of simulations being carried out in order
to more fully explore the factors affecting the accuracy of the
simulations.
An early example of systematic comparison of models
is provided by Cess et al. (1989), who compared results of
documented differences among model simulations in their
117
Historical Overview of Climate Change Science representation of cloud feedback to show how the consequent
effects on atmospheric radiation resulted in different model
response to doubling of the CO2 concentration. A number of
ambitious and comprehensive ‘model intercomparison projects’
(MIPs) were set up in the 1990s under the auspices of the World
Climate Research Programme to undertake controlled conditions
for model evaluation. One of the fi rst was the Atmospheric Model
Intercomparison Project (AMIP), which studied atmospheric
GCMs. The development of coupled models induced the
development of the Coupled Model Intercomparison Project
(CMIP), which studied coupled ocean-atmosphere GCMs and
their response to idealised forcings, such as a 1% yearly increase
in the atmospheric CO2 concentration. It proved important in
carrying out the various MIPs to standardise the model forcing
parameters and the model output so that fi le formats, variable
names, units, etc., are easily recognised by data users. The fact
that the model results were stored separately and independently
of the modelling centres, and that the analysis of the model
output was performed mainly by research groups independent
of the modellers, has added confi dence in the results. Summary
diagnostic products such as the Taylor (2001) diagram were
developed for MIPs.
The establishment of the AMIP and CMIP projects opened
a new era for climate modelling, setting standards of quality
control, providing organisational continuity and ensuring that
results are generally reproducible. Results from AMIP have
provided a number of insights into climate model behaviour
(Gates et al., 1999) and quantifi ed improved agreement between
simulated and observed atmospheric properties as new versions
of models are developed. In general, results of the MIPs suggest
that the most problematic areas of coupled model simulations
involve cloud-radiation processes, the cryosphere, the deep
ocean and ocean-atmosphere interactions.
Comparing different models is not suffi cient, however. Using
multiple simulations from a single model (the so-called Monte
Carlo, or ensemble, approach) has proved a necessary and
complementary approach to assess the stochastic nature of the
climate system. The fi rst ensemble climate change simulations
with global GCMs used a set of different initial and boundary
conditions (Cubasch et al., 1994; Barnett, 1995). Computational
constraints limited early ensembles to a relatively small number
of samples (fewer than 10). These ensemble simulations clearly
indicated that even with a single model a large spread in the
climate projections can be obtained.
Intercomparison of existing models and ensemble model
studies (i.e., those involving many integrations of the same
model) are still undergoing rapid development. Running
ensembles was essentially impossible until recent advances in
computer power occurred, as these systematic comprehensive
climate model studies are exceptionally demanding on computer
resources. Their progress has marked the evolution from the
FAR to the TAR, and is likely to continue in the years to come.
118
Chapter 1
1.6 The IPCC Assessments of Climate
Change and Uncertainties
The WMO and the United Nations Environment Programme
(UNEP) established the IPCC in 1988 with the assigned
role of assessing the scientifi c, technical and socioeconomic
information relevant for understanding the risk of human-
induced climate change. The original 1988 mandate for the
IPCC was extensive: ‘(a) Identifi cation of uncertainties and
gaps in our present knowledge with regard to climate changes
and its potential impacts, and preparation of a plan of action
over the short-term in fi lling these gaps; (b) Identifi cation of
information needed to evaluate policy implications of climate
change and response strategies; (c) Review of current and
planned national/international policies related to the greenhouse
gas issue; (d) Scientifi c and environmental assessments of all
aspects of the greenhouse gas issue and the transfer of these
assessments and other relevant information to governments
and intergovernmental organisations to be taken into account
in their policies on social and economic development and
environmental programs.’ The IPCC is open to all members of
UNEP and WMO. It does not directly support new research or
monitor climate-related data. However, the IPCC process of
synthesis and assessment has often inspired scientifi c research
leading to new fi ndings.
The IPCC has three Working Groups and a Task Force.
Working Group I (WGI) assesses the scientifi c aspects of the
climate system and climate change, while Working Groups II
(WGII) and III (WGIII) assess the vulnerability and adaptation
of socioeconomic and natural systems to climate change, and
the mitigation options for limiting greenhouse gas emissions,
respectively. The Task Force is responsible for the IPCC
National Greenhouse Gas Inventories Programme. This brief
history focuses on WGI and how it has described uncertainty in
the quantities presented (See Box 1.1).
A main activity of the IPCC is to provide on a regular basis
an assessment of the state of knowledge on climate change, and
this volume is the fourth such Assessment Report of WGI. The
IPCC also prepares Special Reports and Technical Papers on
topics for which independent scientifi c information and advice is
deemed necessary, and it supports the United Nations Framework
Convention on Climate Change (UNFCCC) through its work
on methodologies for National Greenhouse Gas Inventories.
The FAR played an important role in the discussions of the
Intergovernmental Negotiating Committee for the UNFCCC.
The UNFCCC was adopted in 1992 and entered into force in
1994. It provides the overall policy framework and legal basis
for addressing the climate change issue.
The WGI FAR was completed under the leadership of Bert
Bolin (IPCC Chair) and John Houghton (WGI Chair) in a
plenary at Windsor, UK in May 1990. In a mere 365 pages with
eight colour plates, it made a persuasive, but not quantitative,
case for anthropogenic interference with the climate system.
Most conclusions from the FAR were non-quantitative and
Chapter 1 remain valid today (see also Section 1.4.4). For example, in
terms of the greenhouse gases, ‘emissions resulting from
human activities are substantially increasing the atmospheric
concentrations of the greenhouse gases: CO2, CH4, CFCs, N2O’
(see Chapters 2 and 3; Section 7.1). On the other hand, the FAR
did not foresee the phase-out of CFCs, missed the importance
of biomass-burning aerosols and dust to climate and stated
that unequivocal detection of the enhanced greenhouse effect
was more than a decade away. The latter two areas highlight
the advance of climate science and in particular the merging
of models and observations in the new fi eld of detection and
attribution (see Section 9.1).
The Policymakers Summary of the WGI FAR gave a broad
overview of climate change science and its Executive Summary
separated key fi ndings into areas of varying levels of confi dence
ranging from ‘certainty’ to providing an expert ‘judgment’.
Much of the summary is not quantitative (e.g., the radiative
forcing bar charts do not appear in the summary). Similarly,
scientifi c uncertainty is hardly mentioned; when ranges are
given, as in the projected temperature increases of 0.2°C to
0.5°C per decade, no probability or likelihood is assigned to
explain the range (see Chapter 10). In discussion of the climate
sensitivity to doubled atmospheric CO2 concentration, the
combined subjective and objective criteria are explained: the
range of model results was 1.9°C to 5.2°C; most were close to
4.0°C; but the newer model results were lower; and hence the
best estimate was 2.5°C with a range of 1.5°C to 4.5°C. The
likelihood of the value being within this range was not defi ned.
However, the importance of identifying those areas where
climate scientists had high confi dence was recognised in the
Policymakers Summary.
The Supplementary Report (IPCC, 1992) re-evaluated the
RF values of the FAR and included the new IPCC scenarios for
future emissions, designated IS92a–f. It also included updated
chapters on climate observations and modelling (see Chapters 3,
4, 5, 6 and 8). The treatment of scientifi c uncertainty remained
as in the FAR. For example, the calculated increase in global
mean surface temperature since the 19th century was given as
0.45°C ± 0.15°C, with no quantitative likelihood for this range
(see Section 3.2).
The SAR, under Bert Bolin (IPCC Chair) and John Houghton
and Gylvan Meira Filho (WGI Co-chairs), was planned with
and coupled to a preliminary Special Report (IPCC, 1995) that
contained intensive chapters on the carbon cycle, atmospheric
chemistry, aerosols and radiative forcing. The WGI SAR
culminated in the government plenary in Madrid in November
1995. The most cited fi nding from that plenary, on attribution of
climate change, has been consistently reaffi rmed by subsequent
research: ‘The balance of evidence suggests a discernible
human infl uence on global climate’ (see Chapter 9). The SAR
provided key input to the negotiations that led to the adoption
in 1997 of the Kyoto Protocol to the UNFCCC.
Uncertainty in the WGI SAR was defi ned in a number of
ways. The carbon cycle budgets used symmetric plus/minus
ranges explicitly defi ned as 90% confi dence intervals, whereas
the RF bar chart reported a ‘mid-range’ bar along with a
Historical Overview of Climate Change Science
plus/minus range that was estimated largely on the spread of
published values. The likelihood, or confi dence interval, of the
spread of published results was not given. These uncertainties
were additionally modifi ed by a declaration that the confi dence
of the RF being within the specifi ed range was indicated by
a stated confi dence level that ranged from ‘high’ (greenhouse
gases) to ‘very low’ (aerosols). Due to the diffi culty in
approving such a long draft in plenary, the Summary for Policy
Makers (SPM) became a short document with no fi gures and
few numbers. The use of scientifi c uncertainty in the SPM was
thus limited and similar to the FAR: a range in the mean surface
temperature increase since 1900 was given as 0.3°C to 0.6°C
with no explanation as to likelihood of this range. While the
underlying report showed projected future warming for a range
of different climate models, the Technical Summary focused on
a central estimate.
The IPCC Special Report on Aviation and the Global
Atmosphere (IPCC, 1999) was a major interim assessment
involving both WGI and WGIII and the Scientifi c Assessment
Panel to the Montreal Protocol on Substances that Deplete the
Ozone Layer. It assessed the impacts of civil aviation in terms
of climate change and global air quality as well as looking
at the effect of technology options for the future fl eet. It was
the fi rst complete assessment of an industrial sub-sector. The
summary related aviation’s role relative to all human infl uence
on the climate system: ‘The best estimate of the radiative
forcing in 1992 by aircraft is 0.05 W m–2 or about 3.5% of
the total radiative forcing by all anthropogenic activities.’ The
authors took a uniform approach to assigning and propagating
uncertainty in these RF values based on mixed objective and
subjective criteria. In addition to a best value, a two-thirds
likelihood (67% confi dence) interval is given. This interval
is similar to a one-sigma (i.e., one standard deviation) normal
error distribution, but it was explicitly noted that the probability
distribution outside this interval was not evaluated and might
not have a normal distribution. A bar chart with ‘whiskers’
(two-thirds likelihood range) showing the components and total
(without cirrus effects) RF for aviation in 1992 appeared in the
SPM (see Sections 2.6 and 10.2).
The TAR, under Robert Watson (IPCC Chair) and John
Houghton and Ding YiHui (WGI Co-chairs), was approved
at the government plenary in Shanghai in January 2001.
The predominant summary statements from the TAR WGI
strengthened the SAR’s attribution statement: ‘An increasing
body of observations gives a collective picture of a warming
world and other changes in the climate system’, and ‘There is
new and stronger evidence that most of the warming observed
over the last 50 years is attributable to human activities.’ The
TAR Synthesis Report (IPCC, 2001b) combined the assessment
reports from the three Working Groups. By combining data
on global (WGI) and regional (WGII) climate change, the
Synthesis Report was able to strengthen the conclusion
regarding human infl uence: ‘The Earth’s climate system has
demonstrably changed on both global and regional scales since
the pre-industrial era, with some of these changes attributable
to human activities’ (see Chapter 9).
119
Historical Overview of Climate Change Science Chapter 1
Box 1.1: Treatment of Uncertainties in the Working Group I Assessment
The importance of consistent and transparent treatment of uncertainties is clearly recognised by the IPCC in preparing its assess-
ments of climate change. The increasing attention given to formal treatments of uncertainty in previous assessments is addressed in
Section 1.6. To promote consistency in the general treatment of uncertainty across all three Working Groups, authors of the Fourth
Assessment Report have been asked to follow a brief set of guidance notes on determining and describing uncertainties in the context
of an assessment .1 This box summarises the way that Working Group I has applied those guidelines and covers some aspects of the
treatment of uncertainty specifi c to material assessed here.
Uncertainties can be classifi ed in several diff erent ways according to their origin. Two primary types are ‘value uncertainties’ and
‘structural uncertainties’. Value uncertainties arise from the incomplete determination of particular values or results, for example, when
data are inaccurate or not fully representative of the phenomenon of interest. Structural uncertainties arise from an incomplete un-
derstanding of the processes that control particular values or results, for example, when the conceptual framework or model used
for analysis does not include all the relevant processes or relationships. Value uncertainties are generally estimated using statistical
techniques and expressed probabilistically. Structural uncertainties are generally described by giving the authors’ collective judgment
of their confi dence in the correctness of a result. In both cases, estimating uncertainties is intrinsically about describing the limits to
knowledge and for this reason involves expert judgment about the state of that knowledge. A diff erent type of uncertainty arises
in systems that are either chaotic or not fully deterministic in nature and this also limits our ability to project all aspects of climate
change.
The scientifi c literature assessed here uses a variety of other generic ways of categorising uncertainties. Uncertainties associated
with ‘random errors’ have the characteristic of decreasing as additional measurements are accumulated, whereas those associated
with ‘systematic errors’ do not. In dealing with climate records, considerable attention has been given to the identifi cation of systemat-
ic errors or unintended biases arising from data sampling issues and methods of analysing and combining data. Specialised statistical
methods based on quantitative analysis have been developed for the detection and attribution of climate change and for producing
probabilistic projections of future climate parameters. These are summarised in the relevant chapters.
The uncertainty guidance provided for the Fourth Assessment Report draws, for the fi rst time, a careful distinction between levels
of confi dence in scientifi c understanding and the likelihoods of specifi c results. This allows authors to express high confi dence that an
event is extremely unlikely (e.g., rolling a dice twice and getting a six both times), as well as high confi dence that an event is about as
likely as not (e.g., a tossed coin coming up heads). Confi dence and likelihood as used here are distinct concepts but are often linked
in practice.
The standard terms used to defi ne levels of confi dence in this report are as given in the IPCC Uncertainty Guidance Note, namely:
Confi dence Terminology Degree of confi dence in being correct
Very high confi dence High confi dence Medium confi dence Low confi dence Very low confi dence At least 9 out of 10 chance
About 8 out of 10 chance
About 5 out of 10 chance
About 2 out of 10 chance
Less than 1 out of 10 chance
Note that ‘low confi dence’ and ‘very low confi dence’ are only used for areas of major concern and where a risk-based perspective
is justifi ed.
Chapter 2 of this report uses a related term ‘level of scientifi c understanding’ when describing uncertainties in diff erent contribu-
tions to radiative forcing. This terminology is used for consistency with the Third Assessment Report, and the basis on which the au-
thors have determined particular levels of scientifi c understanding uses a combination of approaches consistent with the uncertainty
guidance note as explained in detail in Section 2.9.2 and Table 2.11.
1 See Supplementary Material for this report
120
Chapter 1 Historical Overview of Climate Change Science
The standard terms used in this report to defi ne the likelihood of an outcome or result where this can be estimated
probabilistically are:
Likelihood Terminology Likelihood of the occurrence/ outcome
Virtually certain > 99% probability
Extremely likely > 95% probability
Very likely > 90% probability
Likely > 66% probability
More likely than not > 50% probability
About as likely as not 33 to 66% probability
Unlikely < 33% probability
Very unlikely < 10% probability
Extremely unlikely < 5% probability
Exceptionally unlikely < 1% probability
The terms ‘extremely likely’, ‘extremely unlikely’ and ‘more likely than not’ as defi ned above have been added to those given in
the IPCC Uncertainty Guidance Note in order to provide a more specifi c assessment of aspects including attribution and radiative
forcing.
Unless noted otherwise, values given in this report are assessed best estimates and their uncertainty ranges are 90% confi dence
intervals (i.e., there is an estimated 5% likelihood of the value being below the lower end of the range or above the upper end of the
range). Note that in some cases the nature of the constraints on a value, or other information available, may indicate an asymmetric
distribution of the uncertainty range around a best estimate.
In an effort to promote consistency, a guidance paper on
uncertainty (Moss and Schneider, 2000) was distributed to all
Working Group authors during the drafting of the TAR. The
WGI TAR made some effort at consistency, noting in the SPM
that when ranges were given they generally denoted 95%
confi dence intervals, although the carbon budget uncertainties
were specifi ed as ±1 standard deviation (68% likelihood). The
range of 1.5°C to 4.5°C for climate sensitivity to atmospheric
CO2 doubling was reiterated but with no confi dence assigned;
however, it was clear that the level of scientifi c understanding
had increased since that same range was fi rst given in the
Charney et al. (1979) report. The RF bar chart noted that the
RF components could not be summed (except for the long-
lived greenhouse gases) and that the ‘whiskers’ on the RF bars
each meant something different (e.g., some were the range of
models, some were uncertainties). Another failure in dealing
with uncertainty was the projection of 21st-century warming:
it was reported as a range covering (i) six Special Report on
Emission Scenarios (SRES) emissions scenarios and (ii) nine
atmosphere-ocean climate models using two grey envelopes
without estimates of likelihood levels. The full range (i.e.,
scenario plus climate model range) of 1.4°C to 5.8°C is a
much-cited fi nding of the WGI TAR but the lack of discussion
of associated likelihood in the report makes the interpretation
and useful application of this result diffi cult.
1.7 Summary
As this chapter shows, the history of the centuries-long effort
to document and understand climate change is often complex,
marked by successes and failures, and has followed a very uneven
pace. Testing scientifi c fi ndings and openly discussing the test
results have been the key to the remarkable progress that is now
accelerating in all domains, in spite of inherent limitations to
predictive capacity. Climate change science is now contributing
to the foundation of a new interdisciplinary approach to
understanding our environment. Consequently, much published
research and many notable scientifi c advances have occurred
since the TAR, including advances in the understanding and
treatment of uncertainty. Key aspects of recent climate change
research are assessed in Chapters 2 through 11 of this report.

